{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial\n",
    "from scipy import stats\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1)\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "from random import randint\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training sets\n",
    "with open('train.en') as f:\n",
    "    train_en = [l.strip() for l in f.readlines()]\n",
    "with open('train.fr') as f:\n",
    "    train_fr = [l.strip() for l in f.readlines()]\n",
    "\n",
    "#validation sets\n",
    "with open('val.en') as f:\n",
    "    val_en = [l.strip() for l in f.readlines()]\n",
    "with open('val.fr') as f:\n",
    "    val_fr = [l.strip() for l in f.readlines()]\n",
    "\n",
    "#test sets\n",
    "with open('test_2017_flickr.en') as f:\n",
    "    test_en = [l.strip() for l in f.readlines()]\n",
    "with open('test_2017_flickr.fr') as f:\n",
    "    test_fr = [l.strip() for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "# 0 PAD - padding 0 for convenience in masking\n",
    "# 1 BOS - beginning of sentence\n",
    "# 2 EOS - end of sentence\n",
    "# 3 UNK - unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_sentence_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokens_sentences(sentences):\n",
    "    tokens_list = []\n",
    "    sentence_list = []\n",
    "    for s in sentences:\n",
    "        split_sent = s.split()\n",
    "        sentence = []\n",
    "        for w in split_sent:\n",
    "\n",
    "            tokens_list.append(w)\n",
    "            sentence.append(w)\n",
    "\n",
    "        sentence_list.append(sentence)\n",
    "    \n",
    "    return tokens_list, sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens_list_en, sentence_list_en = tokens_sentences(train_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size 15456\n"
     ]
    }
   ],
   "source": [
    "tokens_train_en = list(sorted(set(tokens_list_en)))\n",
    "print('Vocabulary size', len(tokens_train_en))\n",
    "\n",
    "count_tokens_train_en = Counter(tokens_list_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_id_dicts(tokens):\n",
    "    #default dictionary key:id value:token\n",
    "    id2tokens = defaultdict(str)\n",
    "\n",
    "    for i in range(len(tokens)):\n",
    "        id2tokens[i] = tokens[i]\n",
    "\n",
    "    #default dictionary key:token value:id\n",
    "    tokens2id = defaultdict(int)\n",
    "\n",
    "    for ind in id2tokens:\n",
    "        tokens2id[id2tokens[ind]] = ind\n",
    "\n",
    "    return tokens2id, id2tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15456\n"
     ]
    }
   ],
   "source": [
    "tokens2id_en, id2tokens_en = get_id_dicts(tokens_train_en)\n",
    "\n",
    "vocabulary_size_train_en = len(tokens2id_en)\n",
    "print(vocabulary_size_train_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_corpus2id(sentence_list, tokens2id):\n",
    "    \n",
    "    #convert dataset to ids\n",
    "    corpus2id = []\n",
    "    \n",
    "    for s in sentence_list:\n",
    "    \n",
    "        sentence2id = []\n",
    "\n",
    "        for w in s:\n",
    "            word_id = tokens2id[w]\n",
    "            sentence2id.append(word_id)\n",
    "\n",
    "        corpus2id.append(sentence2id)\n",
    "    \n",
    "    return corpus2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_en_2id = convert_corpus2id(sentence_list_en, tokens2id_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2017, 15429, 2125, 8935, 2551, 9950, 9568, 8979, 3793]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_en_2id[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderDecoderAttention(nn.Module):\n",
    "    def __init__(self, vocab_size_en,vocab_size_fr, w_embedding_dim, p_embedding_dim, max_sentence_length):\n",
    "        super(EmbedAlign, self).__init__()\n",
    "        \n",
    "        self.vocab_size_en = vocab_size_en\n",
    "        self.vocab_size_fr = vocab_size_fr\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        self.w_embedding_dim = w_embedding_dim\n",
    "        self.p_embedding_dim = p_embedding_dim\n",
    "        \n",
    "        #encoder\n",
    "        self.w_embeddings = nn.Embedding(self.vocab_size_en, self.w_embedding_dim)\n",
    "        self.p_embeddings = nn.Embedding(self.max_sentence_length, self.p_embedding_dim)\n",
    "        \n",
    "        #self.attention = \n",
    "        \n",
    "        self.attention_projection = nn.Linear(self.embedding_dim, self.embedding_dim)\n",
    "        #do we use non-linearity after attention\n",
    "        \n",
    "        #decoder   \n",
    "        self.rnn = nn.RNN(self.embedding_dim, self.embedding_dim)\n",
    "        \n",
    "        #self.bidirLSTM = nn.LSTM(self.embedding_dim, self.embedding_dim, bidirectional=True)\n",
    "        #TODO: LSTM, GRU \n",
    "        \n",
    "        #TODO: DROPOUT\n",
    "        \n",
    "        \n",
    "    def forward(self, batch_en, batch_fr, pos_fr, lens_fr):\n",
    "        \n",
    "        \n",
    "        w_out = self.w_embeddings(batch_fr)\n",
    "        \n",
    "        p_out = self.p_embeddings(pos_fr)\n",
    "        \n",
    "        e_out = torch.cat((w_out, p_out), 0)\n",
    "        \n",
    "        #avg_out = for each sentence\n",
    "        \n",
    "        #if EOS for encoder, move on the decoder\n",
    "        \n",
    "        attention_matrices = self.attention_projection(e_out)\n",
    "        \n",
    "        #a = torch.matmul(attention_matrices, hidden_from_decoder)\n",
    "        \n",
    "        #softmax_a = a/a.sum()\n",
    "        \n",
    "        #context = e_out*a\n",
    "     \n",
    "        \n",
    "        #a = F.softmax(a, dim=0) \n",
    "        \n",
    "        #input embedding\n",
    "        #set hidden at the beginning\n",
    "        #get rnn output\n",
    "        #apply softmax\n",
    "\n",
    "        #feed actual word for training\n",
    "        #feed previous word for testing\n",
    "\n",
    "\n",
    "#             embeddings = self.w_embeddings(word_x)\n",
    "#             #view_shape = embeddings.shape[0]\n",
    "#             output, (hidden, cell) = self.bidirLSTM(embeddings.view(1, 1, -1)) \n",
    "\n",
    "#             hid_f = hidden[0]\n",
    "#             hid_b = hidden[1]\n",
    "\n",
    "        final_out = 0\n",
    "            \n",
    "        return final_out\n",
    "\n",
    "epochs = 10\n",
    "learning_rate = 0.01\n",
    "w_embedding_dim = 100\n",
    "p_embedding_dim = 100\n",
    "\n",
    "model = EncoderDecoderAttention(vocabulary_size_en, vocabulary_size_fr, embedding_dim) #pad\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "losses = []\n",
    "avg_losses = []\n",
    "\n",
    "portion = 1000\n",
    "\n",
    "print('epoch, total loss, average loss, duration')\n",
    "for e in range(epochs):\n",
    "    \n",
    "    then = datetime.now()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    for b in range(portion):\n",
    "\n",
    "        mu_i = []\n",
    "        sigma_i = []\n",
    "        z_i = []\n",
    "        best_alignments = []\n",
    "        \n",
    "        if len(batches_en[b]) > 0 and len(batches_fr[b]) > 0:\n",
    "            batch_en = torch.tensor(np.asarray(batches_en[b]), dtype= torch.long)\n",
    "\n",
    "            batch_fr = torch.tensor(np.asarray(batches_fr[b]), dtype= torch.long)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss, mu_i, sigma_i, xi,yi,z_i, best_alignments = model(batch_en, batch_fr,mu_i, sigma_i, z_i, best_alignments)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() \n",
    "    \n",
    "    now = datetime.now()\n",
    "        \n",
    "    losses.append(total_loss)\n",
    "    \n",
    "    avg_loss = np.mean(losses)/len(batches_en)\n",
    "    \n",
    "    print(e, total_loss, avg_loss, now-then)\n",
    "    \n",
    "    avg_losses.append(avg_loss)\n",
    "    \n",
    "\n",
    "with open('model_embed' + str(portion) + '.pickle','wb') as file:\n",
    "    pickle.dump(model,file)\n",
    "      \n",
    "iteration= list(range(len(avg_losses)))\n",
    "\n",
    "plt.plot(iteration, avg_losses)\n",
    "plt.xlabel(\"Iterations for MT\")\n",
    "plt.ylabel('Average loss')\n",
    "plt.title('Evolution of the loss as a function of the iteration')\n",
    "plt.savefig(\"mt\" + str(portion)+\".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
