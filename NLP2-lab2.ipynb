{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial\n",
    "from scipy import stats\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1)\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "from random import randint\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('error')\n",
    "\n",
    "import string\n",
    "puncs = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training sets\n",
    "with open('tokenized_lower.en') as f:\n",
    "    train_en = [l.strip() for l in f.readlines()][:10]\n",
    "with open('tokenized_lower.fr') as f:\n",
    "    train_fr = [l.strip() for l in f.readlines()][:10]\n",
    "\n",
    "# #validation sets\n",
    "# with open('val.en') as f:\n",
    "#     val_en = [l.strip() for l in f.readlines()]\n",
    "# with open('val.fr') as f:\n",
    "#     val_fr = [l.strip() for l in f.readlines()]\n",
    "\n",
    "# #test sets\n",
    "# with open('test_2017_flickr.en') as f:\n",
    "#     test_en = [l.strip() for l in f.readlines()]\n",
    "# with open('test_2017_flickr.fr') as f:\n",
    "#     test_fr = [l.strip() for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "# 0 PAD - padding 0 for convenience in masking?\n",
    "# 1 BOS - beginning of sentence\n",
    "# 2 EOS - end of sentence\n",
    "# 3 UNK - unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_sentence_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokens_sentences(sentences):\n",
    "    tokens_list = []\n",
    "    sentence_list = []\n",
    "    for s in sentences:\n",
    "        split_sent = s.split()\n",
    "        sentence = []\n",
    "        for w in split_sent:\n",
    "\n",
    "            if w not in puncs:\n",
    "                tokens_list.append(w)\n",
    "                sentence.append(w)\n",
    "\n",
    "        sentence_list.append(sentence)\n",
    "    \n",
    "    return tokens_list, sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size EN 74\n",
      "Vocabulary size FR 77\n"
     ]
    }
   ],
   "source": [
    "tokens_list_en, sentence_list_en = tokens_sentences(train_en)\n",
    "\n",
    "tokens_train_en = ['<PAD>', '<SOS>', '<EOS>', '<UNK>']\n",
    "tokens_train_en.extend(list(sorted(set(tokens_list_en))))\n",
    "vocab_size_en = len(tokens_train_en)\n",
    "print('Vocabulary size EN', vocab_size_en)\n",
    "\n",
    "count_tokens_train_en = Counter(tokens_list_en)\n",
    "\n",
    "tokens_list_fr, sentence_list_fr = tokens_sentences(train_fr)\n",
    "\n",
    "tokens_train_fr = ['<PAD>', '<SOS>', '<EOS>', '<UNK>']\n",
    "tokens_train_fr.extend(list(sorted(set(tokens_list_fr))))\n",
    "vocab_size_fr = len(tokens_train_fr)\n",
    "print('Vocabulary size FR', len(tokens_train_fr))\n",
    "\n",
    "count_tokens_train_fr = Counter(tokens_list_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_id_dicts(tokens):\n",
    "    #default dictionary key:id value:token\n",
    "    id2tokens = defaultdict(str)\n",
    "\n",
    "    for i in range(len(tokens)):\n",
    "        id2tokens[i] = tokens[i]\n",
    "\n",
    "    #default dictionary key:token value:id\n",
    "    tokens2id = defaultdict(int)\n",
    "\n",
    "    for ind in id2tokens:\n",
    "        tokens2id[id2tokens[ind]] = ind\n",
    "\n",
    "    return tokens2id, id2tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n",
      "77\n"
     ]
    }
   ],
   "source": [
    "tokens2id_en, id2tokens_en = get_id_dicts(tokens_train_en)\n",
    "\n",
    "vocabulary_size_train_en = len(tokens2id_en)\n",
    "print(vocabulary_size_train_en)\n",
    "\n",
    "tokens2id_fr, id2tokens_fr = get_id_dicts(tokens_train_fr)\n",
    "\n",
    "vocabulary_size_train_fr = len(tokens2id_fr)\n",
    "print(vocabulary_size_train_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_corpus2id(sentence_list, tokens2id, max_sentence_length):\n",
    "    \n",
    "    #convert dataset to ids\n",
    "    corpus2id = []\n",
    "    \n",
    "    for s in sentence_list:\n",
    "    \n",
    "        sentence2id = []\n",
    "        sentence2id.append(tokens2id['<SOS>'])\n",
    "    \n",
    "        for w in s:\n",
    "            word_id = tokens2id[w]\n",
    "            sentence2id.append(word_id)\n",
    "        \n",
    "        \n",
    "        sentence2id.append(tokens2id['<EOS>'])\n",
    "        \n",
    "        if len(sentence2id) < max_sentence_length:\n",
    "            corpus2id.append(sentence2id)\n",
    "    \n",
    "        else:\n",
    "            print(sentence2id)#none\n",
    "            \n",
    "    return corpus2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus2id_en = convert_corpus2id(sentence_list_en, tokens2id_en, max_sentence_length)\n",
    "corpus2id_fr = convert_corpus2id(sentence_list_fr, tokens2id_fr, max_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(corpus2id_en), len(corpus2id_fr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 65, 73, 68, 35, 5, 47, 40, 37, 9, 2]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus2id_en[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,vocab_size_fr, w_embedding_dim, p_embedding_dim, dec_embedding_dim, max_sentence_length):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.vocab_size_fr = vocab_size_fr\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        \n",
    "        self.w_embedding_dim = w_embedding_dim\n",
    "        self.p_embedding_dim = p_embedding_dim\n",
    "        \n",
    "        initrange = 0.5 / self.w_embedding_dim\n",
    "        self.dec_embedding_dim = dec_embedding_dim\n",
    "        \n",
    "        #encoder\n",
    "        self.w_embeddings = nn.Embedding(self.vocab_size_fr, self.w_embedding_dim)\n",
    "        self.p_embeddings = nn.Embedding(self.max_sentence_length, self.p_embedding_dim)\n",
    "        \n",
    "        self.w_embeddings.weight.data.uniform_(-initrange, initrange)\n",
    "        self.p_embeddings.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        \n",
    "        self.context_emb_dim = self.w_embedding_dim + self.p_embedding_dim\n",
    "        \n",
    "        #self.context_projection = nn.Linear(self.context_emb_dim, self.dec_embedding_dim)\n",
    "        #do we use non-linearity after attention\n",
    "        \n",
    "        #TODO: DROPOUT\n",
    "        \n",
    "        \n",
    "    def forward(self, sent_fr, pos_fr):\n",
    "        \n",
    "        #embedded = self.embedding(input).view(1, 1, -1)\n",
    "        #TODO:BATCH\n",
    "        \n",
    "        ws = []\n",
    "        ps = []\n",
    "        es = []\n",
    "        \n",
    "        for s in range(len(sent_fr)):\n",
    "            word = sent_fr[s]\n",
    "            pos = pos_fr[s]\n",
    "            \n",
    "            w_out = self.w_embeddings(word)\n",
    "\n",
    "            p_out = self.p_embeddings(pos)\n",
    "\n",
    "            e_out = torch.cat((w_out, p_out), 0)\n",
    "    \n",
    "            ws.append(w_out)\n",
    "            ps.append(p_out)\n",
    "            es.append(e_out)\n",
    "        \n",
    "        stacked_contexts = torch.stack(es, dim = 0)\n",
    "        \n",
    "        average_context = torch.mean(stacked_contexts, dim = 0)\n",
    "            \n",
    "        return average_context, stacked_contexts\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, dec_embedding_dim, vocab_size_en, max_sentence_length, dropout_prob):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.vocab_size_en = vocab_size_en\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        \n",
    "        self.dec_embedding_dim = dec_embedding_dim*2\n",
    "        \n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.dropout = nn.Dropout(self.dropout_prob)\n",
    "        \n",
    "        initrange = 0.5 / self.dec_embedding_dim\n",
    "        self.embedding = nn.Embedding(self.vocab_size_en, self.dec_embedding_dim)\n",
    "        \n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)        \n",
    "        \n",
    "        self.rnn = nn.GRU(self.dec_embedding_dim, self.dec_embedding_dim)\n",
    "        #self.bidirLSTM = nn.LSTM(self.embedding_dim, self.embedding_dim, bidirectional=True)\n",
    "        #TODO: LSTM, GRU \n",
    "       \n",
    "        self.pre_rnn_affine = nn.Linear(self.dec_embedding_dim*2, self.dec_embedding_dim)\n",
    "        #a linear layer after this before softmax\n",
    "        self.out_affine = nn.Linear(self.dec_embedding_dim, self.vocab_size_en)\n",
    "               \n",
    "    \n",
    "    def forward(self, gold_target_sent, encoder_avg_context, encoder_stacked_contexts, train):\n",
    "        \n",
    "        pred = []\n",
    "        attentions = []\n",
    "        \n",
    "        if train: #if training time\n",
    "            for s in range(len(gold_target_sent)):\n",
    "                gold_word = gold_target_sent[s]\n",
    "\n",
    "                output = self.embedding(gold_word)\n",
    "\n",
    "                output = self.dropout(output)\n",
    "\n",
    "                if s == 0:\n",
    "\n",
    "                    weighted_context = torch.zeros(output.shape)\n",
    "                    output = torch.cat((output, weighted_context), 0)\n",
    "\n",
    "                    output = F.relu(self.pre_rnn_affine(output))\n",
    "                    #TODO: start with 0 vector as h0\n",
    "\n",
    "                    output, hidden = self.rnn(output.view(1, 1, -1), encoder_avg_context.view(1, 1, -1))\n",
    "                    prev_hidden = hidden\n",
    "\n",
    "                    s_output = self.out_affine(output[0])\n",
    "                    s_output = F.log_softmax(s_output, dim=1) #TODO: CHECK DIM AND OUTPUT[0]\n",
    "\n",
    "                    pred.append(s_output)\n",
    "\n",
    "                elif s == len(gold_target_sent)-1:\n",
    "\n",
    "                    #end of sentence\n",
    "                    break\n",
    "\n",
    "                else:\n",
    "\n",
    "                    #start with weighted context\n",
    "                    output = torch.cat((output, weighted_context), 0)\n",
    "\n",
    "                    output = F.relu(self.pre_rnn_affine(output))\n",
    "\n",
    "                    output, hidden = self.rnn(output.view(1, 1, -1), prev_hidden.view(1, 1, -1))\n",
    "                    prev_hidden = hidden\n",
    "\n",
    "                    s_output = self.out_affine(output[0])\n",
    "\n",
    "                    s_output = F.log_softmax(s_output, dim=1) #TODO: CHECK DIM AND OUTPUT[0]\n",
    "                    pred.append(s_output)\n",
    "\n",
    "                attention_weights_word = F.log_softmax(torch.matmul(encoder_stacked_contexts, prev_hidden.view(-1,1)), dim = 0)\n",
    "\n",
    "                #print(attention_weights_word)\n",
    "\n",
    "                weighted_context = torch.sum(torch.mul(attention_weights_word, encoder_stacked_contexts), dim = 0)\n",
    "\n",
    "                attentions.append(attention_weights_word)\n",
    "\n",
    "\n",
    "            attention_weights = torch.stack(attentions, dim=0)\n",
    "\n",
    "            pred = torch.stack(pred, dim=0)\n",
    "            \n",
    "            return pred, attention_weights\n",
    "        \n",
    "        else: #if testing time\n",
    "            \n",
    "            decoder_outputs = []\n",
    "            decoder_attentions = []\n",
    "        \n",
    "            test_word = torch.tensor(np.asarray([tokens2id_en['<SOS>']]), dtype = torch.long)\n",
    "            \n",
    "            test_word_id = tokens2id_en['<SOS>']\n",
    "            \n",
    "            for w in range(self.max_sentence_length):\n",
    "       \n",
    "                if test_word_id == tokens2id_en['<EOS>']:\n",
    "                    \n",
    "                    break  \n",
    "                    \n",
    "                output = self.embedding(test_word)\n",
    "            \n",
    "                if w == 0:\n",
    "                    \n",
    "                    weighted_context = torch.zeros(output.shape)\n",
    "                    output = torch.cat((output.squeeze(), weighted_context.squeeze()), 0)\n",
    "                    \n",
    "                    output = F.relu(self.pre_rnn_affine(output))\n",
    "                    #TODO: start with 0 vector as h0\n",
    "\n",
    "                    output, hidden = self.rnn(output.view(1, 1, -1), encoder_avg_context.view(1, 1, -1))\n",
    "                    prev_hidden = hidden\n",
    "\n",
    "                    s_output = self.out_affine(output[0])\n",
    "                    s_output = F.log_softmax(s_output, dim=1) \n",
    "\n",
    "                    test_word_id = int(torch.argmax(s_output))\n",
    "                    test_word = torch.tensor(np.asarray([test_word_id]), dtype = torch.long)\n",
    "           \n",
    "                    \n",
    "                else:   \n",
    "                    #start with weighted context\n",
    "                    \n",
    "                    output = torch.cat((output.squeeze(), weighted_context.squeeze()), 0)\n",
    "\n",
    "                    output = F.relu(self.pre_rnn_affine(output))\n",
    "\n",
    "                    output, hidden = self.rnn(output.view(1, 1, -1), prev_hidden.view(1, 1, -1))\n",
    "                    prev_hidden = hidden\n",
    "\n",
    "                    s_output = self.out_affine(output[0])\n",
    "\n",
    "                    s_output = F.log_softmax(s_output, dim=1)\n",
    "                    \n",
    "                    test_word_id = int(torch.argmax(s_output))\n",
    "                    \n",
    "                    test_word = torch.tensor(np.asarray([test_word_id]), dtype = torch.long)\n",
    "                    \n",
    "                \n",
    "                attention_weights_word = F.log_softmax(torch.matmul(encoder_stacked_contexts, prev_hidden.view(-1,1)), dim = 0)\n",
    "\n",
    "                weighted_context = torch.sum(torch.mul(attention_weights_word, encoder_stacked_contexts), dim = 0)\n",
    "\n",
    "                attentions.append(attention_weights_word)\n",
    "                \n",
    "                decoder_outputs.append(test_word_id)\n",
    "                \n",
    "                                  \n",
    "\n",
    "            attention_weights = torch.stack(attentions, dim=0)            \n",
    "            \n",
    "            return decoder_outputs, attention_weights\n",
    "\n",
    "    \n",
    "    #https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, total loss, duration\n",
      "0 4.304755544662475 0:00:00.694584\n",
      "1 4.299750947952271 0:00:00.689860\n",
      "2 4.294832563400268 0:00:00.680933\n",
      "3 4.289986276626587 0:00:00.690179\n",
      "4 4.2852273941040036 0:00:00.675375\n",
      "5 4.280532598495483 0:00:00.674032\n",
      "6 4.275879669189453 0:00:00.679829\n",
      "7 4.27123761177063 0:00:00.700277\n",
      "8 4.266607332229614 0:00:00.678356\n",
      "9 4.261949968338013 0:00:00.684059\n",
      "10 4.2572469234466555 0:00:00.680679\n",
      "11 4.252484512329102 0:00:00.675394\n",
      "12 4.247660779953003 0:00:00.681310\n",
      "13 4.2427592277526855 0:00:00.689176\n",
      "14 4.237760019302368 0:00:00.689526\n",
      "15 4.23264856338501 0:00:00.682039\n",
      "16 4.2273876667022705 0:00:01.044285\n",
      "17 4.221989536285401 0:00:01.107853\n",
      "18 4.216413307189941 0:00:01.146367\n",
      "19 4.21064829826355 0:00:01.216374\n",
      "20 4.204668807983398 0:00:00.876933\n",
      "21 4.19844331741333 0:00:00.928981\n",
      "22 4.191941452026367 0:00:00.800264\n",
      "23 4.18512110710144 0:00:00.791324\n",
      "24 4.177940559387207 0:00:00.811837\n",
      "25 4.170363092422486 0:00:00.767820\n",
      "26 4.162341356277466 0:00:00.708511\n",
      "27 4.153823184967041 0:00:00.809683\n",
      "28 4.14475269317627 0:00:00.718310\n",
      "29 4.135081195831299 0:00:00.718135\n",
      "30 4.124759292602539 0:00:00.724320\n",
      "31 4.113782691955566 0:00:00.727359\n",
      "32 4.102118754386902 0:00:00.864953\n",
      "33 4.089850378036499 0:00:00.943814\n",
      "34 4.077084708213806 0:00:00.752959\n",
      "35 4.064019227027893 0:00:00.835385\n",
      "36 4.050939011573791 0:00:00.805124\n",
      "37 4.0382472515106205 0:00:01.002719\n",
      "38 4.026367998123169 0:00:01.093767\n",
      "39 4.015688824653625 0:00:00.773257\n",
      "40 4.006461954116821 0:00:00.789485\n",
      "41 3.99874267578125 0:00:00.834106\n",
      "42 3.992385816574097 0:00:00.928805\n",
      "43 3.987122964859009 0:00:00.897777\n",
      "44 3.9826621055603026 0:00:00.900103\n",
      "45 3.9787498712539673 0:00:00.753805\n",
      "46 3.97518630027771 0:00:00.815459\n",
      "47 3.971859884262085 0:00:00.783117\n",
      "48 3.9687003612518312 0:00:00.865641\n",
      "49 3.965676212310791 0:00:00.718863\n",
      "50 3.962751626968384 0:00:00.735864\n",
      "51 3.959920287132263 0:00:00.747315\n",
      "52 3.9571651220321655 0:00:00.726297\n",
      "53 3.9545077085494995 0:00:00.822254\n",
      "54 3.951899290084839 0:00:00.816906\n",
      "55 3.949371361732483 0:00:00.855216\n",
      "56 3.9468950748443605 0:00:00.702938\n",
      "57 3.9444844484329225 0:00:00.715007\n",
      "58 3.942119002342224 0:00:00.752298\n",
      "59 3.939811444282532 0:00:00.759969\n",
      "60 3.9375425815582275 0:00:00.729546\n",
      "61 3.935317277908325 0:00:00.700398\n",
      "62 3.9331258058547975 0:00:00.771240\n",
      "63 3.9309744596481324 0:00:01.042682\n",
      "64 3.928848385810852 0:00:00.872493\n",
      "65 3.9267400979995726 0:00:00.787788\n",
      "66 3.924641251564026 0:00:00.808633\n",
      "67 3.9225771903991697 0:00:01.155959\n",
      "68 3.9205082416534425 0:00:00.855528\n",
      "69 3.9184663772583006 0:00:00.786968\n",
      "70 3.9164159059524537 0:00:00.874224\n",
      "71 3.914372444152832 0:00:00.896091\n",
      "72 3.9123306035995484 0:00:01.008359\n",
      "73 3.91028368473053 0:00:01.120129\n",
      "74 3.9082294702529907 0:00:01.000879\n",
      "75 3.906174325942993 0:00:00.739095\n",
      "76 3.9041030645370483 0:00:00.815016\n",
      "77 3.9020232200622558 0:00:00.808735\n",
      "78 3.8999229192733766 0:00:00.843274\n",
      "79 3.8978031873703003 0:00:01.016914\n",
      "80 3.895664834976196 0:00:00.897761\n",
      "81 3.8935001373291014 0:00:00.851811\n",
      "82 3.891305613517761 0:00:00.757082\n",
      "83 3.8890701055526735 0:00:01.168328\n",
      "84 3.8868268728256226 0:00:01.271032\n",
      "85 3.884525465965271 0:00:01.307348\n",
      "86 3.882208466529846 0:00:00.967230\n",
      "87 3.8798325061798096 0:00:00.910198\n",
      "88 3.87742600440979 0:00:00.944944\n",
      "89 3.8749643087387087 0:00:00.794976\n",
      "90 3.872459292411804 0:00:01.142909\n",
      "91 3.8698894023895263 0:00:00.782101\n",
      "92 3.867277669906616 0:00:00.746281\n",
      "93 3.864588212966919 0:00:01.136463\n",
      "94 3.861837959289551 0:00:00.761914\n",
      "95 3.8590183734893797 0:00:00.836595\n",
      "96 3.8561230182647703 0:00:00.759003\n",
      "97 3.853152060508728 0:00:00.708995\n",
      "98 3.8500940084457396 0:00:00.852201\n",
      "99 3.8469661235809327 0:00:00.839580\n",
      "100 3.843738293647766 0:00:00.855432\n",
      "101 3.8404239416122437 0:00:00.833568\n",
      "102 3.8370095252990724 0:00:00.881615\n",
      "103 3.833486866950989 0:00:00.898833\n",
      "104 3.8298513174057005 0:00:00.849960\n",
      "105 3.826106238365173 0:00:00.777246\n",
      "106 3.822239565849304 0:00:00.854360\n",
      "107 3.818261504173279 0:00:00.695043\n",
      "108 3.8141430854797362 0:00:00.686472\n",
      "109 3.8098849058151245 0:00:00.698314\n",
      "110 3.805484485626221 0:00:00.701276\n",
      "111 3.8009421825408936 0:00:00.729114\n",
      "112 3.7962636232376097 0:00:00.839910\n",
      "113 3.7913992166519166 0:00:00.712078\n",
      "114 3.786403465270996 0:00:00.700666\n",
      "115 3.7812279224395753 0:00:00.682916\n",
      "116 3.775885486602783 0:00:00.675434\n",
      "117 3.7703858613967896 0:00:00.796721\n",
      "118 3.764705014228821 0:00:00.683618\n",
      "119 3.758847165107727 0:00:00.745813\n",
      "120 3.75277636051178 0:00:00.684262\n",
      "121 3.7465155363082885 0:00:00.690353\n",
      "122 3.7400487422943116 0:00:00.691698\n",
      "123 3.7333956718444825 0:00:00.678640\n",
      "124 3.726536774635315 0:00:00.756569\n",
      "125 3.7194676637649535 0:00:00.891996\n",
      "126 3.712180972099304 0:00:00.695060\n",
      "127 3.7046714305877684 0:00:00.841263\n",
      "128 3.6969196796417236 0:00:00.856414\n",
      "129 3.688950228691101 0:00:00.689961\n",
      "130 3.6807281494140627 0:00:00.710884\n",
      "131 3.6722906589508058 0:00:00.747868\n",
      "132 3.6635802030563354 0:00:00.925987\n",
      "133 3.6546305894851683 0:00:00.849578\n",
      "134 3.6454236268997193 0:00:00.701029\n",
      "135 3.635962438583374 0:00:00.685404\n",
      "136 3.6262665748596192 0:00:00.689822\n",
      "137 3.616315793991089 0:00:00.688172\n",
      "138 3.606135630607605 0:00:00.693292\n",
      "139 3.595757341384888 0:00:00.685810\n",
      "140 3.585134410858154 0:00:00.689998\n",
      "141 3.574326276779175 0:00:00.702780\n",
      "142 3.563303804397583 0:00:00.682455\n",
      "143 3.5521026372909548 0:00:00.686518\n",
      "144 3.5406953573226927 0:00:00.686172\n",
      "145 3.529132628440857 0:00:00.683873\n",
      "146 3.5173943996429444 0:00:00.679351\n",
      "147 3.5055190324783325 0:00:00.687714\n",
      "148 3.493492531776428 0:00:00.688534\n",
      "149 3.481374406814575 0:00:00.679946\n",
      "150 3.469103741645813 0:00:00.683225\n",
      "151 3.4567480802536013 0:00:00.686561\n",
      "152 3.4443009376525877 0:00:00.682264\n",
      "153 3.4317337036132813 0:00:00.694076\n",
      "154 3.4191020727157593 0:00:00.694187\n",
      "155 3.4063788414001466 0:00:00.680492\n",
      "156 3.393561005592346 0:00:00.690363\n",
      "157 3.3806494235992433 0:00:00.683391\n",
      "158 3.36760094165802 0:00:00.686158\n",
      "159 3.3544667243957518 0:00:00.689007\n",
      "160 3.3411540269851683 0:00:00.697117\n",
      "161 3.3277220249176027 0:00:00.753622\n",
      "162 3.3140891551971436 0:00:00.684633\n",
      "163 3.3002647876739504 0:00:00.699857\n",
      "164 3.286189413070679 0:00:00.819502\n",
      "165 3.2718679904937744 0:00:00.886491\n",
      "166 3.257260036468506 0:00:00.810124\n",
      "167 3.2423371076583862 0:00:01.057474\n",
      "168 3.2270675182342528 0:00:00.878147\n",
      "169 3.211443877220154 0:00:01.041082\n",
      "170 3.195425009727478 0:00:00.746842\n",
      "171 3.1789905548095705 0:00:00.699108\n",
      "172 3.162129306793213 0:00:00.673393\n",
      "173 3.1447598934173584 0:00:00.679221\n",
      "174 3.1268422842025756 0:00:00.688666\n",
      "175 3.108396124839783 0:00:00.687074\n",
      "176 3.0892873048782348 0:00:00.682638\n",
      "177 3.069581723213196 0:00:00.690343\n",
      "178 3.049216389656067 0:00:00.685892\n",
      "179 3.0282039880752563 0:00:00.690961\n",
      "180 3.0065901279449463 0:00:00.689907\n",
      "181 2.984506607055664 0:00:00.729667\n",
      "182 2.9619571924209596 0:00:00.875011\n",
      "183 2.9390411615371703 0:00:00.880359\n",
      "184 2.915984320640564 0:00:00.831761\n",
      "185 2.8927924156188967 0:00:00.690680\n",
      "186 2.8695998668670653 0:00:00.681128\n",
      "187 2.8464959859848022 0:00:00.684419\n",
      "188 2.8236276865005494 0:00:00.681989\n",
      "189 2.8008832931518555 0:00:00.694883\n",
      "190 2.778436040878296 0:00:00.693649\n",
      "191 2.756304693222046 0:00:00.685538\n",
      "192 2.7343303203582763 0:00:00.691540\n",
      "193 2.712765121459961 0:00:00.687377\n",
      "194 2.6914348363876344 0:00:00.678300\n",
      "195 2.6703949928283692 0:00:00.686682\n",
      "196 2.6497360944747923 0:00:00.684750\n",
      "197 2.62931911945343 0:00:00.696924\n",
      "198 2.6092150926589968 0:00:00.689608\n",
      "199 2.5894719123840333 0:00:00.685006\n",
      "200 2.569905090332031 0:00:00.683471\n",
      "201 2.550639605522156 0:00:00.680117\n",
      "202 2.531548810005188 0:00:00.776105\n",
      "203 2.512725353240967 0:00:00.687355\n",
      "204 2.494109058380127 0:00:00.695910\n",
      "205 2.475668716430664 0:00:00.694104\n",
      "206 2.457393479347229 0:00:00.728193\n",
      "207 2.439391613006592 0:00:00.825851\n",
      "208 2.4214142560958862 0:00:00.926913\n",
      "209 2.4038872003555296 0:00:00.774035\n",
      "210 2.386628341674805 0:00:00.829029\n",
      "211 2.379891586303711 0:00:00.971651\n",
      "212 2.4131046295166017 0:00:00.730259\n",
      "213 2.389535331726074 0:00:00.842901\n",
      "214 2.354714274406433 0:00:00.725996\n",
      "215 2.3380101919174194 0:00:00.719286\n",
      "216 2.3129720807075502 0:00:00.713898\n",
      "217 2.293482255935669 0:00:00.719005\n",
      "218 2.294432485103607 0:00:00.828656\n",
      "219 2.3612867832183837 0:00:00.694818\n",
      "220 2.266950225830078 0:00:00.711056\n",
      "221 2.24021897315979 0:00:00.819858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222 2.283833658695221 0:00:00.710700\n",
      "223 2.2756312489509583 0:00:00.830934\n",
      "224 2.222910690307617 0:00:00.773363\n",
      "225 2.214447796344757 0:00:00.741645\n",
      "226 2.2538997411727903 0:00:00.842658\n",
      "227 2.198846995830536 0:00:00.762001\n",
      "228 2.1914022564888 0:00:00.709011\n",
      "229 2.2148083806037904 0:00:00.737324\n",
      "230 2.1572404742240905 0:00:00.685171\n",
      "231 2.1699841141700746 0:00:00.693973\n",
      "232 2.184958040714264 0:00:00.680270\n",
      "233 2.1176217794418335 0:00:00.672189\n",
      "234 2.122515046596527 0:00:00.672038\n",
      "235 2.198878252506256 0:00:00.801592\n",
      "236 2.106467068195343 0:00:00.925728\n",
      "237 2.0984044551849363 0:00:00.687256\n",
      "238 2.0992056131362915 0:00:00.804627\n",
      "239 2.131313610076904 0:00:00.996843\n",
      "240 2.1146524786949157 0:00:00.990862\n",
      "241 2.072644019126892 0:00:00.910826\n",
      "242 2.0829952716827393 0:00:00.864218\n",
      "243 2.086139678955078 0:00:00.726612\n",
      "244 2.040046548843384 0:00:00.686830\n",
      "245 2.0284789323806764 0:00:00.693071\n",
      "246 2.0607290625572205 0:00:00.693293\n",
      "247 2.0774099349975588 0:00:00.689948\n",
      "248 2.0235734581947327 0:00:00.688206\n",
      "249 2.047767972946167 0:00:00.802834\n",
      "250 2.0365720987319946 0:00:00.945233\n",
      "251 2.0066852927207948 0:00:00.707578\n",
      "252 1.9843067169189452 0:00:00.682549\n",
      "253 2.0039257049560546 0:00:00.744326\n",
      "254 2.010281980037689 0:00:00.697233\n",
      "255 1.9972599744796753 0:00:00.703712\n",
      "256 2.0590951919555662 0:00:00.713618\n",
      "257 2.0638572216033935 0:00:00.757832\n",
      "258 1.9845672845840454 0:00:00.961903\n",
      "259 1.9254060745239259 0:00:00.915375\n",
      "260 1.900420892238617 0:00:00.787233\n",
      "261 1.9332627773284912 0:00:00.985837\n",
      "262 1.993077576160431 0:00:00.802083\n",
      "263 1.9337786316871644 0:00:00.686085\n",
      "264 1.9084991335868835 0:00:00.693535\n",
      "265 1.9405191898345948 0:00:00.681822\n",
      "266 1.9509470343589783 0:00:00.697048\n",
      "267 1.9620418071746826 0:00:00.851898\n",
      "268 1.9789905428886414 0:00:00.687314\n",
      "269 1.8875460028648376 0:00:00.673342\n",
      "270 1.836722445487976 0:00:00.702070\n",
      "271 1.8172032356262207 0:00:00.698385\n",
      "272 1.86614750623703 0:00:00.698048\n",
      "273 1.854334580898285 0:00:00.692782\n",
      "274 1.8218905210494996 0:00:00.695160\n",
      "275 1.816595470905304 0:00:00.793604\n",
      "276 2.005670189857483 0:00:00.706544\n",
      "277 1.9503678917884826 0:00:01.007814\n",
      "278 1.880491840839386 0:00:00.899230\n",
      "279 1.9616795182228088 0:00:01.170470\n",
      "280 1.8127803802490234 0:00:01.063312\n",
      "281 1.761742353439331 0:00:01.103125\n",
      "282 1.772946047782898 0:00:00.952822\n",
      "283 1.801475179195404 0:00:00.732973\n",
      "284 1.723179316520691 0:00:00.684380\n",
      "285 1.8762256860733033 0:00:00.687642\n",
      "286 1.828068161010742 0:00:00.679250\n",
      "287 1.8101377844810487 0:00:00.693771\n",
      "288 1.7193580508232116 0:00:00.685611\n",
      "289 1.7558526396751404 0:00:00.682985\n",
      "290 1.7695451617240905 0:00:00.686562\n",
      "291 1.7023057341575623 0:00:00.687789\n",
      "292 1.7161796808242797 0:00:00.685803\n",
      "293 1.8257591009140015 0:00:00.683826\n",
      "294 1.7566792011260985 0:00:00.685689\n",
      "295 1.6725764513015746 0:00:00.675666\n",
      "296 1.656057846546173 0:00:00.695110\n",
      "297 1.7709040760993957 0:00:00.696994\n",
      "298 1.799678921699524 0:00:00.699599\n",
      "299 1.7406482815742492 0:00:00.981330\n",
      "300 1.6838913321495057 0:00:00.808052\n",
      "301 1.7361555337905883 0:00:00.681181\n",
      "302 1.664404273033142 0:00:00.684446\n",
      "303 1.668487012386322 0:00:00.684311\n",
      "304 1.6274414539337159 0:00:00.720660\n",
      "305 1.6014307975769042 0:00:00.745113\n",
      "306 1.615648579597473 0:00:00.900473\n",
      "307 1.8211897253990172 0:00:01.002933\n",
      "308 1.6549452900886537 0:00:00.791643\n",
      "309 1.6474135160446166 0:00:00.773737\n",
      "310 1.720733118057251 0:00:00.678213\n",
      "311 1.7507524371147156 0:00:00.678171\n",
      "312 1.693672239780426 0:00:00.683263\n",
      "313 1.7245472431182862 0:00:00.693603\n",
      "314 1.6513191223144532 0:00:00.709647\n",
      "315 1.5687721133232118 0:00:00.692999\n",
      "316 1.6159981966018677 0:00:00.680764\n",
      "317 1.587086522579193 0:00:00.694806\n",
      "318 1.5354275941848754 0:00:00.689376\n",
      "319 1.654882562160492 0:00:00.773338\n",
      "320 1.5770090341567993 0:00:00.699543\n",
      "321 1.6243195295333863 0:00:00.685617\n",
      "322 1.6244420289993287 0:00:00.681864\n",
      "323 1.590242600440979 0:00:00.899145\n",
      "324 1.5863288402557374 0:00:00.708815\n",
      "325 1.5334667086601257 0:00:00.706552\n",
      "326 1.503953790664673 0:00:00.689752\n",
      "327 1.5976446986198425 0:00:00.687158\n",
      "328 1.5072195649147033 0:00:00.700197\n",
      "329 1.481583595275879 0:00:00.685440\n",
      "330 1.4852007448673248 0:00:00.673391\n",
      "331 1.5486136674880981 0:00:00.716868\n",
      "332 1.5925605416297912 0:00:00.715833\n",
      "333 1.6091120004653932 0:00:00.679383\n",
      "334 1.5893664956092834 0:00:00.682136\n",
      "335 1.5256181538105011 0:00:00.682064\n",
      "336 1.4775482714176178 0:00:00.679605\n",
      "337 1.453729236125946 0:00:00.687493\n",
      "338 1.469219708442688 0:00:00.694022\n",
      "339 1.512816196680069 0:00:00.679390\n",
      "340 1.5507845759391785 0:00:00.678193\n",
      "341 1.4287970304489135 0:00:00.678892\n",
      "342 1.4036467850208283 0:00:00.686421\n",
      "343 1.403832447528839 0:00:00.691285\n",
      "344 1.390604990720749 0:00:00.697233\n",
      "345 1.4566227674484253 0:00:00.697385\n",
      "346 1.581282377243042 0:00:00.684239\n",
      "347 1.5013967871665954 0:00:00.696311\n",
      "348 1.442483937740326 0:00:00.690458\n",
      "349 1.465723842382431 0:00:00.685840\n",
      "350 1.4036348462104797 0:00:00.693928\n",
      "351 1.415454089641571 0:00:00.678910\n",
      "352 1.3751384437084198 0:00:00.672290\n",
      "353 1.389234149456024 0:00:00.694123\n",
      "354 1.363961136341095 0:00:00.689005\n",
      "355 1.4244153499603271 0:00:00.676758\n",
      "356 1.4526324272155762 0:00:00.703199\n",
      "357 1.5135292053222655 0:00:00.680077\n",
      "358 1.4120766699314118 0:00:00.673446\n",
      "359 1.325034511089325 0:00:00.693710\n",
      "360 1.3414320945739746 0:00:00.705356\n",
      "361 1.3154804170131684 0:00:00.685564\n",
      "362 1.3623137176036835 0:00:00.766776\n",
      "363 1.3657320737838745 0:00:00.700483\n",
      "364 1.5046464860439301 0:00:00.688534\n",
      "365 1.3922284126281739 0:00:00.687690\n",
      "366 1.4778118312358857 0:00:00.690373\n",
      "367 1.3839937686920165 0:00:00.693614\n",
      "368 1.2746894299983977 0:00:00.692283\n",
      "369 1.2606020808219909 0:00:00.679961\n",
      "370 1.2700376749038695 0:00:00.686433\n",
      "371 1.3212404370307922 0:00:00.684118\n",
      "372 1.322758936882019 0:00:00.696178\n",
      "373 1.3096196055412292 0:00:00.812669\n",
      "374 1.2980628490447998 0:00:01.029053\n",
      "375 1.2819477498531342 0:00:00.862412\n",
      "376 1.3207926213741303 0:00:00.793864\n",
      "377 1.4271758913993835 0:00:00.849556\n",
      "378 1.4659965455532074 0:00:00.768971\n",
      "379 1.392404943704605 0:00:00.684794\n",
      "380 1.456550931930542 0:00:00.702026\n",
      "381 1.3572496592998504 0:00:00.857538\n",
      "382 1.4342030048370362 0:00:00.890539\n",
      "383 1.4945345580577851 0:00:00.703057\n",
      "384 1.3081893920898438 0:00:00.863083\n",
      "385 1.2914505481719971 0:00:00.970017\n",
      "386 1.21460822224617 0:00:00.882788\n",
      "387 1.196183580160141 0:00:00.925635\n",
      "388 1.2006161153316497 0:00:00.956684\n",
      "389 1.269245558977127 0:00:00.909994\n",
      "390 1.2103524386882782 0:00:00.686984\n",
      "391 1.2867549180984497 0:00:00.703030\n",
      "392 1.263569414615631 0:00:00.694320\n",
      "393 1.174072813987732 0:00:00.685831\n",
      "394 1.1988087832927703 0:00:00.966602\n",
      "395 1.1984096944332123 0:00:00.692190\n",
      "396 1.3676510870456695 0:00:00.703469\n",
      "397 1.3615155220031738 0:00:00.709865\n",
      "398 1.4073539912700652 0:00:00.961115\n",
      "399 1.389215099811554 0:00:00.997697\n",
      "400 1.2631956815719605 0:00:00.953897\n",
      "401 1.2754726231098175 0:00:00.703170\n",
      "402 1.2771391570568085 0:00:00.697677\n",
      "403 1.1931514501571656 0:00:00.697215\n",
      "404 1.1762279927730561 0:00:00.944483\n",
      "405 1.1353430092334746 0:00:00.999305\n",
      "406 1.1636268377304078 0:00:00.685882\n",
      "407 1.3309457898139954 0:00:00.816815\n",
      "408 1.2594259917736053 0:00:00.927542\n",
      "409 1.333028358221054 0:00:00.952115\n",
      "410 1.1771751165390014 0:00:00.747078\n",
      "411 1.1165749073028564 0:00:00.682158\n",
      "412 1.0815024256706238 0:00:00.892561\n",
      "413 1.0658002316951751 0:00:00.884871\n",
      "414 1.0673388063907623 0:00:00.826455\n",
      "415 1.052570366859436 0:00:00.694858\n",
      "416 1.0552442908287047 0:00:00.690777\n",
      "417 1.176237368583679 0:00:00.700527\n",
      "418 1.1665303111076355 0:00:00.772239\n",
      "419 1.2354881823062898 0:00:00.915632\n",
      "420 1.1713018119335175 0:00:00.688757\n",
      "421 1.1035821676254272 0:00:00.701018\n",
      "422 1.157985305786133 0:00:00.699408\n",
      "423 1.204294753074646 0:00:00.697141\n",
      "424 1.136972963809967 0:00:00.944553\n",
      "425 1.1054736733436585 0:00:00.684420\n",
      "426 1.0458687722682953 0:00:00.712649\n",
      "427 1.1099305689334868 0:00:00.688728\n",
      "428 1.1350626349449158 0:00:00.705673\n",
      "429 1.2566424012184143 0:00:00.863359\n",
      "430 1.1737588107585908 0:00:00.801666\n",
      "431 1.5317657887935638 0:00:00.865236\n",
      "432 1.4596069514751435 0:00:00.689445\n",
      "433 1.2099539756774902 0:00:00.704932\n",
      "434 1.1350942969322204 0:00:00.903794\n",
      "435 1.1229566872119903 0:00:00.953868\n",
      "436 1.11134831905365 0:00:00.693019\n",
      "437 1.0981143832206726 0:00:00.685203\n",
      "438 1.1187801957130432 0:00:00.737435\n",
      "439 1.1244949519634246 0:00:00.916289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440 1.0572295367717743 0:00:00.804200\n",
      "441 1.0071742981672287 0:00:00.698441\n",
      "442 1.0156762301921844 0:00:00.700096\n",
      "443 1.044659721851349 0:00:00.718027\n",
      "444 1.0316293954849243 0:00:00.748038\n",
      "445 1.0078525841236115 0:00:00.890764\n",
      "446 1.0335762560367585 0:00:00.678557\n",
      "447 1.153234538435936 0:00:00.692861\n",
      "448 1.2946719586849214 0:00:00.693341\n",
      "449 1.1660731494426728 0:00:00.686602\n",
      "450 1.0952616691589356 0:00:00.896410\n",
      "451 0.998846834897995 0:00:00.729248\n",
      "452 0.9635786056518555 0:00:00.684698\n",
      "453 0.9627557694911957 0:00:00.704216\n",
      "454 0.9626708000898361 0:00:00.694014\n",
      "455 0.9530817687511444 0:00:00.795646\n",
      "456 0.9570577532052994 0:00:00.851701\n",
      "457 0.9739375352859497 0:00:00.684143\n",
      "458 1.085024079680443 0:00:00.711722\n",
      "459 1.2039242029190063 0:00:00.734324\n",
      "460 1.07953499853611 0:00:00.700880\n",
      "461 1.13052995800972 0:00:00.949121\n",
      "462 0.9738915830850601 0:00:00.681942\n",
      "463 0.9193048179149628 0:00:00.689840\n",
      "464 0.8917346656322479 0:00:00.692266\n",
      "465 0.8839100539684296 0:00:00.683299\n",
      "466 0.8688966274261475 0:00:00.870141\n",
      "467 0.8608544856309891 0:00:00.785822\n",
      "468 0.8780728876590729 0:00:00.695510\n",
      "469 0.9122967153787613 0:00:00.687873\n",
      "470 1.1985819518566132 0:00:00.681475\n",
      "471 1.230010163784027 0:00:00.723556\n",
      "472 1.108139416575432 0:00:00.913055\n",
      "473 1.048065796494484 0:00:00.683110\n",
      "474 1.043200746178627 0:00:00.708663\n",
      "475 0.9681958943605423 0:00:00.694225\n",
      "476 0.9857931673526764 0:00:00.688207\n",
      "477 1.003340509533882 0:00:00.922277\n",
      "478 1.0654550969600678 0:00:00.767370\n",
      "479 0.9469259470701218 0:00:00.792160\n",
      "480 0.8976053297519684 0:00:00.918999\n",
      "481 0.9230209916830063 0:00:01.052373\n",
      "482 0.9811573207378388 0:00:01.033026\n",
      "483 0.922623085975647 0:00:00.889113\n",
      "484 0.8741699367761612 0:00:00.817394\n",
      "485 0.8862078040838242 0:00:00.688380\n",
      "486 0.8506832689046859 0:00:00.865384\n",
      "487 0.9334252029657364 0:00:00.777556\n",
      "488 1.0497276097536088 0:00:00.858443\n",
      "489 1.0558629900217056 0:00:00.785098\n",
      "490 0.978575274348259 0:00:00.906289\n",
      "491 0.8712539136409759 0:00:01.010291\n",
      "492 0.8221737533807755 0:00:00.856069\n",
      "493 0.8116322100162506 0:00:00.750137\n",
      "494 0.8058648437261582 0:00:00.951059\n",
      "495 0.8386777639389038 0:00:00.724657\n",
      "496 0.8651714324951172 0:00:00.721093\n",
      "497 0.9108861744403839 0:00:00.722199\n",
      "498 0.8563128411769867 0:00:00.717870\n",
      "499 0.8059208780527115 0:00:00.712898\n",
      "500 0.8008312255144119 0:00:00.704787\n",
      "501 0.7880014270544052 0:00:00.735993\n",
      "502 0.7848354876041412 0:00:00.714519\n",
      "503 0.7748278141021728 0:00:00.892723\n",
      "504 0.7420996338129043 0:00:00.879444\n",
      "505 0.7768223494291305 0:00:00.850364\n",
      "506 1.125604021549225 0:00:00.851481\n",
      "507 1.0416343063116074 0:00:01.057423\n",
      "508 1.0729150980710984 0:00:01.281850\n",
      "509 1.0090768843889237 0:00:01.104401\n",
      "510 0.891194224357605 0:00:00.857516\n",
      "511 0.8797723323106765 0:00:00.765920\n",
      "512 0.824635100364685 0:00:00.779573\n",
      "513 0.8189257204532623 0:00:00.798817\n",
      "514 0.7992011547088623 0:00:00.832769\n",
      "515 0.7289237916469574 0:00:00.800160\n",
      "516 0.7172627821564674 0:00:00.777921\n",
      "517 0.7084794461727142 0:00:00.805857\n",
      "518 0.7178860813379287 0:00:00.844795\n",
      "519 0.7352476641535759 0:00:00.782166\n",
      "520 0.763708482682705 0:00:00.803172\n",
      "521 0.8338612198829651 0:00:01.175357\n",
      "522 0.8479767352342605 0:00:00.947690\n",
      "523 0.8716429799795151 0:00:00.922667\n",
      "524 0.9584619760513305 0:00:00.899870\n",
      "525 0.9032254159450531 0:00:01.036209\n",
      "526 1.3361676216125489 0:00:01.055450\n",
      "527 1.3000147223472596 0:00:01.192377\n",
      "528 0.9321665406227112 0:00:01.078074\n",
      "529 0.8415334075689316 0:00:01.112141\n",
      "530 0.7659909516572952 0:00:01.122411\n",
      "531 0.7541212111711502 0:00:01.048048\n",
      "532 0.835761758685112 0:00:01.083243\n",
      "533 0.7770232647657395 0:00:01.101205\n",
      "534 0.8530594050884247 0:00:01.095936\n",
      "535 0.8174602508544921 0:00:01.056142\n",
      "536 0.783235278725624 0:00:01.051611\n",
      "537 0.8182019531726837 0:00:00.956611\n",
      "538 0.8492225050926209 0:00:01.074926\n",
      "539 0.8245731115341186 0:00:01.065066\n",
      "540 0.7612441271543503 0:00:01.152316\n",
      "541 0.7269728288054467 0:00:00.971669\n",
      "542 0.698406982421875 0:00:00.955157\n",
      "543 0.6918134227395057 0:00:01.034904\n",
      "544 0.6741465613245964 0:00:00.978442\n",
      "545 0.6767272606492043 0:00:00.697709\n",
      "546 0.6484392881393433 0:00:00.992659\n",
      "547 0.643307963013649 0:00:01.023996\n",
      "548 0.6279040440917015 0:00:00.867675\n",
      "549 0.6253629252314568 0:00:01.054439\n",
      "550 0.6179234683513641 0:00:00.766355\n",
      "551 0.6252837851643562 0:00:00.950473\n",
      "552 0.6683363810181617 0:00:00.981393\n",
      "553 0.962975050508976 0:00:00.812699\n",
      "554 1.1952105075120927 0:00:01.222155\n",
      "555 0.8002183318138123 0:00:00.940518\n",
      "556 0.7600005134940148 0:00:00.830491\n",
      "557 0.7752407744526864 0:00:00.726443\n",
      "558 0.9720998615026474 0:00:00.725923\n",
      "559 1.0366927325725555 0:00:00.727283\n",
      "560 0.8275423675775528 0:00:00.729762\n",
      "561 0.7818408578634262 0:00:01.018106\n",
      "562 0.7800744563341141 0:00:00.753717\n",
      "563 0.709506955742836 0:00:00.856918\n",
      "564 0.6740935668349266 0:00:01.061893\n",
      "565 0.6303717598319054 0:00:00.848292\n",
      "566 0.6196382090449333 0:00:00.955432\n",
      "567 0.6072209909558296 0:00:00.730540\n",
      "568 0.600997643172741 0:00:00.713770\n",
      "569 0.5904893130064011 0:00:00.705353\n",
      "570 0.5911050632596015 0:00:00.707773\n",
      "571 0.6213243499398231 0:00:00.742707\n",
      "572 0.6428403377532959 0:00:00.743310\n",
      "573 0.6814883038401603 0:00:00.721721\n",
      "574 0.744061341881752 0:00:00.711107\n",
      "575 0.7270801201462745 0:00:00.704552\n",
      "576 0.6588507577776909 0:00:00.909837\n",
      "577 0.7064967200160026 0:00:00.693815\n",
      "578 0.8182190597057343 0:00:00.895168\n",
      "579 0.7923389226198196 0:00:00.966174\n",
      "580 0.8859349325299263 0:00:00.745396\n",
      "581 0.8861824080348015 0:00:00.715713\n",
      "582 0.7485640212893486 0:00:00.705599\n",
      "583 0.6554060488939285 0:00:00.721296\n",
      "584 0.6370485588908196 0:00:00.722337\n",
      "585 0.6169161006808281 0:00:00.707865\n",
      "586 0.6239784091711045 0:00:00.896629\n",
      "587 0.5969492599368096 0:00:00.724903\n",
      "588 0.5995491504669189 0:00:00.716073\n",
      "589 0.6021576732397079 0:00:00.717901\n",
      "590 0.593243983387947 0:00:00.691314\n",
      "591 0.620595683157444 0:00:00.711382\n",
      "592 0.5988078862428665 0:00:00.716927\n",
      "593 0.597702631354332 0:00:00.709049\n",
      "594 0.580235455930233 0:00:00.961979\n",
      "595 0.5934241771697998 0:00:00.925872\n",
      "596 0.5662467285990715 0:00:00.851571\n",
      "597 0.5622716009616852 0:00:01.058712\n",
      "598 0.5431371390819549 0:00:01.128908\n",
      "599 0.5414065524935723 0:00:00.874227\n",
      "600 0.6427828148007393 0:00:00.707112\n",
      "601 0.6872293427586555 0:00:00.712625\n",
      "602 0.6971637099981308 0:00:00.684187\n",
      "603 0.814389756321907 0:00:00.712662\n",
      "604 0.8068542197346688 0:00:00.706433\n",
      "605 1.154440100491047 0:00:00.684603\n",
      "606 1.0739408031105995 0:00:00.694655\n",
      "607 0.9314712017774582 0:00:00.698992\n",
      "608 0.7430796802043915 0:00:00.692216\n",
      "609 0.637761415541172 0:00:00.683289\n",
      "610 0.588723661005497 0:00:00.695900\n",
      "611 0.5699922159314156 0:00:00.706985\n",
      "612 0.5800632566213608 0:00:00.683956\n",
      "613 0.5577592000365257 0:00:00.690502\n",
      "614 0.5361412197351456 0:00:00.698432\n",
      "615 0.5272452920675278 0:00:00.702387\n",
      "616 0.5160551100969315 0:00:00.711492\n",
      "617 0.5168191805481911 0:00:00.697507\n",
      "618 0.5333257809281349 0:00:00.702963\n",
      "619 0.5521829679608345 0:00:00.887046\n",
      "620 0.5367451071739197 0:00:00.786746\n",
      "621 0.520193237066269 0:00:00.930982\n",
      "622 0.5239966571331024 0:00:00.839367\n",
      "623 0.5430836051702499 0:00:00.844390\n",
      "624 0.5485949203372001 0:00:00.703235\n",
      "625 0.5399288639426232 0:00:00.709978\n",
      "626 0.5442551746964455 0:00:00.785930\n",
      "627 0.5940812140703201 0:00:00.780873\n",
      "628 0.6652740657329559 0:00:01.069756\n",
      "629 0.532869853079319 0:00:00.963991\n",
      "630 0.6554263815283775 0:00:00.916455\n",
      "631 0.7048184588551522 0:00:00.750585\n",
      "632 0.7372981786727906 0:00:00.897437\n",
      "633 0.8127762332558632 0:00:00.729295\n",
      "634 0.6914687648415565 0:00:00.705334\n",
      "635 0.5890316292643547 0:00:00.710879\n",
      "636 0.6265060007572174 0:00:00.747535\n",
      "637 0.548582923412323 0:00:00.893579\n",
      "638 0.5383255332708359 0:00:00.966097\n",
      "639 0.5163835629820823 0:00:00.798309\n",
      "640 0.5010683745145798 0:00:00.786978\n",
      "641 0.47657292038202287 0:00:00.806962\n",
      "642 0.47307301610708236 0:00:00.716928\n",
      "643 0.487430477142334 0:00:00.731525\n",
      "644 0.49313820600509645 0:00:00.896709\n",
      "645 0.4868429318070412 0:00:00.978024\n",
      "646 0.47538401037454603 0:00:00.743042\n",
      "647 0.4556969583034515 0:00:00.967635\n",
      "648 0.45396270751953127 0:00:00.780966\n",
      "649 0.465690141171217 0:00:01.207000\n",
      "650 0.4690179869532585 0:00:01.411497\n",
      "651 0.5524110183119774 0:00:01.587912\n",
      "652 0.5735689669847488 0:00:01.570257\n",
      "653 0.527855285257101 0:00:01.581038\n",
      "654 0.6973997443914414 0:00:01.439248\n",
      "655 0.9504657059907913 0:00:01.346010\n",
      "656 0.7257725030183793 0:00:01.226260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657 1.0150231659412383 0:00:00.780712\n",
      "658 0.7752289324998856 0:00:00.720085\n",
      "659 0.6142098173499108 0:00:00.759845\n",
      "660 0.5165953516960144 0:00:00.727643\n",
      "661 0.4936615154147148 0:00:00.707619\n",
      "662 0.48328702449798583 0:00:00.782532\n",
      "663 0.47624870836734773 0:00:00.700687\n",
      "664 0.49929879009723666 0:00:00.710908\n",
      "665 0.523410652577877 0:00:00.863256\n",
      "666 0.48180323988199236 0:00:00.779560\n",
      "667 0.46313569098711016 0:00:00.703986\n",
      "668 0.4629408873617649 0:00:00.733397\n",
      "669 0.46669414564967154 0:00:00.949013\n",
      "670 0.4904399193823338 0:00:00.868254\n",
      "671 0.5053203001618385 0:00:00.758890\n",
      "672 0.463238275796175 0:00:00.741389\n",
      "673 0.445883359760046 0:00:00.734301\n",
      "674 0.44711619466543195 0:00:00.727952\n",
      "675 0.4515214301645756 0:00:00.737998\n",
      "676 0.4765765093266964 0:00:00.744247\n",
      "677 0.4975936278700829 0:00:00.769562\n",
      "678 0.4580070324242115 0:00:00.777716\n",
      "679 0.4418560765683651 0:00:00.757971\n",
      "680 0.4320571176707745 0:00:00.743722\n",
      "681 0.4263884149491787 0:00:00.746485\n",
      "682 0.4565063163638115 0:00:00.777308\n",
      "683 0.49429404363036156 0:00:00.694809\n",
      "684 0.4631742961704731 0:00:00.907233\n",
      "685 0.44461026340723037 0:00:00.831349\n",
      "686 0.4175356350839138 0:00:00.851078\n",
      "687 0.398979514837265 0:00:00.772293\n",
      "688 0.42578529119491576 0:00:00.698032\n",
      "689 0.47325400859117506 0:00:00.855488\n",
      "690 0.45301591902971267 0:00:00.933685\n",
      "691 0.43574676364660264 0:00:00.765885\n",
      "692 0.40708530992269515 0:00:00.865914\n",
      "693 0.3871876858174801 0:00:00.919726\n",
      "694 0.4218979112803936 0:00:00.773446\n",
      "695 0.5030402392148972 0:00:00.805133\n",
      "696 0.5231525734066963 0:00:00.773437\n",
      "697 0.6511282704770565 0:00:00.756689\n",
      "698 0.8688946545124054 0:00:00.746337\n",
      "699 1.0894671335816384 0:00:00.716480\n",
      "700 0.6794862553477288 0:00:00.843054\n",
      "701 0.6778671026229859 0:00:00.850477\n",
      "702 0.5567398443818092 0:00:00.816978\n",
      "703 0.5103089861571789 0:00:00.746513\n",
      "704 0.44182160422205924 0:00:00.730645\n",
      "705 0.4189627066254616 0:00:00.730476\n",
      "706 0.402453488856554 0:00:00.713667\n",
      "707 0.39552832767367363 0:00:00.878187\n",
      "708 0.3921555198729038 0:00:00.821545\n",
      "709 0.3988745778799057 0:00:00.784670\n",
      "710 0.4113662846386433 0:00:00.700280\n",
      "711 0.42512371838092805 0:00:00.709415\n",
      "712 0.4041360840201378 0:00:00.722650\n",
      "713 0.41932971924543383 0:00:00.720100\n",
      "714 0.548831059038639 0:00:00.699168\n",
      "715 0.5033996015787124 0:00:00.733976\n",
      "716 0.44403405785560607 0:00:00.697011\n",
      "717 0.39850417971611024 0:00:00.743144\n",
      "718 0.40663201212882993 0:00:00.730378\n",
      "719 0.4168657086789608 0:00:00.746122\n",
      "720 0.4283426724374294 0:00:00.734153\n",
      "721 0.4550959520041943 0:00:00.793327\n",
      "722 0.39283169955015185 0:00:00.736515\n",
      "723 0.3867804929614067 0:00:01.008364\n",
      "724 0.36438497677445414 0:00:00.747447\n",
      "725 0.3705740079283714 0:00:00.802292\n",
      "726 0.3956514813005924 0:00:00.804378\n",
      "727 0.4189158737659454 0:00:00.824539\n",
      "728 0.4747751474380493 0:00:00.819064\n",
      "729 0.4828098364174366 0:00:01.010255\n",
      "730 0.5513458728790284 0:00:00.999110\n",
      "731 0.7628011494874954 0:00:00.924519\n",
      "732 0.668599882721901 0:00:00.805951\n",
      "733 0.5854360014200211 0:00:00.874744\n",
      "734 0.600582679361105 0:00:00.714151\n",
      "735 0.7105220064520836 0:00:00.714262\n",
      "736 0.5839180521667003 0:00:00.769130\n",
      "737 0.4579675458371639 0:00:00.753939\n",
      "738 0.37856304496526716 0:00:00.726075\n",
      "739 0.3650209650397301 0:00:00.738100\n",
      "740 0.3579741843044758 0:00:00.724487\n",
      "741 0.35389056280255315 0:00:00.737176\n",
      "742 0.35326005816459655 0:00:00.791079\n",
      "743 0.36318312883377074 0:00:00.723668\n",
      "744 0.3854866839945316 0:00:00.707321\n",
      "745 0.41613235175609586 0:00:00.776522\n",
      "746 0.4002662181854248 0:00:00.766790\n",
      "747 0.37545692175626755 0:00:00.795351\n",
      "748 0.36023701131343844 0:00:00.704711\n",
      "749 0.35328751876950265 0:00:00.845778\n",
      "750 0.34413046538829806 0:00:00.716801\n",
      "751 0.35936534479260446 0:00:00.689161\n",
      "752 0.3954770311713219 0:00:00.736874\n",
      "753 0.4406424328684807 0:00:00.737611\n",
      "754 0.44306446239352226 0:00:00.697420\n",
      "755 0.3641838185489178 0:00:00.697473\n",
      "756 0.34052721709012984 0:00:00.689071\n",
      "757 0.32861060202121734 0:00:00.774992\n",
      "758 0.33233166113495827 0:00:00.755670\n",
      "759 0.3520584873855114 0:00:00.731103\n",
      "760 0.4041172653436661 0:00:00.704491\n",
      "761 0.39457484856247904 0:00:00.694833\n",
      "762 0.3854244202375412 0:00:00.727904\n",
      "763 0.3546040341258049 0:00:00.706352\n",
      "764 0.34918484538793565 0:00:00.935285\n",
      "765 0.3646263837814331 0:00:00.737370\n",
      "766 0.39236472845077514 0:00:00.698369\n",
      "767 0.34242923781275747 0:00:00.688166\n",
      "768 0.33834452405571935 0:00:00.887770\n",
      "769 0.33111315593123436 0:00:00.701603\n",
      "770 0.326805454492569 0:00:00.695298\n",
      "771 0.3181538335978985 0:00:00.728641\n",
      "772 0.32460579052567484 0:00:00.699868\n",
      "773 0.3173536717891693 0:00:00.855679\n",
      "774 0.32506152987480164 0:00:00.902317\n",
      "775 0.3215407207608223 0:00:00.844743\n",
      "776 0.3342994928359985 0:00:00.754804\n",
      "777 0.32238482162356374 0:00:00.725667\n",
      "778 0.33096169754862786 0:00:00.690511\n",
      "779 0.31903347447514535 0:00:00.695620\n",
      "780 0.32421859055757524 0:00:00.687157\n",
      "781 0.31061108559370043 0:00:00.724282\n",
      "782 0.31183414310216906 0:00:00.727353\n",
      "783 0.30123254284262657 0:00:00.714747\n",
      "784 0.30069006234407425 0:00:00.746093\n",
      "785 0.29745412468910215 0:00:00.722716\n",
      "786 0.30642104968428613 0:00:00.841756\n",
      "787 0.30960171595215796 0:00:00.696281\n",
      "788 0.33346554860472677 0:00:00.689433\n",
      "789 0.31657145395874975 0:00:00.698327\n",
      "790 0.3119493663311005 0:00:00.689256\n",
      "791 0.3082362972199917 0:00:00.683213\n",
      "792 0.3277485080063343 0:00:00.715104\n",
      "793 0.3237806402146816 0:00:00.697435\n",
      "794 0.3482112795114517 0:00:00.689045\n",
      "795 0.32382134795188905 0:00:00.693790\n",
      "796 0.308314448595047 0:00:00.696580\n",
      "797 0.2931360527873039 0:00:00.684494\n",
      "798 0.2827019453048706 0:00:00.739329\n",
      "799 0.28132888972759246 0:00:00.721712\n",
      "800 0.2881178714334965 0:00:00.724341\n",
      "801 0.29297531247138975 0:00:00.685938\n",
      "802 0.31839380264282224 0:00:00.713803\n",
      "803 0.3110650010406971 0:00:00.800160\n",
      "804 0.32588169947266576 0:00:00.684216\n",
      "805 0.3266354039311409 0:00:00.693700\n",
      "806 0.898896449804306 0:00:00.697043\n",
      "807 1.4579291395843028 0:00:00.782757\n",
      "808 1.1264671862125397 0:00:00.693020\n",
      "809 0.6960570439696312 0:00:00.699992\n",
      "810 0.4759763732552528 0:00:00.692266\n",
      "811 0.4710267648100853 0:00:00.693693\n",
      "812 0.506373293697834 0:00:00.690457\n",
      "813 0.3999605178833008 0:00:00.712218\n",
      "814 0.3605110675096512 0:00:00.694598\n",
      "815 0.3329863831400871 0:00:00.729898\n",
      "816 0.32240654304623606 0:00:00.746089\n",
      "817 0.30981102138757705 0:00:00.747591\n",
      "818 0.301569127291441 0:00:00.700011\n",
      "819 0.30703710988163946 0:00:00.700279\n",
      "820 0.348894064873457 0:00:00.696388\n",
      "821 0.4458426870405674 0:00:00.694070\n",
      "822 0.5324329897761345 0:00:00.686515\n",
      "823 0.7593986243009567 0:00:00.696857\n",
      "824 0.6491702020168304 0:00:00.691211\n",
      "825 0.5878161326050758 0:00:00.690758\n",
      "826 0.5008356928825378 0:00:00.691514\n",
      "827 0.35527913793921473 0:00:00.693581\n",
      "828 0.34936665520071986 0:00:00.720591\n",
      "829 0.4182402528822422 0:00:00.707332\n",
      "830 0.4233441673219204 0:00:00.699390\n",
      "831 0.38638258129358294 0:00:00.680323\n",
      "832 0.31586266681551933 0:00:00.686974\n",
      "833 0.3066119194030762 0:00:00.693448\n",
      "834 0.2978240422904491 0:00:00.684735\n",
      "835 0.2973112270236015 0:00:00.686688\n",
      "836 0.3015309914946556 0:00:00.696097\n",
      "837 0.31577919125556947 0:00:00.700773\n",
      "838 0.3008582666516304 0:00:00.686496\n",
      "839 0.30663450062274933 0:00:00.806502\n",
      "840 0.2885477527976036 0:00:00.793770\n",
      "841 0.29144231751561167 0:00:00.824366\n",
      "842 0.27925479114055635 0:00:00.751564\n",
      "843 0.2804666325449944 0:00:00.814963\n",
      "844 0.27787618041038514 0:00:00.888733\n",
      "845 0.28911468759179115 0:00:00.717525\n",
      "846 0.28698019981384276 0:00:00.693928\n",
      "847 0.30513023808598516 0:00:00.696375\n",
      "848 0.29613055661320686 0:00:00.687467\n",
      "849 0.3157520979642868 0:00:00.689836\n",
      "850 0.2976940728724003 0:00:00.686287\n",
      "851 0.29944647252559664 0:00:00.689227\n",
      "852 0.28325073048472404 0:00:00.701771\n",
      "853 0.2731902748346329 0:00:00.826672\n",
      "854 0.2550414949655533 0:00:00.803984\n",
      "855 0.25182698145508764 0:00:00.814628\n",
      "856 0.2482993170619011 0:00:00.835880\n",
      "857 0.24865997433662415 0:00:00.812519\n",
      "858 0.2585496686398983 0:00:00.857571\n",
      "859 0.28454050719738005 0:00:00.832447\n",
      "860 0.2782076969742775 0:00:00.811710\n",
      "861 0.30557344406843184 0:00:00.892504\n",
      "862 0.3970026969909668 0:00:00.685507\n",
      "863 0.3510348252952099 0:00:00.704568\n",
      "864 0.31497897729277613 0:00:00.705654\n",
      "865 0.258746013045311 0:00:00.685327\n",
      "866 0.2494952365756035 0:00:00.687628\n",
      "867 0.24435639530420303 0:00:00.688102\n",
      "868 0.24826755970716477 0:00:00.704742\n",
      "869 0.2850050337612629 0:00:00.804277\n",
      "870 0.3676792629063129 0:00:00.703680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "871 0.3428748816251755 0:00:00.693933\n",
      "872 0.260110042989254 0:00:00.700558\n",
      "873 0.2401429146528244 0:00:00.693187\n",
      "874 0.24823044538497924 0:00:00.691909\n",
      "875 0.24212183207273483 0:00:00.717113\n",
      "876 0.2406304657459259 0:00:00.689738\n",
      "877 0.2381725236773491 0:00:00.676821\n",
      "878 0.26064779609441757 0:00:00.695886\n",
      "879 0.34733943194150924 0:00:00.700260\n",
      "880 0.5136924877762794 0:00:00.696128\n",
      "881 0.625143188983202 0:00:00.684882\n",
      "882 1.179466849565506 0:00:00.799938\n",
      "883 0.837688498198986 0:00:00.767507\n",
      "884 0.5144072525203228 0:00:00.730719\n",
      "885 0.43551072403788565 0:00:00.683790\n",
      "886 0.3906442128121853 0:00:00.690841\n",
      "887 0.28932941779494287 0:00:00.684100\n",
      "888 0.26951806917786597 0:00:00.682268\n",
      "889 0.25986953601241114 0:00:00.726355\n",
      "890 0.2534873940050602 0:00:00.792799\n",
      "891 0.24872235357761383 0:00:00.718568\n",
      "892 0.24413080960512162 0:00:00.693718\n",
      "893 0.2407438725233078 0:00:00.714592\n",
      "894 0.2373521387577057 0:00:00.690258\n",
      "895 0.23569355905056 0:00:00.685172\n",
      "896 0.23413362205028534 0:00:00.691132\n",
      "897 0.2374676525592804 0:00:00.738755\n",
      "898 0.2576315142214298 0:00:00.793821\n",
      "899 0.4319704778492451 0:00:00.735445\n",
      "900 1.0123840242624282 0:00:00.708788\n",
      "901 0.49137125015258787 0:00:00.792896\n",
      "902 0.4706132784485817 0:00:00.731291\n",
      "903 0.38678907603025436 0:00:00.747860\n",
      "904 0.30649093762040136 0:00:00.719164\n",
      "905 0.2684104390442371 0:00:00.720381\n",
      "906 0.2619361042976379 0:00:00.713984\n",
      "907 0.255392450094223 0:00:00.783046\n",
      "908 0.2477019712328911 0:00:00.735412\n",
      "909 0.24241440743207932 0:00:00.716124\n",
      "910 0.23722922280430794 0:00:00.849639\n",
      "911 0.2336933806538582 0:00:00.740649\n",
      "912 0.23141958564519882 0:00:00.695778\n",
      "913 0.2309925876557827 0:00:00.696626\n",
      "914 0.2324530839920044 0:00:00.697423\n",
      "915 0.24712016955018043 0:00:00.698369\n",
      "916 0.35250447914004324 0:00:00.699225\n",
      "917 0.6198134459555149 0:00:00.693952\n",
      "918 0.42373990193009375 0:00:00.716986\n",
      "919 0.5192712433636189 0:00:00.692913\n",
      "920 0.31943655759096146 0:00:00.695098\n",
      "921 0.26298997849225997 0:00:00.690079\n",
      "922 0.2822953961789608 0:00:00.716067\n",
      "923 0.28029912412166597 0:00:00.716159\n",
      "924 0.29732041582465174 0:00:00.692898\n",
      "925 0.35534966364502907 0:00:00.703625\n",
      "926 0.245089865475893 0:00:00.690422\n",
      "927 0.22776468545198442 0:00:00.693809\n",
      "928 0.2242195188999176 0:00:00.690946\n",
      "929 0.22250143215060234 0:00:00.694820\n",
      "930 0.22104357331991195 0:00:00.691844\n",
      "931 0.22043599039316178 0:00:00.725306\n",
      "932 0.2214444763958454 0:00:00.710838\n",
      "933 0.23388525024056434 0:00:00.699653\n",
      "934 0.3758697047829628 0:00:00.697413\n",
      "935 0.460411462187767 0:00:00.716326\n",
      "936 0.2631084553897381 0:00:00.704515\n",
      "937 0.23967705592513083 0:00:00.690818\n",
      "938 0.23860008344054223 0:00:00.684893\n",
      "939 0.2834452085196972 0:00:00.690232\n",
      "940 0.31369924917817116 0:00:00.685554\n",
      "941 0.32153392881155013 0:00:00.747098\n",
      "942 0.23630423098802567 0:00:00.767058\n",
      "943 0.21854015588760375 0:00:00.698943\n",
      "944 0.21378777623176576 0:00:00.741522\n",
      "945 0.21085529029369354 0:00:00.787757\n",
      "946 0.2082417353987694 0:00:00.770553\n",
      "947 0.20640462040901184 0:00:00.770201\n",
      "948 0.2046012192964554 0:00:00.739639\n",
      "949 0.20291852876543998 0:00:00.713177\n",
      "950 0.20149537697434425 0:00:00.709700\n",
      "951 0.20009654462337495 0:00:00.810046\n",
      "952 0.1989239476621151 0:00:00.850726\n",
      "953 0.19778750985860824 0:00:00.694372\n",
      "954 0.19666156843304633 0:00:00.711630\n",
      "955 0.19554352909326553 0:00:00.789669\n",
      "956 0.19445025697350501 0:00:00.873940\n",
      "957 0.19346268996596336 0:00:00.851716\n",
      "958 0.19255366101861 0:00:00.829615\n",
      "959 0.1916058652102947 0:00:00.754965\n",
      "960 0.19063400775194167 0:00:00.946528\n",
      "961 0.1898353450000286 0:00:00.721217\n",
      "962 0.18898448050022126 0:00:00.856908\n",
      "963 0.18821042478084565 0:00:00.851524\n",
      "964 0.18729711100459098 0:00:00.899505\n",
      "965 0.1865115538239479 0:00:00.917001\n",
      "966 0.18585804626345634 0:00:00.989787\n",
      "967 0.1852695994079113 0:00:00.731644\n",
      "968 0.18456538990139962 0:00:00.730127\n",
      "969 0.1843298502266407 0:00:00.737579\n",
      "970 0.18423059955239296 0:00:00.777325\n",
      "971 0.1853948213160038 0:00:00.786976\n",
      "972 0.19197260364890098 0:00:00.741709\n",
      "973 0.28403049111366274 0:00:00.748095\n",
      "974 0.4744697600603104 0:00:00.747318\n",
      "975 0.4578721024096012 0:00:00.767795\n",
      "976 0.27164526656270027 0:00:00.753679\n",
      "977 0.29993117302656175 0:00:00.761723\n",
      "978 0.4005076982080936 0:00:00.784170\n",
      "979 0.3275816082954407 0:00:00.752786\n",
      "980 0.21097340807318687 0:00:00.842527\n",
      "981 0.19946074336767197 0:00:00.781090\n",
      "982 0.1950089991092682 0:00:00.718753\n",
      "983 0.19146880581974984 0:00:00.727838\n",
      "984 0.18904654011130334 0:00:00.688566\n",
      "985 0.18716811165213584 0:00:00.694962\n",
      "986 0.18534919396042823 0:00:00.681312\n",
      "987 0.1839060254395008 0:00:00.698771\n",
      "988 0.18261146321892738 0:00:00.705011\n",
      "989 0.18140935897827148 0:00:00.697729\n",
      "990 0.18038611561059953 0:00:00.693841\n",
      "991 0.17938100770115853 0:00:00.726581\n",
      "992 0.17853527888655663 0:00:00.839594\n",
      "993 0.1775469958782196 0:00:00.792788\n",
      "994 0.17672290056943893 0:00:00.685687\n",
      "995 0.17605061158537866 0:00:00.681288\n",
      "996 0.17523230910301207 0:00:00.698401\n",
      "997 0.17460021302103995 0:00:00.718707\n",
      "998 0.17374653592705727 0:00:00.692032\n",
      "999 0.17312229350209235 0:00:00.688415\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xd4HOXV8OHfUe+SZclyt9x7A2Ns\nWkwxMZ0QCC2QAAmkvKEkeQnwpsAXEkiFACEECKGGXkIx1bhgg3vvvRfJRb1L5/tjZlerVVvJWq2k\nPfd16fLuzOzMMzvrOfN0UVWMMcaEr4hQJ8AYY0xoWSAwxpgwZ4HAGGPCnAUCY4wJcxYIjDEmzFkg\nMMaYMGeBoI2IiIrIkFZ+9nQR2dTWaQrguMNFZIWIFIrIrQF+ptXn6befbHdfUce7r45KRLJEZJ77\n/f6lnY9dJCKD2vmY8SLynojki8jrAX5mjoh8r42Ov05EprXFvlp5/P7u9x4ZqjS0VtgFAhHZKSKl\n7gXz/D3WzmmoczNV1S9UdXh7psF1JzBHVZNV9RH/lW35nzRM3QwcBlJU9WfBOkhD10lVk1R1e7CO\n2YjLgSygu6pe4b9SRO4VkReDdXBVHa2qc9rjWO4xdorIOT7H3+1+79XBPG4wdNmnsWZcpKqfhToR\nHcAA4JVQJ6ILGwCs1/DptTkA2KyqVaFOyPESkaiucB4BU9Ww+gN2Auc0sDwWyAPG+CzLBEqBHu77\n7wNbgaPAu0Bvn20VGOK+ngN8z2fdd4H57ut57rbFQBFwJTAN2Ouz/Uh3H3nAOuBin3XPAn8HPgAK\ngUXA4CbO92J3H3nuPke6yz8HqoEyNx3D/D73O7/1j/mc5w+ALcAxNy3i87kbgQ3uuo+BAY2kK9vd\nV5T7vrf7nR51v+Pv+2w7GVgKFACHgL+6y+OAF4Ej7vktAbIaOd5dwDb3O1sPfMNn3RBgLpCP8wT/\nahPf5+vAQXfbecDoRrZ7FqgEKtzv7xx32f0+2/hf953Az4HV7v5fBeJ81l8CrHS/h23AjGauk+f3\nmAo8D+QCu4BfAhG+v03gz+412wGc18T5N/jbBO5zz7XSTcdNfp+b4bd+lc//ld8CC9xr8wmQ4fO5\nKcCX7vFWAdOa+7/dxLFSgX8BB4B9wP1ApM/3sAB4COc3eD8wGOf/yRH3d/ESkOZu/wJQg3N/KMLJ\nXWcT+G/6XuA197oUut/lpJDdF0N14JCdcCOBwF33DPA7n/c/Bj5yX5/l/hhOwAkajwLzfLYNKBD4\nb+u+n4Z7QwCi3R/NPUCMe9xCYLi7/ln3hzUZJ0f3EvBKI+czDCfgTHf3e6e775iG0tnA5+utd9P+\nPpAG9Me5ucxw113q7n+km7ZfAl82sm///zRzgcdxbu4T3P2e7a77CrjOfZ0ETHFf3wK8ByQAkcCJ\nOMUwDR3vCvc/ZgRO8C0GernrXgb+z10XB5zWxHdyI5Ds/gYeBlY2se2z1L3x+7/3Xnef3+ZiN53p\nOAH1B+66yTjBYbqbzj7AiGauk+f3+DzwXzfd2cBm3Bs1zm+zEuchJxL4IbAfn+Dus8/mfpv3Ai82\n8X3UW++mfRvObzXeff+gu64Pzk34fPecp7vvM5v7v93Isd4B/gkkAj3c7/oWn++hCvgJzm83HucB\nYbp7rTNxAv/Djd1LaNlv+l6c4H2++70/ACwM1n2vub+wqyNwvSMieT5/33eX/we42me7a9xlANcC\nz6jqclUtB+4GpopIdhunbQrOze5BVa1Q1c9xbry+6XpLVRerk3V9CedH1pArgQ9U9VNVrcR56osH\nTjnOND6oqnmquhuY7XP8W4AHVHWDm7bfAxNEZEBTOxORfsBpwC9UtUxVVwJPA9e5m1QCQ0QkQ1WL\nVHWhz/LuODe8alVdpqoFDR1DVV9X1f2qWqOqr+LkaCb77GcATg6vTFXnN5ZWVX1GVQvd38C9wHgR\nSW3q/FroETedR3GCnOe7vQnn9/epew77VHVjcztzKy6vBO52070T+Au13y3ALlV9Sp2y7eeAXjhl\n/f4C+W22xr9VdbOqluI8JXvO+dvATFWd6Z7zpzg5w/NbegARyQLOA25X1WJVzcF5+r/KZ7P9qvqo\nqlapaqmqbnW/73JVzQX+CnwtwOM195sG5+Fwpvu9vwCMb+l5tZVwDQSXqmqaz99T7vLPgXgROdm9\neU0A3nbX9cbJVgOgqkU4Tyd92jhtvYE9qlrjs2yX33EO+rwuwfnP2di+fNNcA+zh+NPc2PEHAH/z\nBFicnIsEcLzewFFVLfRZ5nvON+E8MW4UkSUicqG7/AWc4qdXRGS/iPxRRKIbOoCIXC8iK33SNgbI\ncFff6aZzsdvy5MZG9hEpIg+KyDYRKcB5IsRnP22hse+2H86Tc0tl4Dy97/JZ1ujvSVVL3JcN/aYC\n+W22RlO/pyt8H9pwbq69WnGMATg5mgM++/onTs7AY4/vB0Skh4i8IiL73Ov9IoFf6+Z+01D/vONC\n1YouXCuLG6SqNSLyGs4TziHgfZ8LuR/nxwSAiCTiPI3ua2BXxTjFFR49W5CM/UA/EYnw+Q/XHyc7\n31L7gbGeNyIiODeUhtLckJZWcu7BKVp7qYWf2w+ki0iyz/fdHzedqroFuFpEIoDLgDdEpLuqFuOU\nTd/n5sxmAptwyoG93KD+FHA28JWqVovISpybP6p6EKdoBBE5DfhMROap6la/dF6DU05/Dk4QSMUp\nV5cAz/N4fhd7cMqsG9LUdTpMbY5nvbvM+9220PH+Nlvze3pBVb/f7JbNH2sPUI5T/9BYJbD/Zx5w\nl41T1SMicinwWBPb+2ryN93RhGuOoCn/wclKX0ttsZBn+Q0iMkFEYnGKPRa5WW1/K4HLRCTBbSZ6\nk9/6Q0BjbbwX4dww7hSRaLdd9EW0rnXPa8AFInK2+6T8M5z/DF8G+Pmm0tmQJ4C7RWQ0gIikiki9\nZoT+VHWPm6YHRCRORMbhfGcvufv5tohkujefPPdj1SJypoiMdYs/CnBueA013UvE+U+b6+7vBpwc\nAe77K0Skr/v2mLttQ/tJxvn+juDc0H/f3Ln5WQmcLyLpItITuL0Fn/0Xzu/vbBGJEJE+IjLCXdfo\ndXKLHV4DficiyW5Q/CnO021LHe9v8xCQ7Qb0QLwIXCQiX3dzY3EiMs3nWgV8LFU9gFMR/RcRSXG/\nw8Ei0lRRTzJORXCeiPQB/reBYzT2vTf5m+5owjUQvOfXj8BT/IOqen7svYEPfZbPAn4FvInT6mAw\ndcsXfT2E02rhEE6Zq//Fvxd4zs2ifst3hapW4LT0OQ/nae5x4PpAyoP9qeomnHLWR919XYTTdLYi\nwF38DbhcRI6JSL1+Bg0c723gDzhFNQXAWvc8AnE1TmXbfpziuN+4ZcLgtAJZJyJFbpquUtUynCfq\nN3CCwAacyrl6NzhVXY9TLv4VzjUZi9NCxOMkYJG7/3eB21R1RwNpfB4ne78P5+l6YQPbNOUFnJYv\nO3FuSq8G+kFVXQzcgPPbysc5V08Otbnr9BOc3/R2nBZC/8FpGNEibfDb9HQyOyIiywM43h6cHNg9\nOEF8D87NOJD7VkPHuh6nmGw9TsB/g6aLme7DaRySj9NK7y2/9Q8Av3T/H/+8gc839ZvuUEQ1XJo4\nG2OMaUi45giMMca4LBAYY0yYs0BgjDFhzgKBMcaEuU7RjyAjI0Ozs7NDnQxjjOlUli1bdlhVM5vb\nrlMEguzsbJYuXRrqZBhjTKciIrua38qKhowxJuxZIDDGmDBngcAYY8KcBQJjjAlzFgiMMSbMWSAw\nxpgwZ4HAGGPCXJcOBDPXHOCdFR1yHghjjOkwOkWHstZQVV5fuofZm3JZuP0Iv7loNPExkaFOljHG\ndDhdNkcgIjx1/SR+NG0wryzZw6V/X8DWnMLmP2iMMWGmywYCgKjICO6cMYLnbpzM4aJyLnp0AR+s\nPhDqZBljTIfSpQOBx9eGZTLzttMZ2SuZH/9nOX/6eCM1NTYzmzHGQJgEAoCslDhevnkKV53Uj7/P\n3sadb66m2oKBMcZ03crihsRGRfLAZWPJSonjb7O2IMAfLx+HiIQ6acYYEzJhFQjAqUS+Y/owVJVH\nPt/K0Kwkbj5jcKiTZYwxIRM2RUP+7pg+jPPH9uTBDzeydl9+qJNjjDEhE7aBQER44LJxdE+K5Rdv\nrqaquibUSTLGmJAI20AAkBofzb0XjWbd/gLeWLY31MkxxpiQCOtAAHD+2J6M75vKo59vpaLKcgXG\nmPAT9oHAU3m8L6+U15ftCXVyjDGm3QU9EIhIpIisEJH33fcDRWSRiGwRkVdFJCbYaWjO14ZlckL/\nNB6dtZXSiupQJ8cYY9pVe+QIbgM2+Lz/A/CQqg4FjgE3tUMamiQi/GLGCA4WlPGv+dtDnRxjjGlX\nQQ0EItIXuAB42n0vwFnAG+4mzwGXBjMNgTp5UHfOG9OTv83awqwNh0KdHGOMaTfBzhE8DNwJeGph\nuwN5qlrlvt8L9GnogyJys4gsFZGlubm5QU6m44HLxjKiZwrfe34pt7+ygp2Hi9vluMYYE0pBCwQi\nciGQo6rLfBc3sGmDA/6o6pOqOklVJ2VmZgYljf7SEmJ47Zap3HLGYD5ce5Az/zKH7/57MZ+tP0Sl\n9TMwxnRRwRxi4lTgYhE5H4gDUnByCGkiEuXmCvoC+4OYhhaLj4nkrvNGcOOp2by0aDcvL97N955f\nSlpCNOeN6cmF43ozZVB3IiNsfCJjTNcgqsEfgVNEpgE/V9ULReR14E1VfUVEngBWq+rjTX1+0qRJ\nunTp0qCnsyGV1TXM2ZTL+6v389n6QxRXVJORFMN5Y3px4bhenJSdToQFBWNMByQiy1R1UnPbhWLQ\nuV8Ar4jI/cAK4F8hSEPAoiMjmD4qi+mjsiirrGb2xhzeX32A15ft4YWFu+iRHMv5Y3tx0fheTOzX\nzYKCMabTaZccwfEKZY6gMcXlVczamMP7q/YzZ3MuFVU1DMpI5LqpA/jmiX1JiYsOdRKNMWEu0ByB\nBYI2UFhWycfrDvHSol2s2J1HQkwk3z0lm1vOGExqggUEY0xoWCAIkdV783j6ix28t3o/SbFR/HT6\nMK6fmm2Vy8aYdhdoIAj7sYba2ri+aTxy9UQ+vO10Jvbvxn3vreeKJ75kW25RqJNmjDENskAQJCN6\npvDcDSfx0JXj2X64mEseW8An6w6GOlnGGFOPBYIgEhG+MbEvM289nUGZidz8wjKemmdjGRljOhYL\nBO2gd1o8r90ylQvG9uJ3Mzfw6KwtoU6SMcZ4hd3k9aESFx3J366aQGxUBH/5dDPxMZF87/RBoU6W\nMcZYIGhPUZER/PmK8ZRUVPO7mRvon57AuaN7hjpZxpgwZ0VD7SwiQnjoygmM65PKba+sZGtOYaiT\nZIwJcxYIQiA+JpKnrp9EfEwkP3l5JWWVNiuaMSZ0LBCESI+UOP58xTg2HCjgDx9tDHVyjDFhzAJB\nCJ01IovvTB3AvxfsZNmuY6FOjjEmTFkgCLE7Z4ygV2oc//f2Gpv8xhgTEhYIQiwxNop7Lx7NxoOF\nPDN/R6iTY4wJQxYIOoCvj+7J2SN68OjnWzlcVB7q5BhjwowFgg7ingtGUlpZzSPW69gY084sEHQQ\ngzOTuGZyf/6zaLeNVGqMaVcWCDqQ284ZSlx0JH/40JqTGmPajwWCDiQjKZabzxjEJ+sPsWZvfqiT\nY4wJExYIOpgbTs0mLSGahz7bHOqkGGPChAWCDiY5Lprvnz6IzzfmsHJPXqiTY4wJAxYIOqDvnJJN\nt4RoHvrUcgXGmOCzQNABJcVGccvXBjN3c64NPWGMCToLBB3U9VMH0D0xhoetrsAYE2QWCDqohJgo\nbj5jEF9sOczqvVZXYIwJHgsEHdg1J/cnOTaKf9qE98aYILJA0IElx0Vz7ZQBfLjmALuOFIc6OcaY\nLsoCQQd346nZREVE8NQXliswxgSHBYIOrkdKHJed0IfXl+61kUmNMUFhgaAT+P4ZgyivquHlRbtD\nnRRjTBdkgaATGJyZxKlDuvPKkj1U12iok2OM6WIsEHQS10wewL68UuZtyQ11UowxXYwFgk5i+qgs\nMpJi+I8VDxlj2pgFgk4iJiqCy0/sx+cbczhUUBbq5BhjuhALBJ3Ityb1pbpGeW/V/lAnxRjThVgg\n6EQGZSYxuncK760+EOqkGGO6EAsEncxF43uzak8eu4+UhDopxpguwgJBJ3PhuF4AvLfaioeMMW3D\nAkEn07dbAhP7p/HhWiseMsa0jaAFAhGJE5HFIrJKRNaJyH3u8oEiskhEtojIqyISE6w0dFXnjMxi\n7b4Caz1kjGkTwcwRlANnqep4YAIwQ0SmAH8AHlLVocAx4KYgpqFLOntkDwBmb8wJcUqMMV1B0AKB\nOorct9HunwJnAW+4y58DLg1WGrqq4VnJ9EmLZ5YFAmNMGwhqHYGIRIrISiAH+BTYBuSpapW7yV6g\nTyOfvVlElorI0txcG1bBl4hw1ogezN9ymLLK6lAnxxjTyQU1EKhqtapOAPoCk4GRDW3WyGefVNVJ\nqjopMzMzmMnslM4a0YPSymoW7Tga6qQYYzq5dmk1pKp5wBxgCpAmIlHuqr6AtYNshSmDuhMbFcGc\nTVY8ZIw5PsFsNZQpImnu63jgHGADMBu43N3sO8B/g5WGriw+JpIpg7ozd5MVmxljjk8wcwS9gNki\nshpYAnyqqu8DvwB+KiJbge7Av4KYhi5t2vBMth8utvmMjTHHJZithlar6kRVHaeqY1T1/7nLt6vq\nZFUdoqpXqKrNv9hK04Y7zUjnWK7AGHMcmg0EInKqiCS6r78tIn8VkQHBT5ppzsCMRAZ0T7B6AmPM\ncQkkR/APoERExgN3AruA54OaKhOwacMy+Wr7EWtGaoxptUACQZWqKnAJ8DdV/RuQHNxkmUBNG96D\nssoaa0ZqjGm1QAJBoYjcDXwb+EBEInF6CZsOYMqg7sRYM1JjzHEIJBBciTNu0E2qehCnJ/Cfgpoq\nEzBrRmqMOV4B5QhwioS+EJFhOAPIvRzcZJmWmDbMaUZqk9UYY1ojkEAwD4gVkT7ALOAG4NlgJsq0\nzLThzhAcczZb8ZAxpuUCCQSiqiXAZcCjqvoNYHRwk2VaYmBGIv3TE6w/gTGmVQIKBCIyFbgW+MBd\nFhm8JJmWEhGmDc/ky202GqkxpuUCCQS3A3cDb6vqOhEZhDNekOlApg3PpKyyhsXWjNQY00LNBgJV\nnauqFwOPi0iSO0TEre2QNtMCUwdlEBsVwawNh0KdFGNMJxPIEBNjRWQFsBZYLyLLRMTqCDqY+JhI\nvjYsk4/WHaSmpsEpHowxpkGBFA39E/ipqg5Q1f7Az4Cngpss0xrnj+3FoYJyVuw5FuqkGGM6kUAC\nQaKqeusEVHUOkBi0FJlWO2tkD2IiI5i55mCok2KM6UQCCQTbReRXIpLt/v0S2BHshJmWS4mL5vSh\nGXy09iDO8FDGGNO8QALBjUAm8Bbwtvv6hmAmyrTejDE92ZdXyuq9+aFOijGmk4hqbgNVPQZYK6FO\nYvqoLKIihJlrDzC+X1qok2OM6QQaDQQi8h7QaPmC26TUdDBpCTGcMiSDmWsOcNeMEYhIqJNkjOng\nmsoR/LndUmHa1IVje3Hnm6tZuSePif27hTo5xpgOrtFAoKpz2zMhpu3MGNuTX/53Lf9dud8CgTGm\nWUGbvN6ETkpcNGeP6MH7q/dTVV0T6uQYYzo4CwRd1CUT+nC4qIIh//chn623YSeMMY0LOBCIiHUi\n60TOHJHpff3bD9aHMCXGmI4ukLGGThGR9cAG9/14EXk86CkzxyU2KpJbzhgEQI0qH609wL680hCn\nyhjTEQWSI3gI+DpwBEBVVwFnBDNRpm3cff5Ibj5jEHuOlvKDF5dz1ZNfhTpJxpgOKKCiIVXd47fI\nZj/pJC4Y28v7es9RyxEYY+prtmcxsEdETgFURGJwehlvCG6yTFsZ1zfV+zom0toGGGPqC+TO8APg\nx0AfYC8wwX1vOgER4eLxvQGoqK5h3mab19gYU1cgM5QdVtVrVTVLVXuo6rdV9Uh7JM60jT98c5z3\n9fXPLOZgflkIU2OM6WiaLRoSkUcaWJwPLFXV/7Z9kkxbi4+JZFzfVO+IpNP+PJuNvz0vxKkyxnQU\ngRQNxeEUB21x/8YB6cBNIvJwENNm2tDDV07wvi6rrGHXkeIQpsYY05EEEgiGAGep6qOq+ihwDjAS\n+AZwbjATZ9rOoMwk3v/Jad73VzzxFXe9uZqdhy0gGBPuAgkEfag7NWUi0FtVq4HyoKTKBMWYPqn8\n/ZoTAMgpLOeVJXv4xZurQ5wqY0yoBRII/gisFJF/i8izwArgz+6QE58FM3Gm7V0wrled9zajpTEm\nkFZD/wJOAd5x/05T1adVtVhV/zfYCTRt76nrJ3lfL955lE0HC0OYGmNMqAXaw6gMOAAcBYaIiA0x\n0YlNH5VFYkyk9/3XH54XwtQYY0ItkEHnvgfMAz4G7nP/vTe4yTLB9sR1J9Z5v+WQ5QqMCVeB5Ahu\nA04CdqnqmcBEwLqndnKnD81k9s+n0SctHoDpD83j4sfmU1ldQ1llNdtzi0KcQmNMewkkEJSpahmA\niMSq6kZgeHMfEpF+IjJbRDaIyDoRuc1dni4in4rIFvdfm0sxRAZmJPLmD0/xvl+9N5+P1x3k+mcW\nc9Zf5nK0uCKEqTPGtJdAAsFeEUnDqSj+VET+C+wP4HNVwM9UdSQwBfixiIwC7gJmqepQYJb73oRI\nz9Q4/vDNsd73//OfFSzecRSA/TZ/gTFhIZBWQ99Q1TxVvRf4FfAv4NIAPndAVZe7rwtxRiztA1wC\nPOdu9lwg+zLBdd7YXt4iIl+5RXW7iWzLLWLB1sPtlSxjTDtpMhCISISIrPW8V9W5qvquqraozEBE\nsnHqFhYBWap6wN3fAaBHSxNt2lZKXDQL7jqLmbeeXmf5Df9ewtNfbOdAfimV1TWc/Ze5XPv0ohCl\n0hgTLE0GAlWtAVaJSP/WHkBEkoA3gdtVtaAFn7tZRJaKyNLcXKubbg8jeyUzPCuZk7Jrq23u/2AD\nUx/4nH/O3eZdtuFAwJfRGNMJBFJH0AtYJyKzRORdz18gOxeRaJwg8JKqvuUuPiQivdz1vYCchj6r\nqk+q6iRVnZSZmdnQJqaNiQgf33EGr//glHrrtubUtiI6729ftGeyjDFBFsgMZfe1ZsciIjj1CRtU\n9a8+q94FvgM86P5rQ1l3Aslx0aFOgjEmSJoNBKo6V0QGAENV9TMRSQAim/sccCpwHbBGRFa6y+7B\nCQCvichNwG7gitYl3bSnvNJKEmIiKamw6aqN6WoC6Vn8feAN4J/uoj44TUmbpKrzVVVUdZyqTnD/\nZqrqEVU9W1WHuv8ePb5TMMHw6wtHAXDLGYMY0TOZvJIK0uJrcwV7jpaQV2L9DIzpCgIpGvoxMBmn\nxQ+qukVErKVPF3fjaQO58bSBAOw4XMwn6w/VWX/6H2eTlhDNyl/blBTGdHaBVBaX+zYXFZEowAYv\nDiN9uyU0uDyvpLKdU2KMCYZAAsFcEbkHiBeR6cDrwHvBTZbpSHqkxDa6bvamHKb/dS4VVTUAVFbX\ncP/76zlmw1MY02kEEgjuwhlkbg1wCzAT+GUwE2U6lovG9/a+HpyZWGfdDf9ewpacIv740UaW7z7G\nJ+sO8fT8Hdz/wYb2TqYxppUCqSO4BHheVZ8KdmJMx9QnLZ6dD16AqjJ3cy7f/feSets8PX8HT8/f\nwaNXTwSgvMpaFxnTWQSSI7gY2CwiL4jIBW4dgQlDItJofYFHhAgA23OLKSyzOgRjOoNABp27ARiC\nUzdwDbBNRJ4OdsJMxzQoI7HO7Gb+dh4pBmD9gQJ+9NLy9kqWMeY4BDRVpapWAh8CrwDLcIqLTBiK\niBD+8q0Jja7/08ebvK+/2HKYQwVl7ZEsY8xxCKRD2QwReRbYClwOPI0z/pAJU18fncUfLx/Hd0/J\nbnbb7bnFwU+QMea4BFLe/12cnMAtqlrezLYmDIgI35rUD4CJ/dO47ZWVjW5bVF7VXskyxrRSIHUE\nV6nqO54gICKnisjfg5800xlcMqFPk+tnb8rhr59sanIbY0xoBdQCSEQm4FQUfwvYAbzV9CdMOHnj\nB1OZtzmXEwZ08zYtFQFV+M+i3QBcPKEPQ3okhTKZxphGNJojEJFhIvJrEdkAPAbsAURVz1TVR9st\nhabDm5Sdzk/PHc7Uwd29y1b8anqdbc7561xUlbLKap6Zv4OySutnYExH0VSOYCPwBXCRqm4FEJE7\n2iVVplOKjaptVpqWEFNv/cC7ZzKiZzIbDxYiAjec6gxql1tYTmZy48NYGGOCq6k6gm8CB4HZIvKU\niJwNSPsky3RWX9x5JgvvPrvR9RsPFgKw+ZAz49mHaw5w0u8+Y8lOG43cmFBpNBCo6tuqeiUwApgD\n3AFkicg/RMTGHjYN6peeQM/UOAB+NG1wo9vtPlrM3W+t5u0V+wBYvutYu6TPGFNfIK2GilX1JVW9\nEOgLrMQZiM6YJt05Y0Sj6xZsPcLLi/d45zkI9sxn6/bnc+3TC61uwpgGBNSz2ENVj6rqP1X1rGAl\nyHQtb/5wKp/ccUazdQCeG/S0P83myXnb+GrbEdbszW+zdNz33noWbD3C8t2W8zDGX4sCgTEtdeKA\ndIZlJfPbS8Z4l/XtFl9vu+KKKsqrqtl5pITfz9zI1U8t5KLH5qNaOwdSZXUN2Xd9wBNzt7U4HZ5p\nNvNtMh1j6rFAYNrFjDE9+dPl44iNiuDyE/vWW//iwt0czK8/LtEby/YCsGL3MX722ioAnpq3vcXH\nT3UDQV6pBYLO7kB+qU181MYsEJh2c/mJfdl0/3lcdVL/BtfP3phTb9mKPXkAfOPxL3l31X4AkuNa\nPhJ6cpwTCGxo7M5v6gOfc/IDs0KdjC7FAoFpN+LOVdAzNY6Xvz+Fnilxdda/udxpQZSRVFufECn1\nWyx7buotERXp7KfGZtvuEjxTo5q2YYHAhMTUwd2Z0C8NgLho52e4Zp9TORwVUXvzj4xoKBDU5gi+\n3HaYbz+9qNnWQJ54UqMWCYzxZ4HAhMyVk50RTIdnJddZfrCZOQx8A8EfP9rE/K2HWbD1cJOf8cyc\nVlllgcAYfzbtpAmZM4f34K0ZcEEEAAAgAElEQVQfnUKv1DjeWr6vzqQ2HsXlVVQ3Up5TUVXDSrcO\nIaew6RHSPRmBymorUjDGn+UITEid0L8bvVLj+eHXBvOLGSM4c3imd123hGgKyiopKqs7p0FZpXMz\nz/dpAVRcXkVReRULtx9psPy4yg0AFe0YCI4WV/Cp22HOmI7MAoHpECIihB9OG8wpgzO8y4b0SOLj\ndYe46LH5APzx8nFMzk6nvMqpD/CtFygqr2LMbz7mqicX8uCHG+vtv8rNVbRnJePdb63m+88vZc/R\nknY7pjGtYYHAdChXufUG04ZnkuK2Dtrt3kh7JMeSEBvJkaIKVJWCsro5Ao+1++v3SK6qqZ8jqKlR\n3ly2N2jFRZ5hMzwD7RnTUVkgMB1Kclw0Ox+8gGdvmExKfN1mokOzkpk6qDtbcoqY/tA8Lnhkvnfd\nU1/s8L5OiInEX1W1kyOo9MkR/HfVPn72+iqebEUHtUB4htXIt05spoOzymLTYfVOc/oZXDS+N6N7\np9A7NY7+6QkAbM0patG+XlmyB6ibIzha7Nygc5upaG4twdN3wVoqmY7NAoHpsL5/+iBiIiP57qnZ\n3iEi0hPrT3jzrUl9eW3pXu/7/ukJqCqPfb6Vi8b39g6LDYG3GlJV5m05zGlDMhrsy9ASjbV6Mqaj\nsKIh02GlJcRw2zlDvUEAoHtS/UBw+Yn96rwvr6zhUEE5f/l0M9c+vYg8n4HmmqosLqus9rYuemfl\nPr7zzGJeX7qn1en3dGKrskBgOjgLBKZT6ZOWUG9Z96QYoiNrn9pLKqs5UuwU9+zLK+Xch+bWrvOZ\n90D9imxG/OojrnxyIQCLdzgzph3P/AWeFFU1kQt5fM5Wvtp2pNXHMKYtWCAwnUp8TCS/vXQMv7pw\nlHfZwO6JDMpI8r4vraji8Tm1Q1UX+PRDOOozamV5A7mDZe5MaZ510VHH/1+kqaKhP360iaufWnjc\nxzBtY9gvP+TpL4LTeKAjszoC0+lcN2UAAPuOlXLOyB5ERAiTsrux6ZDTTPNIcQUrduc1+NkjPoHA\n0+TU0y/BV2yU0/LIvzNbS3iKhiqrg1M0tONwMY/M2sIfvjmOmDYIWJ2Bfy6urfddUVXD/R9s4Hun\nDwracTqi8Pj1mC7p1xeN4pQhTge0xNjaZ5pD+WWcPDC93vanDcngaHEFi3ccJa+kwhsIcgsr6gSD\nsspqb1GTb/+ExhwpKmfVnvqBx9NqqLomOP0UfvXOWt5esc9bjBUOglndEs5VOZYjMF3Cj6cNITYq\ngrLKav69YCepCfUrla89uT/ztx7mW//8iu+ekk2xW1+QW1Re58n/9aV7vE/xReXN1xFc+eRCtuYU\nseOB871DbftqrLL4eFsTJcY6uZaCMJpjIZgtsMK5dZflCEyXkJoQzc/OHc7wnilU1SgbDhTU22bG\nmJ4kuzmHbblFtTmCgjKKfJ7846IjvRW8x0qanwnL06eh1K9iudotxqhqpGjoeHs0h2KynY/XHeSj\ntQfa7Xj+gtknI5z7e1ggMF3K6N4p3tdXndSP2T+f5n0vInz2s68RGxVBcXlVnRxBQWltIIiNjvTe\npA/ml/HW8r3eSuaaGqXG78nRUz7//Fe76iz3PGE2liM43kDgGYKjPXsu3/LCMn7w4vJ2O54/36f2\ntn6CtxxBEIjIMyKSIyJrfZali8inIrLF/bdbsI5vwtOInsn0SYsHnCd7T09kj6yUOC4Y14vlu/OY\ntzkXcCpz9+XVDgxXVlHtLRr6avsRfvraKn7++ipUlekPzeV/Xq57I/T0TfAf7M4bCBq54fv2aSip\naHmldHyM89+3vDJ8htau9nlqb+sxoqotRxAUzwIz/JbdBcxS1aHALPe9MW1GRPjo9tO59eyh3HTa\nQCIjhDOGZfLbS8d4t+mVGlfvc9sPF3tfl1ZW17vJHCkqp7C8im25xcxcc7DOOv+JdTyazxHULh/1\n6485UtSyoS6iIiLc/bTuhqiqne4p2Dc31tYd9fxzeuEkaIFAVecB/s0ZLgGec18/B1warOOb8JUc\nF81Ppw+jn5sbeP7Gyd4mpwDdfCqSk9w6gx25tYGgpMIJBL71vgkxUY02JR3ZywkEQ3sk1VnuGfG0\nqpFWQ/438LwWFvF4mlKWtXJo7V+8uZrB98xs1WdDxTdwNdVR73j37evpL7Yz8O4P2vRYHU171xFk\nqeoBAPffHo1tKCI3i8hSEVmam5vbbgk0Xd/0UVnMGN2Tc0dl8ejVE4GGcgRKz5TanMPW3CLvbGhQ\n9yZe6d5A/MvqPTeWRmdY87uRtbSNvOeJuDXFSoB3fKZgts1va3WLhtq4jqCR7+H+Dzag2rm+p5bq\nsM1HVfVJ4EmASZMmdd0rYNrdgO6JPHHdiUBt00tPj+LICKG4vIqK6hqyUuI4kO/Mn5xbWM6PXqqt\nG8grqfQOM13tbWpa94a8YKszdERjNyz/HEFDPZ2bUhsIWj8Mhmc/vkN0dGS+9+LGclqt1dzuqmuU\nqE7yPbVUe+cIDolILwD335x2Pr4xdSTHRnGa2ynt5IHp9OsWz6GCMqqqa0iOi+JXF44iqoHRR32b\nbHpuSCUV1d6n/6PFFd7mpI3lCCqr6i5vaSDwBJLSVgSCQwVlrT5uKNUtGmqfHEGg6zuz9g4E7wLf\ncV9/B/hvOx/fmDpEhBe/dzJv/nAqT14/id5p8ezPK6WyWomKEG46bSBDG6gMLiyr8t6AfZ/4PbkC\n3/4Hjc2TXFFd9wbe0tY/1ceRI1izt3YWt/LjGFivvfkGgrZuNdRcZXFnq1hviWA2H30Z+AoYLiJ7\nReQm4EFguohsAaa7740JuRMHpJMaH012RiJbc4ooKq/yjjdU0EAl7hdbchl778fsOFxcp4jCEwjy\nfAJBQ58HqKiXI2jZDdkTgFpTR+BbER5ojqAjlJH7dvpq81ZDzeUILBC0nKperaq9VDVaVfuq6r9U\n9Yiqnq2qQ91/w2eQFNMpnJTdjYKyKnYcLmZwj0QAfv71YfW2+3RDDlU1ysYDBXWKKDy9jH3nQPAd\n8dRXc3UEqspFj87nzjdWNfh5T6uZ1uQIWhMIOsK8CsHMETR3ow/SkFEdgvUsNsbHheN6e19P7Of0\nd/zGxL7MvPX0Ott5Bpnbl1dKVY1y4oBuREUIC7c7FcT73UrmKYPSySupZPXePHIKy+qU5zcXCIor\nqlmzL7/O7Gu+PDeu1tQR+Ap0zoWOUJdQJ0fQxnUEzeYIOkCOKFg6bKshY0IhOjKCN34wlbdX7OOM\nYZne5aN6p9A9MYYjxRVERoj3Jrz3WClV1TWkJcTQKy2OA3mlAMzZmEPPlDjG9E5l4fajXPzYAgAG\nZiR6h73wDwT+s6c1N3RE5XHUEQi1WYJAb/BNze7WXny/srZuNdRcBqMrFw1ZIDDGz6TsdCZl1x/G\neu6dZ1JWWc0Fj3zBoYLaGdCqapyK5T5p8SzacZSyymrmbM7lO1Oz6eY3x/KOw8XU1CgREUKF3xOt\nf1n/h2uaHtztvVX7AShuoo5g9d48uiXEeDvXefg+/QZaWdwxAkEQ+xE0VzTUhXMEVjRkTICSYqPI\nSIrlzOFOP8jEmEgWbD3MwfwyoiKFK0/qx4H8Mj5YfYDqGmVA9wTSE+sPh33UrUj2v7HuO1Za5/39\nH2zwvva/Sfn2qm2qaOjixxZw+h9n11vue+xAcwQtrcwOhpAWDXXhHIEFAmNa6P5Lx/DiTSfzn+9P\nobyqhiPFFURFRHDW8CwAvnTnIM5Mjq0znIWHpw2/f9HQS4t212nCGOsz65h/Z7Vin3kSqmq0waf1\npipTfZu0dqaiId+bdWWbFw1ZIDDGBCgqMoLThmYwvl8ad5wzFHAqXFPio4iJjGDdfqeNfmZyrLf3\nMTgT40DjgaCovMo73lBZZXWdIbX9A0FhubOdZ8C7hnIFB/PL6i3z8C1WCfRJ3zdgNNWUVFXJvusD\n/vrp5oD22xKNdSi75qmFvLW84Ur1gPfdTI7AioaMMQ06cYBTlzCkRxIiQvekGDYeLEQEhvdMZkK/\nNM4b05NHr57InV8fAcCGA87cyp4n7B98bTB/vmI8AIfdEUjP+ONslvvMu+w/4J0nR9AjxQk0JZX1\n6wn25ZXWW+ZRp2gowI5svoGgqYdjTzPTR2ZtCWi/LVG3aKg2PV9uc4YLP659W47AGNMaUwal88S3\nT+CO6U5fg4EZTt+D4VnJpMRFExkh/OPbJ3LR+N6kJkST3T3B26vX81R++zlD6Z3mDHB3uNAJBDnu\nv93dOoai8rotiDzvPTmO4gam1PSvc/DlmxspCzhH4Fsc1Xjw8A0Yy3cfC2jfgfLNRHlaTbXVKKRW\nNGSMaRURYcaYXsRFO72Q75wxgoykGH46vX4nNICxfdP4avsR8ksrvTfj6MgI70in+/PL6rTrT/DO\nS1z3id8zGF6W+7mGioY8OYKYyPr/zVuTI/D9TFM3Rd/tLnv8y4D2HaiGhqFubAiPFu87jPsRWCAw\npg1N6JfG4nvO4dzRPRtcf92UAeSXVnLVkwupqKohMkKIjBD6pycQHSlszSny3uQBuic6T/z+RUOf\nb8ghLSGaSQOcTm/+TU8rqmp4e8U+53V1Tb0bt+/TfWsqi5fubPxJP5itixpqNdRWldiNZXI8vbAt\nR2CMCVhEA6OVekwemE5KXBQbDhSw62gJiTHOE39UZAQDMxLZmlPImn21A8Kd0N+50ftPWrP9cDGj\ne6d4+ymU+PUFuP+D9ezwmWPBv69BaaVvIGh5ZfGeYyWNbxfEqTPr9CNw79xtFQiarSwOfaOpoLFA\nYEw7e/bGyYDTIcxTpwBOhfOmQ4Ws3J1HbFQE/7j2BO4+3ylq+u176zlaXOGtTN57rIR+3RJIjHH6\nhPrnGDzzK3is9QkuAKUVNSTFRhEdKQHnCHyDR2OztUFwh6KobiBH0FbH860sbqhVlO+xVZXcwpZN\nLdqRWSAwpp2d0L8b1091ps4c0yfVu/yMoZnsOVrKMwt2MKZPKueN7UV0ZAQnD+xORXUNJ/z2Uybd\n/xmqSn5pJd0SY7x1C/5NRf3rDK55alGd92VV1cRFRxAXFRnwWEPFPk1Yi8sbDwTB7G/ge4P21LHU\nac10HMU3dWad82ma6snf+eZGXl+6l5N+9xnr9xe0+ngdiQUCY0LgvotH88JNk/nlBaO8y66Y1I+J\n/dMAGNe3NkA88M2xdT478O6ZVFYrKXHRpCZEkxwXxftrDtS5STY3/lBZRTVx0ZEkxjY+F7M/z80/\nNiqCwiYCgX9RU1sOX113rKH6dQRHSxoe6TUQvjmehlpF+dZPLNh2GIAtOYWtPl5HYoHAmBAQEU4f\nmkm8W0cAzjSZf7liPBeN781VJ/X3Lk+Ji2bmrad7cxHe5fFOsVBNjbJqTx6fb6yd8C+vtML9rLPN\nsKwk77rCskreWrGPvcdKSY2P9k7X2ZziimpiIiPolhDTZI7Av6imtA0nvmmu1ZCn6Kw1fJvg1skR\nuLXFvseOcJd1lU5mFgiM6UAGZSbx6NUTGd6z7qxoo3qn8P8uGcPi/zvbuywlLhqAJ6+fBMBby/dx\n5p/ncMsLSylzK2zTEmKYMbonZZU13idzzxAY4AST5kY59SguryIhNpLkuNrPlFRUccsLS9lztLby\n2JMjuOLEvkD9XtHHo84QEw20GjpWHNi5NMS35VVDfRN8i508LYm6SgWyBQJjOpEeyXE8eNlYYiIj\nGNLDeco/dUgG547K4oM1B9hxuJiP1x3ybj+0RxKnDOnO7qMlrHDnUNjv0+M4NT6avJJKnpy3jZzC\nxoekAOeGnhgTRZ9u8ex1O6vN33KYj9cd4t5313m389yMe6fFAw13dmst36dyz2vfoqi84yga8i1O\na2gSnqoGcgTbcotafbyOxAKBMZ3MVZP7s+n+GYzsVTsW0a1nD/W+TomL4v2fnMa/v3sSD101gUsm\n9CEqQvh43UGKyqs45s6Y9tg1E0lPdIbE+P3Mjdz+ykr+9/VV5BSWsWL3Mcoqq8n3mWlt86FCeqfF\nMSA9gd1HnBxAYqxT9ORbNp/rFs9kZzhDXzdVjNRSvjmCx2ZvpaSiikKfOo5jJa3PEfg2sW2owtu3\n1ZCnhfDjc7a1+ngdic1HYEwnJFK3r8KYPql89tMz6JYQQ3piTL31UwZ1559zt/P8l7sY3TuFtIRo\nLhzXm/LKGu8MaJ4io9eXOe+HZSWx+VARa+/7OgDr9xfww2mDSYqNprC8iuLyKu9T9DGf6Tj3HSsl\nISaSHslOi6a2DAT+nbq+3HqkzrSggRZzNaTEJ+eSX1pJP/d1hEA1TgW7R2QTfUVaYn9eKd2TYrzz\nY4eK5QiM6SKG9Eime1JsvSAAcOG4XoBTcbt01zHvGEYXju9FVkpsve0BNh9yij3G/OZjJtz3CTUK\nGUm1I6oeLir33uSPFlew8WABpRXVfLL+IGP7pHpzC01NnNNS/oEgOirCWzEOUHocx/JN5xGfwDY4\n0ymCW+LTm7qh7xhg1oZD3mlMA3HKg5+3+TAcrWGBwJgwcOVJ/XjrR6fw3VOyAfjxmUMAiI2KZO7/\nnslT10/ipOxujX7eUz6enhhDRpITRHIKy703z4KyKmY8/AV3v7WaQwXlnD40g2S3xVJBae0Ntqi8\nip+9toplu4626jw8pTP3XTwacFpA5ZdWEhMVQXx0ZKum7fQoragmOtK5wR8trm19FOUuO1hQW7fS\nWIbgpueWcsnfFwR0PE/l/boO0BfBioaMCQMiwgn9uzGuTyrXTR3gfcoFiIuOZPqoLKaPymL+lsMs\n2nGEOZty6wx14dEtIYbBbiX1nE05/H123TLyzzY4TVh7pcaT7k7Kc7S4gvX7C6iqqWFrThFvLt9L\ndU2NdwjvlvCU0491+1kUllWRX1JJWnw0VTXK0/N3MKp3Cped0LfF+y6uqKZ/egLbcovJKagNBJ4G\nREd9cgkRjeQIWiKYPbBbynIExoSRqMiIOkHA32lDM/jZucN5+eYp3HP+CG/PZY8+3eLpkxbP2D6p\n9YIA1DYVHZSZSGp8NBECx0oqOP+RL7j4sQVsOuR0wDpWUslljy/gq21HWL038KIUT9GQZ+a3gtJK\n8koqSY2P9t6o//eN1c3u59Ulu+vc2AFKyqvomRpHt4Rodvk2h6301IPU1j80VEfQ0h7VvmMyveMO\nEBgqFgiMMfUkxUZx8xmDeeK6Ezl9aAYJbse37O7O2Ei3fG0QEQIxURHcf+kYJvRLI7t7gvfzY/uk\nEhEhdEuIqTP4neeGt2jHEZbvzuPqpxZy8WMLvHM0NMfTaigpNork2Cj2Hislv7SStIRo7zbNjRK6\n52gJv3hzDT96aRlV1TXeITaKK6qJj46if3pCnX4RnvXHfFpGeW76nqIkaHnTVd9mr7e/urJFn21r\nVjRkjGnUhH5pvHDTyRwqKGPvsRLvk/CF43ozeWA63RNjiYwQvj1lAAu3H+GqJxcyqlcKUe4cCCN7\npfD+6gPe/R1yi1zK/EYo3ZdX4i3u8ZdfWklUhJAYG+W9yUdFCCN7pbBufz6llTX0cfsseBSXV3kr\nq/15ci0bDxZy8wvL+HxjDjsfvIDSiioSYyOpqompk1so9QkEqoqIeMclqqxWPl53kOzuiTQw7UOT\n/L+DULIcgTGmWVkpcfXK9Hskx9UpIjl5YDoPXzmBZ284ybvsNxeNok9aPCN6JvNNt9ze9yna491V\n+8kpKOPed9d5cwebDxUye1MO4+/7hPP+9gVQe/OMiBBG9U5hw4FCcgvL6ZYQzWlDMrz7a2qoCU8T\n07ySSu+wHIcKyigqryYhJoqUuGgKfJqheo5ZWa3eIOJbvn/LC8v4+sPzWtxxLphjMrWU5QiMMW1C\nRLh0Yp86y4ZmJfPFnWcCzvwBXxueyaCMRC75+wLOHZXFvReP5tHPt/Diwt3MXHMQgGe/3Mk3T+jL\nmz6T0e8+WsKyXUf5w0cbAWfgu8kD03n2y52UVlYzoHsCv79sLK8t3cP/vb2W57/aRXpiDD+aNpiK\n6hr+9NEmrjypH0Ozkuv0O/DYn1dKfmkFaQnRREbUzginqpRVVdM7NY79+WUcK64kOS66Tic2D98W\nS+f97QvuOGdooxMUQf0cQUFZFanx0Y1sHVwWCIwxQeWZqCc2IpKLx/cG4Is7zyQjKZaYqAh+e8kY\nEmKiePqL7aQnxnC4qKJOEPD45j++AuDWs4YQFx3JjNE9GdojiS05RYzomUJ0ZATTR2Zx//sb+Nf8\nHQDM25zLoh1OU9Wn5+9g/f/7OruPFtfb995jpVRWK2nx0QhOJbSqUl5Vg6pTSb4/v4zcojL6d0+o\nk2Pw8B2raMOBAv67cn/TgcAvR1BUboHAGBNGevuU6YsI95w/knvOHwk4lbNPzN1GYVkVt549lAiB\nG59dwpKdxzhnZA9+eu5wwAkwz944mQVbDnPWiB4A9EiJ49GrJ/L0/O0s3H7UGwQ8Xlm8h9/P3Fgv\nPZ4K7W4JMcRGRVBVo+w9Vuod2G9UrxSW7DzG1pwiThyQTmFZFemJtXUJcdER9fow+I4s2xD/eSAC\nHQ48GCwQGGM6lLjoSG4/Z1idZY9dcwKzNuRw6cTedZb3SYvnWyf1q7PsnFFZnDMqi/zSSh7+bDOq\ncPf5I7js8S/5f++vB2BQRiLbfVozPTJrCwBpCdFMHdyd+z/YwD1vr/EGpyFZyXRPjOGx2Vs5ZXAG\nBWWVjOyVzIKtzrAcPZLj6s0b3dxwF74d7QCKyls/PMbxsspiY0yHl5USxzUn9ychJvBn19T4aH5z\n0WjuvXg0sVGR3H3eSFLjoxmelcw7/3Mqw7KSvD2EPT2nx/VNo196AvdfOoYvtx3xVlKP6pXMv757\nEvkllVz46HwO5JcxoV8ar90ylW9P6c+B/FJW+g0tcaSZuRE8Q2M8fu0JAA3WO7QXyxEYY8LCaUMz\nWPrLcxCcjnVv/ehUDheWU1Rexdsr9jG8ZzI9U50OdFdN7s/Yvqn8e8FOuifFMLFfNyIihJdvnsJv\n319PRVUNV0/uT99uCURFCi8v3sPLi/fQMyWOG07NZsnOo3y2IYc/f7yJacMzGd07tV5RkSfH0Ldb\nfJ33oSChbLIUqEmTJunSpUtDnQxjjGnQ7iMlLNl5lJMHpdO3WwJHisr5xZurmbUxB1WnJ3K/bvFk\nZyQyMCORPmnxfLLuECv35rH8V9OZ8vtZpCfGcM3J/ZnYL40hPZLontTwYIAtISLLVHVSs9tZIDDG\nmOA4XFTO8l3HWLsvn225xew4XMzOI8XeiuXzxvTkH98+kS+3HeZ3H2yoMwBdUmwUvVLjeOK6E5sc\nFqQpgQYCKxoyxpggyUiK5dzRPes0I1VVCsurKCqr8o7ldMrgDD649XQOFZSx4UABW3OK2HuslP15\npaS1Q5NSCwTGGNOORISUuGhv01RfWSlxZKXEMW14j3ZNk7UaMsaYMGeBwBhjwpwFAmOMCXMhCQQi\nMkNENonIVhG5KxRpMMYY42j3QCAikcDfgfOAUcDVIjKqvdNhjDHGEYocwWRgq6puV9UK4BXgkhCk\nwxhjDKEJBH2APT7v97rL6hCRm0VkqYgszc3NbbfEGWNMuAlFIKg/PRHU696sqk+q6iRVnZSZmdkO\nyTLGmPAUig5lewHfcWP7Avub+sCyZcsOi8iuVh4vAzjcys92VnbO4cHOOTwczzkPCGSjdh9rSESi\ngM3A2cA+YAlwjaquC9LxlgYy1kZXYuccHuycw0N7nHO75whUtUpE/gf4GIgEnglWEDDGGNO8kIw1\npKozgZmhOLYxxpi6wqFn8ZOhTkAI2DmHBzvn8BD0c+4U8xEYY4wJnnDIERhjjGmCBQJjjAlzXToQ\ndMXB7USkn4jMFpENIrJORG5zl6eLyKcissX9t5u7XETkEfc7WC0iJ4T2DFpPRCJFZIWIvO++Hygi\ni9xzflVEYtzlse77re767FCmu7VEJE1E3hCRje71ntrVr7OI3OH+rteKyMsiEtfVrrOIPCMiOSKy\n1mdZi6+riHzH3X6LiHzneNLUZQNBFx7crgr4maqOBKYAP3bP6y5glqoOBWa578E5/6Hu383AP9o/\nyW3mNmCDz/s/AA+553wMuMldfhNwTFWHAA+523VGfwM+UtURwHicc++y11lE+gC3ApNUdQxO8/Kr\n6HrX+Vlght+yFl1XEUkHfgOcjDN+2288waNVVLVL/gFTgY993t8N3B3qdAXhPP8LTAc2Ab3cZb2A\nTe7rfwJX+2zv3a4z/eH0QJ8FnAW8jzNUyWEgyv964/RRmeq+jnK3k1CfQwvPNwXY4Z/urnydqR2H\nLN29bu8DX++K1xnIBta29roCVwP/9FleZ7uW/nXZHAEBDm7XmblZ4YnAIiBLVQ8AuP96Jj3tKt/D\nw8CdQI37vjuQp6pV7nvf8/Kes7s+392+MxkE5AL/dovDnhaRRLrwdVbVfcCfgd3AAZzrtoyufZ09\nWnpd2/R6d+VAENDgdp2ViCQBbwK3q2pBU5s2sKxTfQ8iciGQo6rLfBc3sKkGsK6ziAJOAP6hqhOB\nYmqLCxrS6c/ZLdq4BBgI9AYScYpG/HWl69ycxs6xTc+9KweCFg9u11mISDROEHhJVd9yFx8SkV7u\n+l5Ajru8K3wPpwIXi8hOnPkrzsLJIaS5Y1dB3fPynrO7PhU42p4JbgN7gb2qush9/wZOYOjK1/kc\nYIeq5qpqJfAWcApd+zp7tPS6tun17sqBYAkw1G1xEINT6fRuiNN03EREgH8BG1T1rz6r3gU8LQe+\ng1N34Fl+vdv6YAqQ78mCdhaqereq9lXVbJzr+LmqXgvMBi53N/M/Z893cbm7fad6UlTVg8AeERnu\nLjobWE8Xvs44RUJTRCTB/Z17zrnLXmcfLb2uHwPnikg3Nyd1rrusdUJdaRLkCpnzcUY63Qb8X6jT\n00bndBpOFnA1sNL9Ox+nbHQWsMX9N93dXnBaT20D1uC0yAj5eRzH+U8D3ndfDwIWA1uB14FYd3mc\n+36ru35QqNPdynOdAMlBN1kAAAOdSURBVCx1r/U7QLeufp2B+4CNwFrgBSC2q11n4GWcOpBKnCf7\nm1pzXYEb3XPfCtxwPGmyISaMMSbMdeWiIWOMMQGwQGCMMWHOAoExxoQ5CwTGGBPmLBAYY0yYs0Bg\nOjQRKXL/zRaRa9p43/f4vf+yLffvt+9YEflMRFaKyJWt3Me9IqIiMsRn2R3usknuCJwrRWS3iOS6\nr1d2llE5TehYIDCdRTbQokDgjkDblDqBQFVPaWGaWmIiEK2qE1T11UA+0Ej61+B0qvO4HKfTFap6\nsqpOAH4NvOoea4Kq7jy+pJuuzgKB6SweBE53n3DvEGdugj+JyBJ3nPZbAERkmjjzNfwH56aJiLwj\nIsvcce5vdpc9CMS7+3vJXebJfYi777UissbzBO/ue47UzhHwktsDFhF5UETWu2n5s2/CRaQH8CIw\nwT3eYBE52x1Mbo0449PHutvuFJFfi8h84IoGvod3cMbjQUQG4Qy0ltuWX7QJP1HNb2JMh3AX8HNV\nvRDAvaHnq+pJ7k10gYh84m47GRijqjvc9zeq6lERiQeWiMibqnqXiPyP+wTt7zKcXr3jgQz3M/Pc\ndROB0TjjuiwAThWR9cA3gBGqqiKS5rszVc0Rke950i8iccAc4GxV3SwizwM/xBk/CaBMVU9r5Hso\nwBl6YgxOQHgVuCGA78+YRlmOwHRW5+KMwbISZxju7jiTdwAs9gkCALeKyCpgIc5AXUNp2mnAy6pa\nraqHgLnAST773quqNTjDe2Tj3JzLgKdF5DKgpJn9D8cZXG2z+/454Ayf9c0VHb2CUzx0KfB2M9sa\n0ywLBKazEuAnPuXgA1XVkyMo9m4kMg1nVMupqjoeWIEzRk1z+25Muc/rapwJU6pwciFv4tycPzqO\n/YNP+hvxHnAdsFubHoLcmIBYIDCdRSGQ7PP+Y+CH7pDciMgwcSZu8ZeKM51hiYiMwJne06PS83k/\n84Ar3XqITJyn9cWNJUycuSFSVXUmcDtOsVJTNgLZPq1/rsPJdQREVUuBXwC/C/QzxjTF6ghMZ7Ea\nqHKLeJ7Fmc83G1juVtjm4jyN+/sI+IGIrMaZ5m+hz7ongdUislydYa093saZEnEVzkivd6rqQTeQ\nNCQZ+K9b9i/AHU2diKqWicgNwOvijKO/BHiiqc80sI9XWrK9MU2x0UeNMSbMWdGQMcaEOQsExhgT\n5iwQGGNMmLNAYIwxYc4CgTHGhDkLBMYYE+YsEBhjTJj7/7k7lWlLhBTZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb5ed81c5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<SOS>', 'deux', 'jeunes', 'hommes', 'blancs', 'sont', 'dehors', 'près', 'de', 'buissons', '<EOS>']\n",
      "['<SOS>', 'two', 'young', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '<EOS>']\n",
      "['a', 'young', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "learning_rate = 0.01\n",
    "w_embedding_dim = 300\n",
    "p_embedding_dim = 300\n",
    "dec_embedding_dim = 300\n",
    "dropout_prob = 0.1\n",
    "\n",
    "model_encoder = Encoder(vocab_size_fr, w_embedding_dim, p_embedding_dim, dec_embedding_dim, max_sentence_length)\n",
    "model_decoder = Decoder(dec_embedding_dim, vocab_size_en, max_sentence_length, dropout_prob)\n",
    "\n",
    "optimizer_encoder = optim.SGD(model_encoder.parameters(), lr = learning_rate)\n",
    "optimizer_decoder = optim.SGD(model_decoder.parameters(), lr = learning_rate)\n",
    "\n",
    "loss_func = nn.NLLLoss()\n",
    "losses = []\n",
    "avg_losses = []\n",
    "\n",
    "portion = 10\n",
    "\n",
    "train = True\n",
    "print('epoch, total loss, duration')\n",
    "for e in range(epochs):\n",
    "    \n",
    "    then = datetime.now()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    for s in range(portion):\n",
    "     \n",
    "        current_input = corpus2id_fr[s]\n",
    "        gold_output = corpus2id_en[s]\n",
    "        \n",
    "        if len(current_input) > 0 and len(gold_output) > 0:\n",
    "            \n",
    "            optimizer_encoder.zero_grad()\n",
    "            optimizer_decoder.zero_grad()\n",
    "            \n",
    "            sent_fr = torch.tensor(np.asarray(current_input), dtype= torch.long)\n",
    "            sent_en = torch.tensor(np.asarray(gold_output), dtype= torch.long)\n",
    "\n",
    "            pos_fr = torch.tensor(np.asarray([p for p in range(len(sent_fr))]))\n",
    "            pos_en = torch.tensor(np.asarray([p for p in range(len(sent_en))]))\n",
    "\n",
    "            average_context, stacked_contexts = model_encoder(sent_fr, pos_fr)\n",
    "        \n",
    "            pred, attention_weights = model_decoder(sent_en, average_context, stacked_contexts, train)\n",
    "            \n",
    "            #print(pred, sent_en)\n",
    "            sent_en = sent_en[1:len(sent_en)] #skip SOS\n",
    "            loss = loss_func(pred.squeeze(), sent_en)\n",
    "        \n",
    "            loss.backward()\n",
    "\n",
    "            optimizer_encoder.step()\n",
    "            optimizer_decoder.step()\n",
    "\n",
    "            total_loss += loss.item() \n",
    "       \n",
    "    now = datetime.now()\n",
    "        \n",
    "    losses.append(total_loss)\n",
    "    \n",
    "    print(e, total_loss/portion, now-then)\n",
    "    \n",
    "\n",
    "with open('model_encoder' + str(portion) + '.pickle','wb') as file:\n",
    "    pickle.dump(model_encoder,file)\n",
    "      \n",
    "\n",
    "with open('model_decoder' + str(portion) + '.pickle','wb') as file:\n",
    "    pickle.dump(model_decoder,file)\n",
    "    \n",
    "iteration= list(range(len(losses)))\n",
    "\n",
    "plt.plot(iteration, losses)\n",
    "plt.xlabel(\"Iterations for MT\")\n",
    "plt.ylabel('Average loss')\n",
    "plt.title('Evolution of the loss as a function of the iteration')\n",
    "plt.savefig(\"mt\" + str(portion)+\".png\")\n",
    "plt.show()\n",
    "\n",
    "test_fr_sentence = corpus2id_fr[0]\n",
    "test_en_sentence = corpus2id_en[0]\n",
    "    \n",
    "decoder_outputs, decoder_attentions = evaluate_test(model_encoder, model_decoder,test_fr_sentence, test_en_sentence)\n",
    "\n",
    "print(word_ids2string(test_fr_sentence, id2tokens_fr))\n",
    "print(word_ids2string(test_en_sentence, id2tokens_en))\n",
    "print(word_ids2string(decoder_outputs, id2tokens_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<SOS>', 'une', 'fille', 'branchée', 'parle', 'à', 'son', 'portable', 'tout', 'en', 'glissant', 'lentement', 'dans', 'la', 'rue', '<EOS>']\n",
      "['<SOS>', 'a', 'trendy', 'girl', 'talking', 'on', 'her', 'cellphone', 'while', 'gliding', 'slowly', 'down', 'the', 'street', '<EOS>']\n",
      "['a', 'trendy', 'girl', 'talking', 'on', 'her', 'cellphone', 'while', 'gliding', 'slowly', 'down', 'the', 'street', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "pair = 7\n",
    "\n",
    "test_fr_sentence = corpus2id_fr[pair]\n",
    "test_en_sentence = corpus2id_en[pair]\n",
    "    \n",
    "decoder_outputs, decoder_attentions = evaluate_test(model_encoder, model_decoder,test_fr_sentence, test_en_sentence)\n",
    "\n",
    "print(word_ids2string(test_fr_sentence, id2tokens_fr))\n",
    "print(word_ids2string(test_en_sentence, id2tokens_en))\n",
    "print(word_ids2string(decoder_outputs, id2tokens_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('model_encoder' + str(portion) + '.pickle','rb') as file:\n",
    "    model_encoder = pickle.load(file)\n",
    "      \n",
    "\n",
    "with open('model_decoder' + str(portion) + '.pickle','rb') as file:\n",
    "    model_decoder = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_test(model_encoder, model_decoder, sent_fr, sent_en):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        sent_fr = torch.tensor(np.asarray(sent_fr), dtype= torch.long)\n",
    "        sent_en = torch.tensor(np.asarray(sent_en), dtype= torch.long)\n",
    "\n",
    "        pos_fr = torch.tensor(np.asarray([p for p in range(len(sent_fr))]))\n",
    "        pos_en = torch.tensor(np.asarray([p for p in range(len(sent_en))]))\n",
    "\n",
    "        average_context, stacked_contexts = model_encoder(sent_fr, pos_fr)\n",
    "        \n",
    "        decoder_outputs, decoder_attentions = model_decoder(sent_en, average_context, stacked_contexts, train=False)\n",
    "    \n",
    "    return decoder_outputs, decoder_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_ids2string(sentence, id2token):\n",
    "    \n",
    "    converted = []\n",
    "\n",
    "    for s in sentence:\n",
    "        converted.append(id2token[s])\n",
    "        \n",
    "    return converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "#BEAM SEARCH\n",
    "#teacher forcing prob\n",
    "#dropout prob\n",
    "#gru lstm rnn check\n",
    "#relu before rnn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def visualize_attention(model, sentence):\n",
    "    \n",
    "    #model_encoder, model_decoder, sent_en, sent_fr\n",
    "    \n",
    "#************************************************************************\n",
    "# A is the attention torch Tensor: the output of your model\n",
    "# S is the softmax version of S, also a torch Tensor! (actually more acurately it's a Variable(Tensor(..))\n",
    "#************************************************************************\n",
    "\n",
    "    # Plot the attention tensor\n",
    "    plt.clf()\n",
    "    numpy_S = S.data.numpy() # get the data in Variable, and then the torch Tensor as numpy array\n",
    "    plt.imshow(numpy_S)\n",
    "    plt.savefig(\"attention-sent-{}-epoch-{}\".format(i, step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.tensor(np.asarray([i for i in range(10)]), dtype= torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-9.4586, -8.4586, -7.4586, -6.4586, -5.4586, -4.4586, -3.4586,\n",
      "        -2.4586, -1.4586, -0.4586])\n"
     ]
    }
   ],
   "source": [
    "asf = F.log_softmax(a, dim=0)\n",
    "print(asf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.1000,  0.2000,  0.3000,  0.4000,  0.5000,  0.6000,\n",
       "         0.7000,  0.8000,  0.9000])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = torch.tensor(np.asarray([i+1 for i in range(10)]), dtype= torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.],\n",
      "        [  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.]])\n"
     ]
    }
   ],
   "source": [
    "st = torch.stack([a,b], dim = 0)\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.1000,  0.2000,  0.3000,  0.4000,  0.5000,  0.6000,\n",
       "          0.7000,  0.8000,  0.9000],\n",
       "        [ 0.2000,  0.4000,  0.6000,  0.8000,  1.0000,  1.2000,  1.4000,\n",
       "          1.6000,  1.8000,  2.0000]])"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.tensor(np.asarray([0.1, 0.2]), dtype = torch.float).view(-1,1)\n",
    "print(weights.shape)\n",
    "\n",
    "torch.mul(weights, st)\n",
    "# torch.matmul(weights.view(1,2), st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   1.],\n",
       "        [  1.,   2.],\n",
       "        [  2.,   3.],\n",
       "        [  3.,   4.],\n",
       "        [  4.,   5.],\n",
       "        [  5.,   6.],\n",
       "        [  6.,   7.],\n",
       "        [  7.,   8.],\n",
       "        [  8.,   9.],\n",
       "        [  9.,  10.]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([a,b], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.5000,  5.5000])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(st, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5000,  1.5000,  2.5000,  3.5000,  4.5000,  5.5000,  6.5000,\n",
       "         7.5000,  8.5000,  9.5000])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(st, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2689,  0.2689,  0.2689,  0.2689,  0.2689,  0.2689,  0.2689,\n",
       "          0.2689,  0.2689,  0.2689],\n",
       "        [ 0.7311,  0.7311,  0.7311,  0.7311,  0.7311,  0.7311,  0.7311,\n",
       "          0.7311,  0.7311,  0.7311]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(st, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = a*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'long' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-405-521c823e1b54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'long' is not defined"
     ]
    }
   ],
   "source": [
    "long(torch.argmax(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "test_word = torch.tensor(np.asarray([tokens2id_en['<SOS>']]), dtype = torch.long)\n",
    "print(test_word, test_word.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#     attn_weights = F.softmax(\n",
    "#             self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "#         attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "#                                  encoder_outputs.unsqueeze(0))\n",
    "\n",
    "#         output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "#         output = self.attn_combine(output).unsqueeze(0)\n",
    "           \n",
    "#         atts= torch.matmul(es, hidden_from_decoder)\n",
    "        \n",
    "#         weighted_context = es*attention_weights\n",
    "        \n",
    "        #if EOS for encoder, move on to the decoder\n",
    "        \n",
    "        #attention_matrices = self.attention_projection(e_out)\n",
    "        \n",
    "        #input embedding\n",
    "        #set hidden at the beginning\n",
    "        #get rnn output\n",
    "        #apply softmax\n",
    "\n",
    "        #feed actual word for training\n",
    "        #feed previous word for testing\n",
    "\n",
    "#             #view_shape = embeddings.shape[0]\n",
    "#             output, (hidden, cell) = self.bidirLSTM(embeddings.view(1, 1, -1)) \n",
    "\n",
    "#             hid_f = hidden[0]\n",
    "#             hid_b = hidden[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
