{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial\n",
    "from scipy import stats\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1)\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "from random import randint\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('error')\n",
    "\n",
    "import string\n",
    "# puncs = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "portion = 29000\n",
    "\n",
    "#training sets\n",
    "with open('tokenized_low.BPE.en') as f:\n",
    "    train_en = [l.strip() for l in f.readlines()][:portion]\n",
    "with open('tokenized_low.BPE.fr') as f:\n",
    "    train_fr = [l.strip() for l in f.readlines()][:portion]\n",
    "\n",
    "# #validation sets\n",
    "# with open('val.en') as f:\n",
    "#     val_en = [l.strip() for l in f.readlines()]\n",
    "# with open('val.fr') as f:\n",
    "#     val_fr = [l.strip() for l in f.readlines()]\n",
    "\n",
    "# #test sets\n",
    "# with open('test_tokenized.BPE.en') as f:\n",
    "#     test_en = [l.strip() for l in f.readlines()]\n",
    "# with open('test_tokenized.BPE.fr') as f:\n",
    "#     test_fr = [l.strip() for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "# 0 PAD - padding 0 for convenience in masking?\n",
    "# 1 BOS - beginning of sentence\n",
    "# 2 EOS - end of sentence\n",
    "# 3 UNK - unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_sentence_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokens_sentences(sentences):\n",
    "    tokens_list = []\n",
    "    sentence_list = []\n",
    "    for s in sentences:\n",
    "        split_sent = s.split()\n",
    "        sentence = []\n",
    "        for w in split_sent:\n",
    "#             if w not in puncs:\n",
    "            tokens_list.append(w)\n",
    "            sentence.append(w)\n",
    "\n",
    "        sentence_list.append(sentence)\n",
    "    \n",
    "    return tokens_list, sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m@@\n",
      "m@@\n",
      "563773\n",
      "812\n"
     ]
    }
   ],
   "source": [
    "tokens_list,sentence_list = tokens_sentences(train_en)\n",
    "\n",
    "print(tokens_list[4])\n",
    "print(sentence_list[0][4])\n",
    "\n",
    "print(len(tokens_list))\n",
    "print(len(sorted(set(tokens_list))))\n",
    "# print(set(tokens_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size EN 816\n",
      "Vocabulary size FR 862\n"
     ]
    }
   ],
   "source": [
    "tokens_list_en, sentence_list_en = tokens_sentences(train_en)\n",
    "\n",
    "tokens_train_en = ['<PAD>', '<SOS>', '<EOS>', '<UNK>']\n",
    "tokens_train_en.extend(list(sorted(set(tokens_list_en))))\n",
    "vocab_size_en = len(tokens_train_en)\n",
    "print('Vocabulary size EN', vocab_size_en)\n",
    "\n",
    "count_tokens_train_en = Counter(tokens_list_en)\n",
    "\n",
    "tokens_list_fr, sentence_list_fr = tokens_sentences(train_fr)\n",
    "\n",
    "tokens_train_fr = ['<PAD>', '<SOS>', '<EOS>', '<UNK>']\n",
    "tokens_train_fr.extend(list(sorted(set(tokens_list_fr))))\n",
    "vocab_size_fr = len(tokens_train_fr)\n",
    "print('Vocabulary size FR', len(tokens_train_fr))\n",
    "\n",
    "count_tokens_train_fr = Counter(tokens_list_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_id_dicts(tokens):\n",
    "    #default dictionary key:id value:token\n",
    "    id2tokens = defaultdict(str)\n",
    "\n",
    "    for i in range(len(tokens)):\n",
    "        id2tokens[i] = tokens[i]\n",
    "\n",
    "    #default dictionary key:token value:id\n",
    "    tokens2id = defaultdict(int)\n",
    "\n",
    "    for ind in id2tokens:\n",
    "        tokens2id[id2tokens[ind]] = ind\n",
    "\n",
    "    return tokens2id, id2tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816\n",
      "862\n"
     ]
    }
   ],
   "source": [
    "tokens2id_en, id2tokens_en = get_id_dicts(tokens_train_en)\n",
    "\n",
    "vocabulary_size_train_en = len(tokens2id_en)\n",
    "print(vocabulary_size_train_en)\n",
    "\n",
    "tokens2id_fr, id2tokens_fr = get_id_dicts(tokens_train_fr)\n",
    "\n",
    "vocabulary_size_train_fr = len(tokens2id_fr)\n",
    "print(vocabulary_size_train_fr)\n",
    "\n",
    "# print(tokens2id_en['m@@'])\n",
    "# print(id2tokens_en[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#building the corpora (list of list of ids) simultaneously \n",
    "def convert_corpora2id_both(sentence_list_en, sentence_list_fr, tokens2id_en, tokens2id_fr, max_sentence_length):\n",
    "    \n",
    "    #counts to check long sentences\n",
    "    counter_long = 0\n",
    "    \n",
    "    #convert dataset to ids\n",
    "    corpus2id_en = []\n",
    "    corpus2id_fr = []\n",
    "    \n",
    "    for s in range(len(sentence_list_en)):\n",
    "    \n",
    "        sentence2id_en = []\n",
    "        sentence2id_en.append(tokens2id_en['<SOS>'])\n",
    "        \n",
    "        sentence2id_fr = []\n",
    "        sentence2id_fr.append(tokens2id_fr['<SOS>'])\n",
    "        \n",
    "        sentence_en = sentence_list_en[s]\n",
    "        sentence_fr = sentence_list_fr[s]\n",
    "        \n",
    "        \n",
    "        for w_en in sentence_en:\n",
    "            word_id = tokens2id_en[w_en]\n",
    "            sentence2id_en.append(word_id)\n",
    "            \n",
    "        for w_fr in sentence_fr:\n",
    "            word_id = tokens2id_fr[w_fr]\n",
    "            sentence2id_fr.append(word_id)\n",
    "        \n",
    "        \n",
    "        sentence2id_en.append(tokens2id_en['<EOS>'])\n",
    "        sentence2id_fr.append(tokens2id_fr['<EOS>'])\n",
    "\n",
    "        if len(sentence2id_en) < max_sentence_length and len(sentence2id_fr) < max_sentence_length:\n",
    "            corpus2id_en.append(sentence2id_en)\n",
    "            corpus2id_fr.append(sentence2id_fr)\n",
    "        \n",
    "        else:\n",
    "            counter_long += 1\n",
    "#             print(sentence_list_en[s])\n",
    "#             print(sentence_list_fr[s])\n",
    "        \n",
    "    print('the number of sentences that were not added is',counter_long)       \n",
    "    return corpus2id_en, corpus2id_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of sentences that were not added is 531\n"
     ]
    }
   ],
   "source": [
    "# corpus2id_en = convert_corpus2id(sentence_list_en, tokens2id_en, max_sentence_length)\n",
    "# corpus2id_fr = convert_corpus2id(sentence_list_fr, tokens2id_fr, max_sentence_length)\n",
    "\n",
    "corpus2id_en, corpus2id_fr = convert_corpora2id_both(sentence_list_en,sentence_list_fr, tokens2id_en, tokens2id_fr, max_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are  28469 french sentences\n",
      "there are  28469 english sentences\n"
     ]
    }
   ],
   "source": [
    "# print(corpus2id_en[0])\n",
    "\n",
    "print('there are ', len(corpus2id_fr), 'french sentences')\n",
    "print('there are ', len(corpus2id_en), 'english sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #get test sentences \n",
    "\n",
    "# test_tokens_list_en,test_sentence_list_en = tokens_sentences(test_en)\n",
    "# test_tokens_list_fr,test_sentence_list_fr = tokens_sentences(test_fr)\n",
    "\n",
    "# for sent in range(len(test_sentence_list_en)):\n",
    "#     if len(test_sentence_list_en[sent]) > 50 or len(test_sentence_list_fr[sent]) > 50:\n",
    "#         print(test_sentence_list_en[sent])\n",
    "#         print(test_sentence_list_fr[sent])\n",
    "\n",
    "# test_corpus2id_en, test_corpus2id_fr = convert_corpora2id_both(test_sentence_list_en,test_sentence_list_fr, tokens2id_en, tokens2id_fr, max_sentence_length)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NMTModel(nn.Module):\n",
    "    def __init__(self,vocab_size_fr, w_embedding_dim, p_embedding_dim, dec_embedding_dim, max_sentence_length, vocab_size_en, dropout_prob):\n",
    "        super(NMTModel, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(vocab_size_fr, w_embedding_dim, p_embedding_dim, dec_embedding_dim, max_sentence_length)\n",
    "        self.decoder = Decoder(dec_embedding_dim, vocab_size_en, max_sentence_length, dropout_prob)\n",
    "            \n",
    "    def forward(self, sent_fr, pos_fr, sent_en, train):\n",
    "        \n",
    "        average_context, stacked_contexts = self.encoder(sent_fr, pos_fr)\n",
    "        \n",
    "        pred, attention_weights = self.decoder(sent_en, average_context, stacked_contexts, train)\n",
    "          \n",
    "        return pred, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,vocab_size_fr, w_embedding_dim, p_embedding_dim, dec_embedding_dim, max_sentence_length):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.vocab_size_fr = vocab_size_fr\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        \n",
    "        self.w_embedding_dim = w_embedding_dim\n",
    "        self.p_embedding_dim = p_embedding_dim\n",
    "        \n",
    "        initrange = 0.5 / self.w_embedding_dim\n",
    "        self.dec_embedding_dim = dec_embedding_dim\n",
    "        \n",
    "        #encoder\n",
    "        self.w_embeddings = nn.Embedding(self.vocab_size_fr, self.w_embedding_dim)\n",
    "        self.p_embeddings = nn.Embedding(self.max_sentence_length, self.p_embedding_dim)\n",
    "        \n",
    "        self.w_embeddings.weight.data.uniform_(-initrange, initrange)\n",
    "        self.p_embeddings.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        \n",
    "        self.context_emb_dim = self.w_embedding_dim + self.p_embedding_dim\n",
    "        \n",
    "        #self.context_projection = nn.Linear(self.context_emb_dim, self.dec_embedding_dim)\n",
    "        #do we use non-linearity after attention\n",
    "        \n",
    "        #TODO: DROPOUT\n",
    "        \n",
    "        \n",
    "    def forward(self, sent_fr, pos_fr):\n",
    "        \n",
    "        #embedded = self.embedding(input).view(1, 1, -1)\n",
    "        #TODO:BATCH\n",
    "       \n",
    "        ws = self.w_embeddings(sent_fr)\n",
    "        ps = self.p_embeddings(pos_fr)\n",
    "        es = torch.cat((ws, ps), 1)\n",
    "    \n",
    "        stacked_contexts = es\n",
    "        average_context = torch.mean(stacked_contexts, dim = 0)\n",
    "            \n",
    "        return average_context, stacked_contexts\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, dec_embedding_dim, vocab_size_en, max_sentence_length, dropout_prob):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.vocab_size_en = vocab_size_en\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        \n",
    "        self.dec_embedding_dim = dec_embedding_dim*2\n",
    "        \n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.dropout = nn.Dropout(self.dropout_prob)\n",
    "        \n",
    "        initrange = 0.5 / self.dec_embedding_dim\n",
    "        self.embedding = nn.Embedding(self.vocab_size_en, self.dec_embedding_dim)\n",
    "        \n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)        \n",
    "        \n",
    "        self.lstm = nn.LSTM(self.dec_embedding_dim, self.dec_embedding_dim)\n",
    "        #self.bidirLSTM = nn.LSTM(self.embedding_dim, self.embedding_dim, bidirectional=True)\n",
    "        #TODO: LSTM, GRU \n",
    "       \n",
    "        self.pre_rnn_affine = nn.Linear(self.dec_embedding_dim*2, self.dec_embedding_dim)\n",
    "        #a linear layer after this before softmax\n",
    "        self.out_affine = nn.Linear(self.dec_embedding_dim, self.vocab_size_en)\n",
    "               \n",
    "    \n",
    "    def forward(self, gold_target_sent, encoder_avg_context, encoder_stacked_contexts, train):\n",
    "        \n",
    "        if train:\n",
    "            pred = []\n",
    "            attentions = []\n",
    "\n",
    "            embeds = self.embedding(gold_target_sent)\n",
    "            embeds = self.dropout(embeds)\n",
    "\n",
    "            output, (hidden, cell) = self.lstm(embeds.view(-1,1,200),(encoder_avg_context.view(1, 1, -1), torch.zeros(encoder_avg_context.view(1,1,-1).shape)))\n",
    "\n",
    "            for w in range(len(gold_target_sent)):\n",
    "\n",
    "                sw = output[w]\n",
    "                cj = F.softmax(torch.matmul(sw,torch.transpose(encoder_stacked_contexts,0,1)), dim = 1)\n",
    "\n",
    "                c_vec = cj.view(-1,1) *  encoder_stacked_contexts.squeeze()\n",
    "\n",
    "                sw = torch.cat((sw, c_vec),dim=0)\n",
    "\n",
    "                s_output = self.out_affine(sw)\n",
    "                s_output = F.log_softmax(s_output, dim=1)\n",
    "\n",
    "                pred.append(s_output)\n",
    "\n",
    "            pred = torch.stack(pred, dim=1)\n",
    "\n",
    "            return pred, attentions\n",
    "        \n",
    "        else:\n",
    "           \n",
    "            embeds = self.embedding(gold_target_sent)\n",
    "            embeds = self.dropout(embeds)\n",
    "\n",
    "            output, (hidden, cell) = self.lstm(embeds.view(-1,1,200),(encoder_avg_context.view(1, 1, -1), torch.zeros(encoder_avg_context.view(1,1,-1).shape)))\n",
    "\n",
    "            for w in range(len(gold_target_sent)):\n",
    "\n",
    "                sw = output[w]\n",
    "                cj = F.softmax(torch.matmul(sw,torch.transpose(encoder_stacked_contexts,0,1)), dim = 1)\n",
    "\n",
    "                c_vec = cj.view(-1,1) *  encoder_stacked_contexts.squeeze()\n",
    "\n",
    "                sw = torch.cat((sw, c_vec),dim=0)\n",
    "\n",
    "                s_output = self.out_affine(sw)\n",
    "                s_output = F.log_softmax(s_output, dim=1)\n",
    "\n",
    "                pred.append(s_output)\n",
    "\n",
    "            pred = torch.stack(pred, dim=1)\n",
    "\n",
    "            return decoder, attentions\n",
    "        \n",
    "        \n",
    "            decoder_outputs = []\n",
    "            decoder_attentions = []\n",
    "        \n",
    "            test_word = torch.tensor(np.asarray([tokens2id_en['<SOS>']]), dtype = torch.long)\n",
    "            \n",
    "            test_word_id = tokens2id_en['<SOS>']\n",
    "            \n",
    "            for w in range(self.max_sentence_length):\n",
    "       \n",
    "                if test_word_id == tokens2id_en['<EOS>']:\n",
    "                    \n",
    "                    break  \n",
    "                    \n",
    "                output = self.embedding(test_word)\n",
    "            \n",
    "                if w == 0:\n",
    "                    \n",
    "                    weighted_context = torch.zeros(output.shape)\n",
    "                    output = torch.cat((output.squeeze(), weighted_context.squeeze()), 0)\n",
    "                    \n",
    "                    output = F.relu(self.pre_rnn_affine(output))\n",
    "                    #TODO: start with 0 vector as h0\n",
    "\n",
    "                    output, hidden = self.rnn(output.view(1, 1, -1), encoder_avg_context.view(1, 1, -1))\n",
    "                    prev_hidden = hidden\n",
    "\n",
    "                    s_output = self.out_affine(output[0])\n",
    "                    s_output = F.log_softmax(s_output, dim=1) \n",
    "\n",
    "                    test_word_id = int(torch.argmax(s_output))\n",
    "                    test_word = torch.tensor(np.asarray([test_word_id]), dtype = torch.long)\n",
    "           \n",
    "                    \n",
    "                else:   \n",
    "                    #start with weighted context\n",
    "                    \n",
    "                    output = torch.cat((output.squeeze(), weighted_context.squeeze()), 0)\n",
    "\n",
    "                    output = F.relu(self.pre_rnn_affine(output))\n",
    "\n",
    "                    output, hidden = self.rnn(output.view(1, 1, -1), prev_hidden.view(1, 1, -1))\n",
    "                    prev_hidden = hidden\n",
    "\n",
    "                    s_output = self.out_affine(output[0])\n",
    "\n",
    "                    s_output = F.log_softmax(s_output, dim=1)\n",
    "                    \n",
    "                    test_word_id = int(torch.argmax(s_output))\n",
    "                    \n",
    "                    test_word = torch.tensor(np.asarray([test_word_id]), dtype = torch.long)\n",
    "                    \n",
    "                \n",
    "                attention_weights_word = F.log_softmax(torch.matmul(encoder_stacked_contexts, prev_hidden.view(-1,1)), dim = 0)\n",
    "\n",
    "                weighted_context = torch.sum(torch.mul(attention_weights_word, encoder_stacked_contexts), dim = 0)\n",
    "\n",
    "                attentions.append(attention_weights_word)\n",
    "                \n",
    "                decoder_outputs.append(test_word_id)\n",
    "                \n",
    "                                  \n",
    "\n",
    "            attention_weights = torch.stack(attentions, dim=0)            \n",
    "            \n",
    "            return decoder_outputs, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, total loss, duration\n",
      "0 6.695893812179565 0:00:00.315016\n",
      "1 6.664563846588135 0:00:00.296277\n",
      "2 6.632889890670777 0:00:00.291619\n",
      "3 6.600469732284546 0:00:00.344770\n",
      "4 6.566849088668823 0:00:00.324160\n",
      "5 6.531475591659546 0:00:00.284916\n",
      "6 6.493671035766601 0:00:00.295270\n",
      "7 6.45253586769104 0:00:00.284752\n",
      "8 6.406772899627685 0:00:00.286524\n",
      "9 6.354709911346435 0:00:00.292317\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xd8FVX6x/HPNwkQuii9RpCiorSA\n9CIWbNi72MUGdl3Xbbq7rv52bdhQaTZUFMvau4CIBEPvVaQJBOlI5/n9McN6jSkXzGVSnvfrdV/J\nzJ0z89zJZJ4758ycIzPDOeecy09S1AE455wrGjxhOOeci4snDOecc3HxhOGccy4unjCcc87FxROG\nc865uHjCOMAkmaTD9rNsF0lzCzqmOLbbVNJkSZsk3RRnmf3+nNnWkxauK+X3rquwklRD0phw/z58\ngLe9WVLDA7zNspLek7RB0htxlhkl6eoC2v5MSd0LYl37uf364X5PjiqG/eUJIxeSFkvaGv5h976e\nPMAx/Oqka2Zfm1nTAxlD6C5glJlVNLPHs79ZkP/MJVRfYA1QycxuT9RGcvo7mVkFM1uUqG3m4hyg\nBnCImZ2b/U1J90p6OVEbN7MjzWzUgdhWuI3Fko6L2f6ScL/vTuR2E6HYfmsrIKeZ2edRB1EINABe\nizqIYqwBMMtKzlO0DYB5ZrYr6kB+L0kpxeFzxM3M/JXDC1gMHJfD/DLAeqB5zLxqwFagejh9DbAA\nWAu8C9SOWdaAw8LfRwFXx7x3OTA2/H1MuOwWYDNwPtAdWBaz/OHhOtYDM4HeMe89DzwFfABsAjKA\nRnl83t7hOtaH6zw8nP8lsBvYFsbRJFu5+7O9/2TM57wOmA+sC2NRTLkrgdnhe58ADXKJKy1cV0o4\nXTvcp2vDfXxNzLLtgExgI7AKeCScnwq8DPwUfr7vgBq5bO9uYGG4z2YBZ8a8dxgwGthAcEUwIo/9\n+QawMlx2DHBkLss9D+wEdoT777hw3j9jlsn+d18M3AFMC9c/AkiNef90YEq4HxYCvfL5O+09HisD\nLwJZwA/An4Gk2GMTeCj8m30PnJTH58/x2ATuCz/rzjCOq7KV65Xt/akx/yv/AL4J/zafAlVjyrUH\nxoXbmwp0z+9/O49tVQaGAD8Cy4F/Askx++Eb4FGCY/CfQCOC/5OfwuNiOHBQuPxLwB6C88Nmgqv1\nNOI/pu8FXg//LpvCfZke2Xkxqg0X9he5JIzwvaHA/THTNwIfh78fGx40rQmSyxPAmJhl40oY2ZcN\np7sTnjiAUuHBdQ9QOtzuJqBp+P7z4QHYjuBKcjjwWi6fpwlBYjo+XO9d4bpL5xRnDuV/834Y+/vA\nQUB9gpNQr/C9M8L1Hx7G9mdgXC7rzv7PNRp4miAJtAzX2zN871ugT/h7BaB9+Pu1wHtAOSAZaENQ\n/ZPT9s4N/4GTCJL0FqBW+N6rwJ/C91KBznnskyuBiuEx8BgwJY9ln+fXCSL79P/+7jHH5oQwzoMJ\nEu914XvtCJLI8WGcdYBm+fyd9h6PLwL/DeNOA+YRntAJjs2dBF+GkoHrgRXEfAmIWWd+x+a9wMt5\n7I/fvB/GvpDgWC0bTj8YvleH4GR9cviZjw+nq+X3v53Ltt4BngXKA9XDfX1tzH7YBfQnOHbLEnyR\nOD78W1cj+ILwWG7nEvbtmL6XIMmfHO73B4DxiTrv5ffyNoy8vSNpfczrmnD+K8CFMctdFM4DuBgY\namaTzGw78Eegg6S0Ao6tPcFJ8UEz22FmXxKcoGPjesvMJlhwyTyc4GDMyfnAB2b2mZntJPgWWRbo\n+DtjfNDM1pvZEuCrmO1fCzxgZrPD2P4FtJTUIK+VSaoHdAb+YGbbzGwKMBjoEy6yEzhMUlUz22xm\n42PmH0JwYtxtZhPNbGNO2zCzN8xshZntMbMRBFdI7WLW04DginGbmY3NLVYzG2pmm8Jj4F6ghaTK\neX2+ffR4GOdagmS4d99eRXD8fRZ+huVmNie/lYUNsOcDfwzjXgw8zC/7FuAHMxtkQd37C0AtgraI\n7OI5NvfHMDObZ2ZbCb517/3MlwAfmtmH4Wf+jOBK8+R93YCkGsBJwC1mtsXMVhNcTVwQs9gKM3vC\nzHaZ2VYzWxDu7+1mlgU8AnSLc3v5HdMQfIn8MNzvLwEt9vVzFRRPGHk7w8wOinkNCud/CZSVdEx4\nkmsJvB2+V5vgch4AM9tM8G2nTgHHVhtYamZ7Yub9kG07K2N+/5ngnzi3dcXGvAdYyu+PObftNwAG\n7E3EBFdCimN7tYG1ZrYpZl7sZ76K4BvoHEnfSTo1nP8SQbXXa5JWSPq3pFI5bUDSpZKmxMTWHKga\nvn1XGOeE8E6bK3NZR7KkByUtlLSR4BsmMespCLnt23oE38T3VVWCq4EfYublejyZ2c/hrzkdU/Ec\nm/sjr+Pp3NgvdwQn4Vr7sY0GBFdIP8as61mCK429lsYWkFRd0muSlod/75eJ/2+d3zENv/3cqVHd\nNeiN3vvBzPZIep3gG9Mq4P2YP/gKgoMOAEnlCb7dLs9hVVsIqkn2qrkPYawA6klKivnHrE9QjbCv\nVgBH7Z2QJIITT04x52RfG2uXElTpDd/HciuAgyVVjNnf9QnjNLP5wIWSkoCzgJGSDjGzLQR15/eF\nV3ofAnMJ6qn/J0z+g4CewLdmtlvSFIIkgZmtJKiSQVJn4HNJY8xsQbY4LyJoRziOIFlUJqj3V5yf\n8/ccF0sJ6tRzktffaQ2/XEHNCuf9b9/uo997bO7P8fSSmV2T75L5b2spsJ2gfSS3xuzsZR4I5x1t\nZj9JOgN4Mo/lY+V5TBc2foWx/14huIS/mF+qo/bOv0JSS0llCKpbMsJL/OymAGdJKhfePntVtvdX\nAbndI59BcGK5S1Kp8L7y09i/u5leB06R1DP85n07wT/NuDjL5xVnTp4B/ijpSABJlSX95vbK7Mxs\naRjTA5JSJR1NsM+Gh+u5RFK18CS1Piy2W1IPSUeF1S4bCU6MOd3SWJ7gnzsrXN8VBFcYhNPnSqob\nTq4Ll81pPRUJ9t9PBCf+f+X32bKZApws6WBJNYFb9qHsEILjr6ekJEl1JDUL38v17xRWd7wO3C+p\nYpg8byP4tryvfu+xuQpICxN/PF4GTpN0Ynh1lyqpe8zfKu5tmdmPBA3qD0uqFO7DRpLyqmKqSNCg\nvV5SHeDOHLaR237P85gubDxh5O29bM9h7K12wsz2/lPUBj6Kmf8F8BfgTYK7LBrx6/rPWI8S3KWx\niqBOOPtBci/wQnhpfF7sG2a2g+DOppMIvh0+DVwaT311dmY2l6Ae+IlwXacR3FK8I85VDADOkbRO\n0m+e08hhe28D/0dQRbQRmBF+jnhcSNBouIKgGvBvYZ01BHe9zJS0OYzpAjPbRvANfSRBsphN0Mj4\nmxOhmc0iqLf/luBvchTBHTF7tQUywvW/C9xsZt/nEOOLBNUKywm+rY/PYZm8vERwp89igpPXiHgL\nmtkE4AqCY2sDwWfde8Wb39+pP8ExvYjgjqhXCG7w2CcFcGzufZjvJ0mT4tjeUoIrunsIkv1SgpN2\nPOe3nLZ1KUH13CyCLwYjybt66z6Cm1w2ENyV+Fa29x8A/hz+H9+RQ/m8julCRWYl5dZv55xzv4df\nYTjnnIuLJwznnHNx8YThnHMuLp4wnHPOxaVYPYdRtWpVS0tLizoM55wrMiZOnLjGzKrFs2yxShhp\naWlkZmZGHYZzzhUZkn7If6mAV0k555yLiycM55xzcfGE4ZxzLi4JTRiSDpI0UtIcSbMldZA0IuwN\ndIqCoQun5FK2l6S5khZIujuRcTrnnMtfohu9BxAMLHSOpNJAOTM7f++bCga835C9UNhJ3FMEg5Is\nA76T9G7Y149zzrkIJCxhSKoEdCUYoWpvh2Q7Yt4XcB7BaFzZtQMWWDg4vaTXCDoX84ThnHMRSWSV\nVEOCniOHSZosaXA4NsReXYBV4RgG2dXh14OULCOXwVck9ZWUKSkzKyuroGJ3zjmXTSITRgpBl78D\nzawVQbfJsW0RFxKMkZyTnAaaybFbXTN7zszSzSy9WrW4nj35jce/mM93i9fuV1nnnCspEpkwlhEM\nXJ8RTo8kSCCEwwueRe79/C8jGPFtr7oEfcUXuA1bdzI84wfOfeZbrn7hO+au3JR/IeecK4ESljDC\n4SyXSmoazurJL20QxwFzzGxZLsW/AxpLOjRsLL+AYMCaAle5bCm+uqM7d57YlIxFa+k1YAx3vDGV\n5eu3JmJzzjlXZCX6OYz+wHBJ04CW/DJU5QVkq46SVFvShwDhWLr9gE8IRkh73cxmJirIcqVTuLHH\nYYy5qwdXdz6Ud6esoMdDo7j/g1ms2xLvoHPOOVe8FasR99LT060g+pJavn4rj342jzcnLaNC6RSu\n696IKzqlUa50sep6yznnkDTRzNLjWtYTRu7mrtzEfz6Zw+ezV1O9YhluPq4x56XXo1SyPyDvnCse\n9iVh+JkvD01rVmTwZW1547oO1Du4HH96ewYnPjqGD6f/SHFKtM45Fw9PGHFom3YwI6/rwKBL00lO\nEjcMn8QZT33DuIVrog7NOecOGE8YcZLE8UfU4ONbuvLvc45m9abtXDQog0uHTmDmit/0buKcc8WO\nt2Hsp207d/Pit4t56quFbNi6k9Nb1ub245tS/5ByB2T7zjlXELzR+wDasHUnz4xeyLBvvmf3HuPi\nYxrQ79jDqFqhzAGNwznn9ocnjAis2riNxz6fz+uZS0lNSeKarg25uktDKpTxW3Gdc4WXJ4wILcza\nzEOfzOWjGSs5pHxp+h97GBcd04DSKd5c5JwrfPy22gg1qlaBgZe04e0bOtK4RgXufW8Wxz0ymv9O\nWc6ePcUnOTvnSh5PGAnSqn4VXr2mPc9f0ZbyZVK4+bUpnPrEWEbPy/JnOJxzRZInjASSRPem1fmg\nf2ceO78lG7ft5LKhE7h4cAZTl66POjznnNsnnjAOgKQkcUarOnxxezf+dtoRzFm5idOf+oYbh09i\nUdbmqMNzzrm4eKN3BDZt28mgr79n8NeL2L5rD+e3rcctPRtTvVJq1KE550oYv0uqiMjatJ0nvpzP\nKxlLKJWcxJWd07i2WyMqpZaKOjTnXAnhCaOIWbxmCw9/No/3pq6gSrlS9Du2MZe0r0+ZlOSoQ3PO\nFXN+W20Rk1a1PE9c2Ir3+3fmyNqV+cf7fiuuc67w8YRRiDSvU5mXrz6GF69sR4Uypbj5tSn0fmos\nY+d7r7jOueh5wiiEujapxgf9O/Po+S1Yt2UnlwzJoM+QDO8V1zkXKU8YhVRSkjizVV2+uL0bfz7l\ncKYv38Apj4/l1hFTWLr256jDc86VQN7oXURs2LqTgaOCXnHN4NIODbixx2FUKV866tCcc0VYoWn0\nlnSQpJGS5kiaLalDOL+/pLmSZkr6dy5lF0uaLmmKpOKZBfZB5bKluPukZoy6sztntKrN0G++p+t/\nvuLpUQvYtnN31OE550qAhF5hSHoB+NrMBksqDZQDWgF/Ak4xs+2SqpvZ6hzKLgbSzSzuFt/ifIWR\n3dyVm/j3x3P4Ys5qalZK5bbjm3B2m7okJynq0JxzRUihuMKQVAnoCgwBMLMdZrYeuB540My2h/N/\nkyxc/prWrMiQy9syom97alRO5a43p3HSgDF8MXuVd27onEuIRFZJNQSygGGSJksaLKk80AToIilD\n0mhJbXMpb8CnkiZK6pvbRiT1lZQpKTMrK6vgP0Uhd0zDQ3jnho48fXFrdu42rnohk/OfG8/kJeui\nDs05V8wkrEpKUjowHuhkZhmSBgAbgTOBL4GbgbbACKChZQtEUm0zWyGpOvAZ0N/MxuS1zZJUJZWT\nnbv38NqEJQz4Yj5rNu/g5KNqcueJzTi0avmoQ3POFVKFokoKWAYsM7OMcHok0Dqc/5YFJgB7gKrZ\nC5vZivDnauBtoF0CYy0WSiUn0adDGqPu7MEtxzVm1Nwsjn9kNH95ZwZZm7ZHHZ5zrohLWMIws5XA\nUklNw1k9gVnAO8CxAJKaAKWBXzVsSyovqeLe34ETgBmJirW4qVAmhVuOa8LoO3twYbv6vDphCd3/\n8xWPfT6PLdt3RR2ec66ISvRdUi2BwQRJYRFwBbAFGAq0BHYAd5jZl5JqA4PN7GRJDQmuKgBSgFfM\n7P78tlfSq6Ry8/2aLfznkzl8OH0lVSuU4ebjGnNB23qUSvbnNp0r6by3WpejyUvW8cBHc5jw/Voa\nVi3PnSc2pVfzmkh+K65zJVVhacNwhUyr+lUY0bc9Qy5LJyVZXD98Emc+PY6MRT9FHZpzrgjwhFHC\nSKLn4TX46Oau/Pvso1m5YRvnPzeeq57/jnmrNkUdnnOuEPMqqRJu287dDPtmMU+PWsCW7bs4p01d\nbj2+CbUql406NOfcAeBtGG6frduyg6e+WsCL3/6ABNd0ach13RtRoUxK1KE55xLIE4bbb0vX/sxD\nn87lv1NWULVCaW45rgkXtK1Hit9R5Vyx5I3ebr/VO7gcAy5oxbv9OtGwWgX+/M4Meg342vuocs55\nwnA5O7ruQYzo255Bl6azZ0/QR9XFgzOYsdxH/XOupPKE4XIlieOPqMEnt3bl76cfyZyVmzjtybHc\n9voUVqzfGnV4zrkDzNswXNw2btvJ018tZOg33yPg6i6Hcl23RlRMLRV1aM65/eRtGC4hKqUGo/59\neXs3Tmpek6e+WkiPh0bx8vgf2LV7T9ThOecSzBOG22d1q5TjsWwN4yc+5oM3OVfcecJw+y22YdwM\nrnohk4sGecO4c8WVJwz3u2RvGJ+7ahOnPjGW20Z4w7hzxY03ersC5Q3jzhUt3ujtIpNTw3j3/4zi\nJW8Yd67I84ThEiK2YbxR9Qr8JWwY/3yWN4w7V1R5wnAJlb1h/OoXvWHcuaLKE4ZLOG8Yd6548EZv\nd8Bt3LaTgaMWMmRs0DB+VedDub67N4w7FwVv9HaFWqXUUvyh1y8N40+PChvGv13MTm8Yd67QSmjC\nkHSQpJGS5kiaLalDOL+/pLmSZkr6dy5le4XLLJB0dyLjdNH4TcP4f2fSyxvGnSu0En2FMQD42Mya\nAS2A2ZJ6AKcDR5vZkcBD2QtJSgaeAk4CjgAulHREgmN1EcmpYfzCQeOZvswbxp0rTBKWMCRVAroC\nQwDMbIeZrQeuBx40s+3h/NU5FG8HLDCzRWa2A3iNIMm4Yip7w/i8VZvp/dRY7nxjKqs3bYs6POcc\nib3CaAhkAcMkTZY0WFJ5oAnQRVKGpNGS2uZQtg6wNGZ6WTjvNyT1lZQpKTMrK6ugP4M7wEolJ3Fp\nhzRG3dmdvl0a8s6U5fT4zygGjlrI9l27ow7PuRItkQkjBWgNDDSzVsAW4O5wfhWgPXAn8LokZSub\nfRogx0ptM3vOzNLNLL1atWoFFryLVqXUUvzx5MP59NZudGh0CP/38RyOf2QMn8xc6e0bzkUkkQlj\nGbDMzDLC6ZEECWQZ8JYFJgB7gKo5lK0XM10XWJHAWF0hdWjV8gy+rC0vXdWOMilJXPvSRC4enMGc\nlRujDs25EidhCcPMVgJLJTUNZ/UEZgHvAMcCSGoClAbWZCv+HdBY0qGSSgMXAO8mKlZX+HVpXI2P\nbu7Cfb2PZOaKjZw84Gv+/M501m7ZEXVozpUYKQlef39geHjSXwRcQVA1NVTSDGAHcJmZmaTawGAz\nO9nMdknqB3wCJANDzWxmgmN1hVxKchKXdUyjd4vaPPb5PF7OWMK7U1Zwy3FN6NOhAaWS/bEi5xLJ\nn/R2Rda8VZv4x/uz+Hr+GhpVK89fTj2C7k2rRx2Wc0WKP+ntSoQmNSry4pXtGHRpOrv3GJcP+44r\nhk1gYdbmqENzrljyhOGKtNjnN+45uRnfLV7HiY+O4R/vz2LD1p1Rh+dcseIJwxULZVKS6du1EV/d\n0Z1z2tRl6Dff0+OhUQzP+IHde4pPtatzUfKE4YqVahXL8ODZR/Nev84cVq0Cf3p7Bqc+MZZvF/4U\ndWjOFXmeMFyx1LxOZUZc254nL2rFxq07uXDQeK57aSJL1/4cdWjOFVmJvq3WuchI4tSja3Pc4TUY\nNGYRT49ayJdzV3N150O5ocdhVCjjh79z+8KvMFyxl1oqmf49G/PlHd045ahaPD1qIcc+NIqRE5ex\nx9s3nIubJwxXYtSqXJZHz2/JWzd0pNZBZbnjjamc+fQ3TPxhXdShOVckeMJwJU7r+lV4+/qOPHxu\nC37csI2zB47jltcm8+MGH1/cubx4wnAlUlKSOLtNXb66ozs39mjEhzNWcuxDo3n8i/ls2+ndqDuX\nE08YrkQrXyaFO09sxhe3daN702o88tk8ej48mvemrvBu1J3LxhOGc0C9g8sx8JI2vHpNeyqmptD/\n1cmc9+y3zFjuw8Q6t5cnDOdidGh0CB/c1IV/nXkUC7O2cNqTY7n7zWnejbpzeMJw7jeSk8RFx9Tn\nqzu6c2WnQ3lj4jKOfXgUr05Y4rfhuhLNE4ZzuahcthR/OfUIPrypC02qV+SPb03nrIHjvJrKlVie\nMJzLR9OaFRlxbXseOa8Fy9b9TO8nx/LX/87w3nBdiZNvwpDUT1Kl8PdnJU2Q1DPxoTlXeEjirNZ1\n+eL27vRp34CXx/9Az4dH8ebEZX43lSsx4rnC6GtmGyWdANQBrgf+ndiwnCucKpctxX2nN+fdfp2p\nU6Uct78xlfOfG8/clZuiDs25hIsnYez9+nQSMMzMJsZZzrliq3mdyrx9fUceOOso5q3axMmPf839\nH8xi8/ZdUYfmXMLEc+KfKulD4DTgI0kV+CWJOFdiJSWJC9vV58vbu3Num7oM+vp7ej48iven+UN/\nrnhSfge2pGSgDbDAzNZKOgSob2aT8125dBAwGGhOkGSuBE4ErgGywsXuMbMPcyi7GNgE7AZ2xTNI\neXp6umVmZua3mHMJMWnJOv7yzgxmrthIl8ZVubf3kTSqViHqsJzLk6SJ8ZxfIb4rjLbAjDBZXAj8\nAVgTZywDgI/NrBnQApgdzn/UzFqGr98kixg9wmXi+jDORal1/Sq8268z9/U+kilL1tPrsTE89Mlc\ntu7wvqlc8RBPwngO2CrpaOAeYBXwcn6FwjurugJDAMxsh5mt/x2xOlfoJSeJyzqm8cUd3Tj16No8\n+dUCjntkNJ/NWhV1aM79bvEkjF0W1FudDgwws4eBinGUa0hQ7TRM0mRJgyWVD9/rJ2mapKGSquRS\n3oBPJU2U1De3jUjqKylTUmZWVlZuizl3QFWvmMqj57fktb7tKVc6mWtezOSq57/zIWJdkRZPG8bX\nwLsE7Q7dCK4wpprZUfmUSwfGA53MLEPSAGAj8CRBlZYB/wBqmdmVOZSvbWYrJFUHPgP6m9mYvLbp\nbRiuMNq5ew/Dvvmexz6fz+49xo09DuPabg0pk5IcdWjOFXgbxvmAgGvN7EegLvBIHOWWAcvMLCOc\nHgm0NrNVZrbbzPYAg4B2ORU2sxXhz9XA27kt51xhVyo5ib5dG/HF7d3oeXh1HvlsHic+OobR8/yK\n2BUt+SaM8MQ9FCgjqRfws5kNi6PcSmCppKbhrJ7ALEm1YhY7E5iRvayk8pIq7v0dOCGn5ZwrSmpV\nLsvTF7fhxSvbIYnLhk7ghuETfaQ/V2TE0zXI2cAkoA9wKZAp6cw4198fGC5pGtAS+Bfwb0nTw3k9\ngFvD7dQOn/cAqAGMlTQVmAB8YGYf78Pncq7Q6tqkGh/f0oXbj2/CF7NX0/Ph0Tw7eiE7d++JOjTn\n8hRPG8ZU4AQzWxVO1wA+NbMWByC+feJtGK6oWbr2Z+57byafz15N4+oV+McZzWnf8JCow3IlSEG3\nYSTtTRahrDjLOefyUe/gcgy+rC2DLk3n5x27ueC58dw6YgqrN22LOjTnfiMljmU+DauKXgmnLwA+\nSVxIzpU8xx9Rg86HVeWprxbw3JhFfD5rFbef0IRL2jcgJdm/n7nCIZ4qKQHnAZ0I7pYaA4y0QthZ\njldJueJgUdZm/vbuTL6ev4YjalXin2c2p3X93B5Xcu732ZcqqXwTRlHiCcMVF2bGh9NX8o/3Z7Fy\n4zbOT6/HH05qxsHlS0cdmitm9iVh5FolJWkdOfdKK8DM7OD9jM85lw9JnHJ0Lbo1rcbjX8xnyNjv\n+Wz2Ku7tfSSnHV2L4MLfuQMrr8rRqkC1HF575zvnEqxCmRTuOflwPripM/WqlOWmVydzzYuZ/uyG\ni0SuCSN8GjvX14EM0rmSrlnNSrx1Qyf+fMrhjF2whhMeGcPwjB/Ys6f4VCm7ws9vv3CuiEhOEld3\nacgnt3TlqLqV+dPbM7hw0Hi+X7Ml6tBcCeEJw7kipsEh5Rl+9TH839lHMevHjfR6bAzPjl7ILn9S\n3CWYJwzniiBJnN+2Pp/f1o2uTarxwEdzOPPpccxasTHq0FwxlmvCkLRO0tocXuskrT2QQTrnclaj\nUirP9WnDUxe15scNW+n95Fge+mQu23Z6M6MreHk96V31gEXhnNtve2/B7djoEP75wWye/GoBH834\nkf87+2jS0/zud1dw4r5LCqhM0Ivs3pdzrhCpUr40D5/XgheubMe2nXs499lvuffdmWzZvivq0Fwx\nEU/35qdImkcwIFJG+PPLRAfmnNs/3ZpU45Nbu3JZhzRe+HYxJ/hgTa6AxNPofT9BP1JzzawecCIw\nKpFBOed+nwplUri395GMvK4DqaWSuGzoBG57fQrrtuyIOjRXhMWTMHaZWRaQJElm9hnQOsFxOecK\nQJsGB/PBTV3of+xhvDtlBcc/OpoPpv1IcepDzh048SSMDeEwqWOBFyU9DPgN384VEamlkrn9hKa8\n268ztSqX5cZXJtH3pYms2uhjbrh9E0/COAPYBtxCUBW1HDg1gTE55xLgiNqVePuGjtxzcjPGzMvi\nuEdG89qEJX614eIWT8L4Y3in1E4zG2JmjwC3JTow51zBS0lOom/XRnxyS1eOqFWJu9+azsWDM/jh\nJ+9exOUvnoTRK4d5pxR0IM65AyetanlevaY9/zrzKKYv28CJj41h0JhF7PbODF0e8nrS+1pJk4Gm\nkibFvOYDs+JZuaSDJI2UNEfSbEkdJN0rabmkKeHr5FzK9pI0V9ICSXfv38dzzuUmKUlcdEx9Prut\nG50Pq8r9H87mrKe/Yc5K715vsTGXAAAV20lEQVTE5SzXEfckVQEOAR4AYk/Ym8xsdVwrl14Avjaz\nwZJKA+UI2kI2m9lDeZRLBuYBxxM89/EdcKGZ5ZmofMQ95/aPmfH+tB+5992ZbNi6kxt6HMaNPRpR\nJiU56tBcgu3LiHt5Pem9zswWmNm5QFmCk/fxxDl4kqRKQFdgSLi+HWa2Pp6yQDtggZktMrMdwGvA\n6XGWdc7tI0mc1qI2n93WjdNa1ObxL+Zz6uNjmbRkXdShuUIknie9bwReB+qHr9cl3RDHuhsCWcAw\nSZMlDQ5vzwXoJ2mapKHhlUx2dYClMdPLwnk5xddXUqakzKwsf5rVud/j4PKlefT8lgy7oi1btu/i\n7IHjuO89717EBeJp9L4WaGdm95jZPcAxwHVxlEsheMBvoJm1ArYQVG0NBBoBLYEfgYdzKJvTgMU5\n1p2Z2XNmlm5m6dWq+cixzhWEHk2r8+lt3ejTvgHDvlnMiY+N4ev5/oWspIsnYQjYGTO9k5xP6Nkt\nA5aZWUY4PRJobWarwtt09wCDCKqfcipbL2a6LrAijm065wpIhTIp/P305rx+bQdKJyfRZ8gE7nhj\nKht+3pl/YVcs5XWX1N6uz18Cxkv6s6Q/A+OAF/JbsZmtBJZKahrO6gnMklQrZrEzgRk5FP8OaCzp\n0LCx/ALg3Xw/jXOuwLU79GA+vLkLN3RvxNuTl9NrwBjGLVwTdVguAnldYUwAMLN/A32Bn4GtwHV5\n3eGUTX9guKRpBFVQ/wL+LWl6OK8HcCuApNqSPgy3uQvoB3wCzAZeN7OZ+/rhnHMFI7VUMnf1asbb\nN3SkbKlkLh6cwQMfzmb7Lh+oqSTJ67bayWHbQ5Hht9U6l3g/79jF/R/MZnjGEo6oVYkBF7SkcY2K\nUYfl9tO+3FabV8JYBjySW8Gwi5BCxROGcwfO57NW8Yc3p7F5+y7+eFIzLuuYhhRP86YrTArkOQwg\nGagAVMzl5ZwrwY47ogYf39KVTodV5d73ZnHZsO9Y7T3gFmt5XWFMMrMiNe6FX2E4d+CZGS9nLOH+\nD2ZRtlQyD559NCceWTPqsFycCuoKw68tnXP5kkSf9g14v38X6lQpy7UvTeTuN6f5w37FUF4Jo+cB\ni8I5V+QdVr0Cb13fiRu6N2JE5lJOfvxrJnvXIsVKXn1JrT2QgTjnir7SKUnc1asZI/p2YNdu45xn\nvmXA5/PZtdsH6SwO4nnS2znn9km7Qw/mo1u60LtFbR79fB7nPfutD9JUDHjCcM4lRKXUUjx6fkse\nv7AVC1Zv5uQBX/N65lIfErYI84ThnEuo3i1q8/EtXTmqbmXuGjmN61+exLotO6IOy+0HTxjOuYSr\nfVBZXrm6PX88qRlfzFnlvd8WUZ4wnHMHRFKSuLZbI965sROVypaiz5AJ/P29WWzb6f1RFRWeMJxz\nB9SRtSvzfv/OXN4xjaHffE/vJ8cy+0cfR7wo8IThnDvgUkslc2/vI3n+iras+3knpz/5DYO/XsSe\nPd4gXph5wnDORaZ70+p8fHMXujWtxj8/mE2foRn8uGFr1GG5XHjCcM5F6pAKZXiuTxv+7+yjmLxk\nPb0e+5oPpv0YdVguB54wnHORk8T5bevzwU1dSKtanhtfmcRtr09h0zYfDrYw8YThnCs0Dq1anpHX\ndeCmno15Z/JyThrwNZmLvZeiwsIThnOuUCmVnMRtxzfhjes6kiRx3rPf8vCnc9np/VFFzhOGc65Q\natOgCh/e3IWzW9fliS8XcPbAcSzK2hx1WCWaJwznXKFVoUwK/zm3BQMvbs2StT9zyuNjeSVjifdH\nFZGEJgxJB0kaKWmOpNmSOsS8d4ckk1Q1l7K7JU0JX+8mMk7nXOF20lG1+PjmrrRpUIV73p7ONS9O\n9P6oIpDoK4wBwMdm1gxoAcwGkFQPOB5YkkfZrWbWMnz1TnCczrlCrmblVF68sh1/PfUIxszL4tQn\nxjJ92YaowypREpYwJFUCugJDAMxsh5mtD99+FLgL8OtK51zckpLElZ0P5Y3rOmBmnP3MOF7/bmnU\nYZUYibzCaAhkAcMkTZY0WFJ5Sb2B5WY2NZ/yqZIyJY2XdEZuC0nqGy6XmZXlvV86VxK0qHcQ7/Xv\nTNu0Ktz15jT++NZ0tu/yTgwTTYlqPJKUDowHOplZhqQBwA6Cq44TzGyDpMVAupmtyaF8bTNbIakh\n8CXQ08wW5rXN9PR0y8zMLPDP4pwrnHbvMR76dC4DRy2kRb2DGHhxa2ofVDbqsIoUSRPNLD2eZRN5\nhbEMWGZmGeH0SKA1cCgwNUwWdYFJkmpmL2xmK8Kfi4BRQKsExuqcK4KSk8QfejXjmUvasHD1Zk59\nYizjFvzm+6crIAlLGGa2ElgqqWk4qycwycyqm1mamaURJJXW4bL/I6mKpDLh71WBTsCsRMXqnCva\nejWvyX/7deKQ8qW5ZEgGz4xe6LfeJkCi75LqDwyXNA1oCfwrtwUlpUsaHE4eDmRKmgp8BTxoZp4w\nnHO5alStAu/c2ImTmtfiwY/mcP3Lk7wvqgKWsDaMKHgbhnPOzBj89fc8+PEc0g4px7N92nBY9YpR\nh1VoFZY2DOecO+AkcU3Xhrx81TFs2BoMzvThdO8uvSB4wnDOFUsdGh3Ce/0706RmRW4YPokHPpzN\nLu/A8HfxhOGcK7ZqVS7La33b06d9A54ds4g+QyawZvP2qMMqsjxhOOeKtTIpyfzjjOY8fG4LJi1Z\nx2lPjGXyknVRh1UkecJwzpUIZ7epy5vXdyQlORhj4+XxP/itt/vIE4ZzrsRoXqcy7/XrTMdGVfnz\nOzO4c+Q0tu30LkXi5QnDOVeiHFSuNEMvb8tNPRszcuIyzh44jqVrf446rCLBE4ZzrsRJThK3Hd+E\nIZels2Ttz5z25FhGz/POS/PjCcM5V2L1PLwG7/XrTM1KqVw+bAJPfDGfPXu8XSM3njCccyVaWtXy\nvH1DJ05vUZuHP5tH35cy2bDVuxTJiScM51yJV7Z0Mo+e35J7TzuCUXOzOP3JscxZuTHqsAodTxjO\nOUfQpcjlnQ7ltb7t+XnHbs58ahz/nbI86rAKFU8YzjkXIz3tYN7v35nmdSpx82tTuPfdmez0LkUA\nTxjOOfcb1Sul8so17bmiUxrPj1vMRYPGs3rjtqjDipwnDOecy0Gp5CT+dtqRDLigJTOWb+SUJ8aS\nuXht1GFFyhOGc87l4fSWdXj7xo6UL53MBc+NZ9g335fYLkU8YTjnXD6a1azEf/t1pnvTatz33ixu\nGTGFn3fsijqsA84ThnPOxaFy2VI81yedO05owrtTV3DW0+NYvGZL1GEdUJ4wnHMuTklJot+xjXn+\ninas3LiN054cy7cLf4o6rAPGE4Zzzu2jbk2q8V6/ztSolMplQyfw/rQVUYd0QCQ0YUg6SNJISXMk\nzZbUIea9OySZpKq5lL1M0vzwdVki43TOuX1V7+ByjLyuA0fXrUz/VyczdOz3UYeUcIm+whgAfGxm\nzYAWwGwASfWA44ElORWSdDDwN+AYoB3wN0lVEhyrc87tk4PKleblq4/hhCNq8Pf3Z/GvD2cX684L\nE5YwJFUCugJDAMxsh5mtD99+FLgLyG3Pngh8ZmZrzWwd8BnQK1GxOufc/kotlczTF7ehT/sGPDdm\nEbe+PoUdu4rnk+EpCVx3QyALGCapBTARuBnoCSw3s6mScitbB1gaM70snPcbkvoCfQHq169fMJE7\n59w+SE4Sfz/9SGpWTuU/n8xlzebtPHNJGyqmloo6tAKVyCqpFKA1MNDMWgFbgHuBPwF/zadsTpkk\nx6sRM3vOzNLNLL1atWq/I1znnNt/krixx2E8dG4LMhat5bxnx7OqmHUnksiEsQxYZmYZ4fRIggRy\nKDBV0mKgLjBJUs0cytaLma4LlIzbEJxzRdo5beoy5PK2/PDTFs56ehwLVm+OOqQCk7CEYWYrgaWS\nmoazegKTzKy6maWZWRpBYmgdLhvrE+AESVXCxu4TwnnOOVfodWtSjRF9O7B9127OeWYcE38oHn1Q\nJfouqf7AcEnTgJbAv3JbUFK6pMEAZrYW+AfwXfj6ezjPOeeKhKPqVuat6ztRpVxpLhqUwSczs38v\nLnpUnDrRSk9Pt8zMzKjDcM65//lp83aufCGT6cvW8/fTm3NJ+wZRh/QrkiaaWXo8y/qT3s45l0CH\nVCjDq9ccQ4+m1fnzOzN46JO5Rba3W08YzjmXYOVKp/BsnzZc0LYeT361gDtHTiuSo/gl8jkM55xz\noZTkJB446yhqVk7lsc/nk7VpO09f3JryZYrOadivMJxz7gCRxC3HNeGBs47i6/lZXDhoPGs2b486\nrLh5wnDOuQPswnb1GXRpOvNWbeLsgUVnXA1PGM45F4Geh9fg1Wvas3HrTs4eOI4pS9fnXyhinjCc\ncy4irepX4c3rO1KuTDIXPjeer+asjjqkPHnCcM65CDWsVoE3r+9Io+rlufrFTF7/bmn+hSLiCcM5\n5yJWvWIqr/XtQMdGh3DXm9N4/Iv5hfJZDU8YzjlXCFQok8KQy9pyVqs6PPLZPP70zgx2FbJnNYrO\nDcDOOVfMlU5J4uHzWlCzcipPj1rI6o3beeLCVpQtnRx1aIBfYTjnXKEiibt6NeO+3kfyxZxVXDx4\nPOu27Ig6LMAThnPOFUqXdUxj4MWtmbFiI2c/M46la3+OOiRPGM45V1j1al6L4Vcfw5pN2zlr4Dhm\nLN8QaTyeMJxzrhBrm3Ywb17fkVJJ4oLnxjN2/prIYvGE4ZxzhVzjGhV564ZO1K1SlsuHTeCdycsj\nicMThnPOFQE1K6fy+nUdSE+rwi0jpvDM6IUH/FkNTxjOOVdEVEotxQtXtuPUo2vx4EdzuO+9Weze\nc+CShj+H4ZxzRUiZlGQev6AVNSqlMmTs96zetI1HzmtJaqnEP6uR0IQh6SBgMNAcMOBK4GTgdGAP\nsBq43MxW5FB2NzA9nFxiZr0TGatzzhUVSUniL6ceQa3Kqfzzg9ms2TyB569oS7nSib0GSPQVxgDg\nYzM7R1JpoBww08z+AiDpJuCvwHU5lN1qZi0THJ9zzhVZV3dpSPVKqYydn0VqShG+wpBUCegKXA5g\nZjuA7I8rlie48nDOObcfereoTe8WtQ/IthLZ6N0QyAKGSZosabCk8gCS7pe0FLiY4AojJ6mSMiWN\nl3RGAuN0zjkXh0QmjBSgNTDQzFoBW4C7AczsT2ZWDxgO9MulfH0zSwcuAh6T1CinhST1DRNLZlZW\nVoF/COecc4FEJoxlwDIzywinRxIkkFivAGfnVHhvQ7iZLQJGAa1yWe45M0s3s/Rq1aoVRNzOOedy\nkLCEYWYrgaWSmoazegKzJDWOWaw3MCd7WUlVJJUJf68KdAJmJSpW55xz+Uv0XVL9geHhHVKLgCuA\nwWES2QP8QHiHlKR04Dozuxo4HHhW0h6CpPagmXnCcM65CKkwDgO4v9LT0y0zMzPqMJxzrsiQNDFs\nL86Xdw3inHMuLp4wnHPOxaVYVUlJyiJoF9kfVYHoOpovXHxf/Jrvj1/z/fGL4rAvGphZXLeYFquE\n8XtIyoy3Hq+4833xa74/fs33xy9K2r7wKinnnHNx8YThnHMuLp4wfvFc1AEUIr4vfs33x6/5/vhF\nidoX3obhnHMuLn6F4ZxzLi6eMJxzzsWlxCcMSb0kzZW0QNLdUccTJUn1JH0labakmZJujjqmqElK\nDsdzeT/qWKIm6SBJIyXNCY+RDlHHFCVJt4b/JzMkvSopNeqYEq1EJwxJycBTwEnAEcCFko6INqpI\n7QJuN7PDgfbAjSV8fwDcDMyOOohCYu+Qy82AFpTg/SKpDnATkG5mzYFk4IJoo0q8Ep0wgHbAAjNb\nFA4h+xpwesQxRcbMfjSzSeHvmwhOCHWijSo6kuoCpwCDo44lajFDLg+BYMhlM1sfbVSRSwHKSkoB\nygErIo4n4Up6wqgDLI2ZXkYJPkHGkpRGMGhVRt5LFmuPAXcRdMVf0uU65HJJZGbLgYeAJcCPwAYz\n+zTaqBKvpCcM5TCvxN9nLKkC8CZwi5ltjDqeKEg6FVhtZhOjjqWQyHXI5ZJIUhWC2ohDgdpAeUmX\nRBtV4pX0hLEMqBczXZcScFmZF0mlCJLFcDN7K+p4ItQJ6C1pMUFV5bGSXo42pEjFM+RySXIc8L2Z\nZZnZTuAtoGPEMSVcSU8Y3wGNJR0ajgp4AfBuxDFFRpII6qhnm9kjUccTJTP7o5nVNbM0guPiSzMr\n9t8gc5PbkMsRhhS1JUB7SeXC/5uelICbABI9RGuhZma7JPUDPiG4y2Gomc2MOKwodQL6ANMlTQnn\n3WNmH0YYkys8chpyuUQyswxJI4FJBHcXTqYEdBPiXYM455yLS0mvknLOORcnTxjOOefi4gnDOedc\nXDxhOOeci4snDOecc3HxhOGKBUmbw59pki4q4HXfk216XEGuP9u6y0j6XNIUSefv5zrulWSSDouZ\nd2s4L11SRrj+JZKywt+nhN3BOJcrTxiuuEkD9ilhhL0W5+VXCcPMEvlEbyuglJm1NLMR8RTIJf7p\n/Lr31HMIH7Qzs2PMrCXwV2BEuK2WZrb494XuijtPGK64eRDoEn5jvjUcz+I/kr6TNE3StQCSuodj\nf7xCcHJF0juSJoZjHPQN5z1I0CPpFEnDw3l7r2YUrnuGpOl7rwjCdY+KGTtiePg0MJIelDQrjOWh\n2MAlVQdeBlqG22skqWfY2d90SUMllQmXXSzpr5LGAufmsB/eIex5WVJDYANB54HO7bcS/aS3K5bu\nBu4ws1MBwhP/BjNrG55sv5G0t1fRdkBzM/s+nL7SzNZKKgt8J+lNM7tbUr/wG3l2ZwEtCcaGqBqW\nGRO+1wo4kqBvsm+ATpJmAWcCzczMJB0UuzIzWy3p6r3xhwPyjAJ6mtk8SS8C1xP0oguwzcw657If\nNhJ05dGcIHGMoAQ/me0Khl9huOLuBODSsKuTDOAQoHH43oSYZAFwk6SpwHiCTikbk7fOwKtmttvM\nVgGjgbYx615mZnuAKQRVZRuBbcBgSWcBP+ez/qYEHdzNC6dfIBiTYq/8qqxeI6iWOgN4O59lncuX\nJwxX3AnoH1NPf2jMuAVb/reQ1J2gB9IOZtaCoG+g/IbczKl7/L22x/y+G0gxs10EVzVvEpzEP/4d\n64eY+HPxHkHfYEtKajf1rmB5wnDFzSagYsz0J8D1YbftSGqSy8A/lYF1ZvazpGYEQ9TutXNv+WzG\nAOeH7STVCL79T8gtsHCckcphZ463EFRn5WUOkBZzt1MfgquYuJjZVuAPwP3xlnEuL96G4YqbacCu\nsGrpeYJxqNOASWHDcxbBt/vsPgaukzQNmEtQLbXXc8A0SZPM7OKY+W8DHYCpBANv3WVmK8OEk5OK\nwH/DtgkBt+b1Qcxsm6QrgDcUDAP6HfBMXmVyWMdr+7K8c3nx3mqdc87FxauknHPOxcUThnPOubh4\nwnDOORcXTxjOOefi4gnDOedcXDxhOOeci4snDOecc3H5f19wouk+OoY3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f67c0967cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<SOS>', 'deux', 'jeunes', 'hommes', 'blancs', 'sont', 'dehors', 'près', 'de', 'b@@', 'u@@', 'i@@', 's@@', 's@@', 'ons', '.', '<EOS>']\n",
      "['<SOS>', 'two', 'young', ',', 'white', 'm@@', 'al@@', 'es', 'are', 'outside', 'near', 'many', 'bu@@', 'sh@@', 'es', '.', '<EOS>']\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "learning_rate = 0.1\n",
    "w_embedding_dim = 100\n",
    "p_embedding_dim = 100\n",
    "dec_embedding_dim = 100\n",
    "dropout_prob = 0.1\n",
    "\n",
    "# model_encoder = Encoder(vocab_size_fr, w_embedding_dim, p_embedding_dim, dec_embedding_dim, max_sentence_length)\n",
    "# model_decoder = Decoder(dec_embedding_dim, vocab_size_en, max_sentence_length, dropout_prob)\n",
    "model_NMT = NMTModel(vocab_size_fr, w_embedding_dim, p_embedding_dim, dec_embedding_dim, max_sentence_length, vocab_size_en, dropout_prob)\n",
    "\n",
    "optimizer_NMT = optim.SGD(model_NMT.parameters(), lr = learning_rate)\n",
    "# optimizer_encoder = optim.SGD(model_encoder.parameters(), lr = learning_rate)\n",
    "# optimizer_decoder = optim.SGD(model_decoder.parameters(), lr = learning_rate)\n",
    "\n",
    "loss_func = nn.NLLLoss()\n",
    "losses = []\n",
    "avg_losses = []\n",
    "\n",
    "portion = 10\n",
    "\n",
    "train = True\n",
    "print('epoch, total loss, duration')\n",
    "for e in range(epochs):\n",
    "    \n",
    "    then = datetime.now()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    for s in range(portion):\n",
    "     \n",
    "        current_input = corpus2id_fr[s]\n",
    "        gold_output = corpus2id_en[s]\n",
    "        \n",
    "        if len(current_input) > 0 and len(gold_output) > 0:\n",
    "            \n",
    "            optimizer_NMT.zero_grad()\n",
    "            \n",
    "            sent_fr = torch.tensor(np.asarray(current_input), dtype= torch.long)\n",
    "            sent_en = torch.tensor(np.asarray(gold_output), dtype= torch.long)\n",
    "\n",
    "            pos_fr = torch.tensor(np.asarray([p for p in range(len(sent_fr))]))\n",
    "            pos_en = torch.tensor(np.asarray([p for p in range(len(sent_en))]))\n",
    "        \n",
    "            pred, attention_weights = model_NMT(sent_fr, pos_fr, sent_en, train)\n",
    "            \n",
    "            #sent_en = sent_en[1:len(sent_en)] #skip SOS\n",
    "            loss = loss_func(pred[0], sent_en)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer_NMT.step()\n",
    "            \n",
    "            total_loss += loss.item() \n",
    "       \n",
    "    now = datetime.now()\n",
    "        \n",
    "    losses.append(total_loss)\n",
    "    \n",
    "    print(e, total_loss/portion, now-then)\n",
    "\n",
    "with open('model_NMT' + str(portion) + '.pickle','wb') as file:\n",
    "    pickle.dump(model_NMT,file)\n",
    "\n",
    "    \n",
    "iteration= list(range(len(losses)))\n",
    "\n",
    "plt.plot(iteration, losses)\n",
    "plt.xlabel(\"Iterations for MT\")\n",
    "plt.ylabel('Total loss')\n",
    "plt.title('Evolution of the loss as a function of the iteration')\n",
    "plt.savefig(\"mt\" + str(portion)+\".png\")\n",
    "plt.show()\n",
    "\n",
    "test_fr_sentence = corpus2id_fr[0]\n",
    "test_en_sentence = corpus2id_en[0]\n",
    "    \n",
    "decoder_outputs, decoder_attentions = evaluate_sent(model_NMT, test_fr_sentence, test_en_sentence)\n",
    "\n",
    "print(word_ids2string(test_fr_sentence, id2tokens_fr))\n",
    "print(word_ids2string(test_en_sentence, id2tokens_en))\n",
    "print(word_ids2string(decoder_outputs, id2tokens_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = 3\n",
    "\n",
    "test_fr_sentence = corpus2id_fr[pair]\n",
    "test_en_sentence = corpus2id_en[pair]\n",
    "    \n",
    "decoder_outputs, decoder_attentions = evaluate_sent(model_NMT,test_fr_sentence, test_en_sentence)\n",
    "\n",
    "french_gold = word_ids2string(test_fr_sentence, id2tokens_fr)\n",
    "print(french_gold)\n",
    "print(len(word_ids2string(test_fr_sentence, id2tokens_fr)))\n",
    "\n",
    "english_gold = word_ids2string(test_en_sentence, id2tokens_en)\n",
    "print(english_gold)\n",
    "\n",
    "english_output = word_ids2string(decoder_outputs, id2tokens_en)\n",
    "print(english_output)\n",
    "print(len(word_ids2string(decoder_outputs, id2tokens_en)))\n",
    "\n",
    "print(decoder_attentions.size())\n",
    "S = decoder_attentions\n",
    "sent_num = pair\n",
    "\n",
    "# visualize_attention(S,sent_num)\n",
    "\n",
    "french_gold = (\" \").join(french_gold)\n",
    "showAttention(french_gold,english_output,S,pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('model_encoder' + str(portion) + '.pickle','rb') as file:\n",
    "    model_encoder = pickle.load(file)\n",
    "      \n",
    "\n",
    "with open('model_decoder' + str(portion) + '.pickle','rb') as file:\n",
    "    model_decoder = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_sent(model_NMT, sent_fr, sent_en):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        sent_fr = torch.tensor(np.asarray(sent_fr), dtype= torch.long)\n",
    "        sent_en = torch.tensor(np.asarray(sent_en), dtype= torch.long)\n",
    "\n",
    "        pos_fr = torch.tensor(np.asarray([p for p in range(len(sent_fr))]))\n",
    "        pos_en = torch.tensor(np.asarray([p for p in range(len(sent_en))]))\n",
    "\n",
    "#         average_context, stacked_contexts = model_encoder(sent_fr, pos_fr)\n",
    "        \n",
    "#         decoder_outputs, decoder_attentions = model_decoder(sent_en, average_context, stacked_contexts, train=False)\n",
    "        \n",
    "        decoder_outputs, decoder_attentions = model_NMT(sent_fr, pos_fr, sent_en, train=False)\n",
    "        \n",
    "    return decoder_outputs, decoder_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_ids2string(sentence, id2token):\n",
    "    \n",
    "    converted = []\n",
    "\n",
    "    for s in sentence:\n",
    "        converted.append(id2token[s])\n",
    "        \n",
    "    return converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write the results of the predicted sentences to a txt file for evaluation\n",
    "\n",
    "def write_test_eval(model_NMT, test_sentences_fr, test_sentences_en):\n",
    "\n",
    "    filename = \"test_results.txt\" \n",
    "    output = open(filename,\"w\") \n",
    "    \n",
    "    for sent in range(2): #range(len(test_sentences_fr)):\n",
    "\n",
    "        decoder_outputs, decoder_attentions = evaluate_sent(model_NMT, test_sentences_fr[sent], test_sentences_en[sent])\n",
    "        print(decoder_attentions.size())\n",
    "        \n",
    "        output_list = word_ids2string(decoder_outputs, id2tokens_en)\n",
    "        if '<EOS>' in output_list:\n",
    "            output_list.remove('<EOS>')\n",
    "        \n",
    "        output_string = (\" \").join(output_list)\n",
    "        \n",
    "        output.write(output_string + \"\\n\")\n",
    "\n",
    "    output.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_corpus2id_fr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-49cead130d78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwrite_test_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_NMT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_corpus2id_fr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_corpus2id_en\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_corpus2id_fr' is not defined"
     ]
    }
   ],
   "source": [
    "write_test_eval(model_NMT, test_corpus2id_fr, test_corpus2id_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "#BEAM SEARCH\n",
    "#teacher forcing prob\n",
    "#dropout prob\n",
    "#gru lstm rnn check\n",
    "#relu before rnn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_attention(S,sent_num):\n",
    "    \n",
    "    #model_encoder, model_decoder, sent_en, sent_fr\n",
    "    \n",
    "    #************************************************************************\n",
    "    # S is the log softmax version of S, also a torch Tensor! (actually more acurately it's a Variable(Tensor(..))\n",
    "    #************************************************************************\n",
    "\n",
    "    S = S.exp()\n",
    "    \n",
    "    # Plot the attention tensor\n",
    "    plt.clf()\n",
    "    numpy_S = S.data.numpy()\n",
    "    numpy_S = numpy_S[:,:,0]\n",
    "    #print(numpy_S.shape)\n",
    "\n",
    "    plt.imshow(numpy_S)\n",
    "    imname = \"attentions-test-\" + str(sent_num)\n",
    "    plt.savefig(imname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def showAttention(input_sentence, output_words, attentions, sentence_number):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    attentions = attentions.exp()\n",
    "    cax = ax.matshow(attentions[:,:,0].data.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    \n",
    "    imname = \"attentions-test-\" + str(sentence_number)\n",
    "    plt.savefig(imname)\n",
    "    plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.tensor(np.asarray([i for i in range(10)]), dtype= torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "asf = F.log_softmax(a, dim=0)\n",
    "print(asf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = torch.tensor(np.asarray([i+1 for i in range(10)]), dtype= torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st = torch.stack([a,b], dim = 0)\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = torch.tensor(np.asarray([0.1, 0.2]), dtype = torch.float).view(-1,1)\n",
    "print(weights.shape)\n",
    "\n",
    "torch.mul(weights, st)\n",
    "# torch.matmul(weights.view(1,2), st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.stack([a,b], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.mean(st, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.mean(st, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F.softmax(st, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = a*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "long(torch.argmax(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_word = torch.tensor(np.asarray([tokens2id_en['<SOS>']]), dtype = torch.long)\n",
    "print(test_word, test_word.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#     attn_weights = F.softmax(\n",
    "#             self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "#         attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "#                                  encoder_outputs.unsqueeze(0))\n",
    "\n",
    "#         output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "#         output = self.attn_combine(output).unsqueeze(0)\n",
    "           \n",
    "#         atts= torch.matmul(es, hidden_from_decoder)\n",
    "        \n",
    "#         weighted_context = es*attention_weights\n",
    "        \n",
    "        #if EOS for encoder, move on to the decoder\n",
    "        \n",
    "        #attention_matrices = self.attention_projection(e_out)\n",
    "        \n",
    "        #input embedding\n",
    "        #set hidden at the beginning\n",
    "        #get rnn output\n",
    "        #apply softmax\n",
    "\n",
    "        #feed actual word for training\n",
    "        #feed previous word for testing\n",
    "\n",
    "#             #view_shape = embeddings.shape[0]\n",
    "#             output, (hidden, cell) = self.bidirLSTM(embeddings.view(1, 1, -1)) \n",
    "\n",
    "#             hid_f = hidden[0]\n",
    "#             hid_b = hidden[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
