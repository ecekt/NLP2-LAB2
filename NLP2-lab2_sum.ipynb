{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial\n",
    "from scipy import stats\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1)\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "from random import randint\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('error')\n",
    "\n",
    "import string\n",
    "# puncs = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "portion = 29000\n",
    "\n",
    "#training sets\n",
    "with open('tokenized_low.BPE.en') as f:\n",
    "    train_en = [l.strip() for l in f.readlines()][:portion]\n",
    "with open('tokenized_low.BPE.fr') as f:\n",
    "    train_fr = [l.strip() for l in f.readlines()][:portion]\n",
    "\n",
    "# #validation sets\n",
    "# with open('val.en') as f:\n",
    "#     val_en = [l.strip() for l in f.readlines()]\n",
    "# with open('val.fr') as f:\n",
    "#     val_fr = [l.strip() for l in f.readlines()]\n",
    "\n",
    "# #test sets\n",
    "# with open('test_tokenized.BPE.en') as f:\n",
    "#     test_en = [l.strip() for l in f.readlines()]\n",
    "# with open('test_tokenized.BPE.fr') as f:\n",
    "#     test_fr = [l.strip() for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "# 0 PAD - padding 0 for convenience in masking?\n",
    "# 1 BOS - beginning of sentence\n",
    "# 2 EOS - end of sentence\n",
    "# 3 UNK - unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_sentence_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokens_sentences(sentences):\n",
    "    tokens_list = []\n",
    "    sentence_list = []\n",
    "    for s in sentences:\n",
    "        split_sent = s.split()\n",
    "        sentence = []\n",
    "        for w in split_sent:\n",
    "#             if w not in puncs:\n",
    "            tokens_list.append(w)\n",
    "            sentence.append(w)\n",
    "\n",
    "        sentence_list.append(sentence)\n",
    "    \n",
    "    return tokens_list, sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m@@\n",
      "m@@\n",
      "563773\n",
      "812\n"
     ]
    }
   ],
   "source": [
    "tokens_list,sentence_list = tokens_sentences(train_en)\n",
    "\n",
    "print(tokens_list[4])\n",
    "print(sentence_list[0][4])\n",
    "\n",
    "print(len(tokens_list))\n",
    "print(len(sorted(set(tokens_list))))\n",
    "# print(set(tokens_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size EN 816\n",
      "Vocabulary size FR 862\n"
     ]
    }
   ],
   "source": [
    "tokens_list_en, sentence_list_en = tokens_sentences(train_en)\n",
    "\n",
    "tokens_train_en = ['<PAD>', '<SOS>', '<EOS>', '<UNK>']\n",
    "tokens_train_en.extend(list(sorted(set(tokens_list_en))))\n",
    "vocab_size_en = len(tokens_train_en)\n",
    "print('Vocabulary size EN', vocab_size_en)\n",
    "\n",
    "count_tokens_train_en = Counter(tokens_list_en)\n",
    "\n",
    "tokens_list_fr, sentence_list_fr = tokens_sentences(train_fr)\n",
    "\n",
    "tokens_train_fr = ['<PAD>', '<SOS>', '<EOS>', '<UNK>']\n",
    "tokens_train_fr.extend(list(sorted(set(tokens_list_fr))))\n",
    "vocab_size_fr = len(tokens_train_fr)\n",
    "print('Vocabulary size FR', len(tokens_train_fr))\n",
    "\n",
    "count_tokens_train_fr = Counter(tokens_list_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_id_dicts(tokens):\n",
    "    #default dictionary key:id value:token\n",
    "    id2tokens = defaultdict(str)\n",
    "\n",
    "    for i in range(len(tokens)):\n",
    "        id2tokens[i] = tokens[i]\n",
    "\n",
    "    #default dictionary key:token value:id\n",
    "    tokens2id = defaultdict(int)\n",
    "\n",
    "    for ind in id2tokens:\n",
    "        tokens2id[id2tokens[ind]] = ind\n",
    "\n",
    "    return tokens2id, id2tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816\n",
      "862\n"
     ]
    }
   ],
   "source": [
    "tokens2id_en, id2tokens_en = get_id_dicts(tokens_train_en)\n",
    "\n",
    "vocabulary_size_train_en = len(tokens2id_en)\n",
    "print(vocabulary_size_train_en)\n",
    "\n",
    "tokens2id_fr, id2tokens_fr = get_id_dicts(tokens_train_fr)\n",
    "\n",
    "vocabulary_size_train_fr = len(tokens2id_fr)\n",
    "print(vocabulary_size_train_fr)\n",
    "\n",
    "# print(tokens2id_en['m@@'])\n",
    "# print(id2tokens_en[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#building the corpora (list of list of ids) simultaneously \n",
    "def convert_corpora2id_both(sentence_list_en, sentence_list_fr, tokens2id_en, tokens2id_fr, max_sentence_length):\n",
    "    \n",
    "    #counts to check long sentences\n",
    "    counter_long = 0\n",
    "    \n",
    "    #convert dataset to ids\n",
    "    corpus2id_en = []\n",
    "    corpus2id_fr = []\n",
    "    \n",
    "    for s in range(len(sentence_list_en)):\n",
    "    \n",
    "        sentence2id_en = []\n",
    "        sentence2id_en.append(tokens2id_en['<SOS>'])\n",
    "        \n",
    "        sentence2id_fr = []\n",
    "        sentence2id_fr.append(tokens2id_fr['<SOS>'])\n",
    "        \n",
    "        sentence_en = sentence_list_en[s]\n",
    "        sentence_fr = sentence_list_fr[s]\n",
    "        \n",
    "        \n",
    "        for w_en in sentence_en:\n",
    "            word_id = tokens2id_en[w_en]\n",
    "            sentence2id_en.append(word_id)\n",
    "            \n",
    "        for w_fr in sentence_fr:\n",
    "            word_id = tokens2id_fr[w_fr]\n",
    "            sentence2id_fr.append(word_id)\n",
    "        \n",
    "        \n",
    "        sentence2id_en.append(tokens2id_en['<EOS>'])\n",
    "        sentence2id_fr.append(tokens2id_fr['<EOS>'])\n",
    "\n",
    "        if len(sentence2id_en) < max_sentence_length and len(sentence2id_fr) < max_sentence_length:\n",
    "            corpus2id_en.append(sentence2id_en)\n",
    "            corpus2id_fr.append(sentence2id_fr)\n",
    "        \n",
    "        else:\n",
    "            counter_long += 1\n",
    "#             print(sentence_list_en[s])\n",
    "#             print(sentence_list_fr[s])\n",
    "        \n",
    "    print('the number of sentences that were not added is',counter_long)       \n",
    "    return corpus2id_en, corpus2id_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of sentences that were not added is 531\n"
     ]
    }
   ],
   "source": [
    "# corpus2id_en = convert_corpus2id(sentence_list_en, tokens2id_en, max_sentence_length)\n",
    "# corpus2id_fr = convert_corpus2id(sentence_list_fr, tokens2id_fr, max_sentence_length)\n",
    "\n",
    "corpus2id_en, corpus2id_fr = convert_corpora2id_both(sentence_list_en,sentence_list_fr, tokens2id_en, tokens2id_fr, max_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are  28469 french sentences\n",
      "there are  28469 english sentences\n"
     ]
    }
   ],
   "source": [
    "# print(corpus2id_en[0])\n",
    "\n",
    "print('there are ', len(corpus2id_fr), 'french sentences')\n",
    "print('there are ', len(corpus2id_en), 'english sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #get test sentences \n",
    "\n",
    "# test_tokens_list_en,test_sentence_list_en = tokens_sentences(test_en)\n",
    "# test_tokens_list_fr,test_sentence_list_fr = tokens_sentences(test_fr)\n",
    "\n",
    "# for sent in range(len(test_sentence_list_en)):\n",
    "#     if len(test_sentence_list_en[sent]) > 50 or len(test_sentence_list_fr[sent]) > 50:\n",
    "#         print(test_sentence_list_en[sent])\n",
    "#         print(test_sentence_list_fr[sent])\n",
    "\n",
    "# test_corpus2id_en, test_corpus2id_fr = convert_corpora2id_both(test_sentence_list_en,test_sentence_list_fr, tokens2id_en, tokens2id_fr, max_sentence_length)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NMTModel(nn.Module):\n",
    "    def __init__(self,vocab_size_fr, w_embedding_dim, p_embedding_dim, dec_embedding_dim, max_sentence_length, vocab_size_en, dropout_prob):\n",
    "        super(NMTModel, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(vocab_size_fr, w_embedding_dim, p_embedding_dim, dec_embedding_dim, max_sentence_length,dropout_prob)\n",
    "        self.decoder = Decoder(dec_embedding_dim, vocab_size_en, max_sentence_length, dropout_prob)\n",
    "            \n",
    "    def forward(self, sent_fr, pos_fr, sent_en, train):\n",
    "        \n",
    "        average_context, stacked_contexts = self.encoder(sent_fr, pos_fr)\n",
    "        \n",
    "        pred, attention_weights = self.decoder(sent_en, average_context, stacked_contexts, train)\n",
    "          \n",
    "        return pred, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,vocab_size_fr, w_embedding_dim, p_embedding_dim, dec_embedding_dim, max_sentence_length, dropout_prob):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.vocab_size_fr = vocab_size_fr\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        \n",
    "        self.w_embedding_dim = w_embedding_dim\n",
    "        self.p_embedding_dim = p_embedding_dim\n",
    "        \n",
    "        initrange = 0.5 / self.w_embedding_dim\n",
    "        self.dec_embedding_dim = dec_embedding_dim\n",
    "        \n",
    "        #encoder\n",
    "        self.w_embeddings = nn.Embedding(self.vocab_size_fr, self.w_embedding_dim)\n",
    "        self.p_embeddings = nn.Embedding(self.max_sentence_length, self.p_embedding_dim)\n",
    "        \n",
    "        self.w_embeddings.weight.data.uniform_(-initrange, initrange)\n",
    "        self.p_embeddings.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.dropout = nn.Dropout(self.dropout_prob)\n",
    "        \n",
    "        self.context_emb_dim = self.w_embedding_dim + self.p_embedding_dim\n",
    "        \n",
    "        #self.context_projection = nn.Linear(self.context_emb_dim, self.dec_embedding_dim)\n",
    "        #do we use non-linearity after attention\n",
    "        \n",
    "        #TODO: DROPOUT\n",
    "        \n",
    "        \n",
    "    def forward(self, sent_fr, pos_fr):\n",
    "        \n",
    "        #embedded = self.embedding(input).view(1, 1, -1)\n",
    "        #TODO:BATCH\n",
    "       \n",
    "        ws = self.w_embeddings(sent_fr)\n",
    "        ps = self.p_embeddings(pos_fr)\n",
    "        es = torch.cat((ws, ps), 1)\n",
    "        \n",
    "        es = self.dropout(es)\n",
    "        \n",
    "        stacked_contexts = es\n",
    "        average_context = torch.mean(stacked_contexts, dim = 0)\n",
    "            \n",
    "        return average_context, stacked_contexts\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, dec_embedding_dim, vocab_size_en, max_sentence_length, dropout_prob):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.vocab_size_en = vocab_size_en\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        \n",
    "        self.dec_embedding_dim = dec_embedding_dim*2\n",
    "        \n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.dropout = nn.Dropout(self.dropout_prob)\n",
    "        \n",
    "        initrange = 0.5 / self.dec_embedding_dim\n",
    "        self.embedding = nn.Embedding(self.vocab_size_en, self.dec_embedding_dim)\n",
    "        \n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)        \n",
    "        \n",
    "        self.lstm = nn.LSTM(self.dec_embedding_dim, self.dec_embedding_dim)\n",
    "        #self.bidirLSTM = nn.LSTM(self.embedding_dim, self.embedding_dim, bidirectional=True)\n",
    "        #TODO: LSTM, GRU \n",
    "       \n",
    "        self.pre_rnn_affine = nn.Linear(self.dec_embedding_dim*2, self.dec_embedding_dim)\n",
    "        #a linear layer after this before softmax\n",
    "        self.out_affine = nn.Linear(self.dec_embedding_dim*2, self.vocab_size_en)\n",
    "               \n",
    "    \n",
    "    def forward(self, gold_target_sent, encoder_avg_context, encoder_stacked_contexts, train):\n",
    "        \n",
    "        if train:\n",
    "            pred = []\n",
    "            attentions = []\n",
    "\n",
    "            embeds = self.embedding(gold_target_sent)\n",
    "            embeds = self.dropout(embeds)\n",
    "\n",
    "            output, (hidden, cell) = self.lstm(embeds.view(-1,1,200),(encoder_avg_context.view(1, 1, -1), encoder_avg_context.view(1,1,-1)))\n",
    "\n",
    "            #print(output[-1], hidden) same\n",
    "            \n",
    "            \n",
    "            for w in range(len(gold_target_sent)):\n",
    "\n",
    "                sw = output[w]\n",
    "                cj = F.softmax(torch.matmul(sw,torch.transpose(encoder_stacked_contexts,0,1)), dim = 1)\n",
    "\n",
    "                c_vec = cj.view(-1,1) *  encoder_stacked_contexts.squeeze()\n",
    "                sw = torch.sum(c_vec, dim=0).view(1,-1)\n",
    "                \n",
    "                sw_temp = torch.stack([sw]*c_vec.shape[0], dim =1).squeeze()\n",
    "                \n",
    "                sw = torch.cat((sw_temp, c_vec),dim=1)\n",
    "                \n",
    "                s_output = self.out_affine(sw)\n",
    "                s_output = F.log_softmax(s_output, dim=1)\n",
    "\n",
    "                pred.append(s_output)\n",
    "\n",
    "            pred = torch.stack(pred, dim=1)\n",
    "\n",
    "            return pred, attentions\n",
    "        \n",
    "        \n",
    "        else: #test\n",
    "            \n",
    "            decoder_outputs = []\n",
    "            decoder_attentions = []\n",
    "        \n",
    "            test_word = torch.tensor(np.asarray([tokens2id_en['<SOS>']]), dtype = torch.long)\n",
    "            \n",
    "            test_word_id = tokens2id_en['<SOS>']\n",
    "            \n",
    "            for w in range(self.max_sentence_length):\n",
    "       \n",
    "                if test_word_id == tokens2id_en['<EOS>']:\n",
    "                    \n",
    "                    break  \n",
    "                    \n",
    "                output = self.embedding(test_word)\n",
    "                output = self.dropout(output)\n",
    "            \n",
    "                if w == 0:\n",
    "            \n",
    "                    output, (hidden,cell) = self.lstm(output.view(1, 1, -1), (encoder_avg_context.view(1, 1, -1),encoder_avg_context.view(1, 1, -1)))\n",
    "                    prev_hidden = hidden\n",
    "\n",
    "                    cj = F.softmax(torch.matmul(output[0],torch.transpose(encoder_stacked_contexts,0,1)), dim = 1)\n",
    "\n",
    "                    c_vec = cj.view(-1,1) *  encoder_stacked_contexts.squeeze()\n",
    "\n",
    "                    sw = torch.sum(c_vec, dim=0).view(1,-1)\n",
    "                \n",
    "                    sw_temp = torch.stack([sw]*c_vec.shape[0], dim =1).squeeze()\n",
    "\n",
    "                    sw = torch.cat((sw_temp, c_vec),dim=1)\n",
    "                \n",
    "\n",
    "                    s_output = self.out_affine(sw)\n",
    "                    s_output = F.log_softmax(s_output, dim=1)\n",
    "                    \n",
    "                    test_word_id = int(torch.argmax(s_output))\n",
    "                    test_word = torch.tensor(np.asarray([test_word_id]), dtype = torch.long)\n",
    "           \n",
    "                else:\n",
    "                    output, (hidden,cell) = self.lstm(output.view(1, 1, -1), (prev_hidden.view(1, 1, -1),encoder_avg_context.view(1, 1, -1)))\n",
    "                    prev_hidden = hidden\n",
    "\n",
    "                    cj = F.softmax(torch.matmul(output[0],torch.transpose(encoder_stacked_contexts,0,1)), dim = 1)\n",
    "\n",
    "                    c_vec = cj.view(-1,1) *  encoder_stacked_contexts.squeeze()\n",
    "\n",
    "                    sw = torch.sum(c_vec, dim=0).view(1,-1)\n",
    "                \n",
    "                    sw_temp = torch.stack([sw]*c_vec.shape[0], dim =1).squeeze()\n",
    "\n",
    "                    sw = torch.cat((sw_temp, c_vec),dim=1)\n",
    "                \n",
    "\n",
    "                    s_output = self.out_affine(sw)\n",
    "                    s_output = F.log_softmax(s_output, dim=1)\n",
    "                    \n",
    "                    test_word_id = int(torch.argmax(s_output))\n",
    "                    test_word = torch.tensor(np.asarray([test_word_id]), dtype = torch.long)\n",
    "        \n",
    "                decoder_outputs.append(test_word_id)\n",
    "            \n",
    "            return decoder_outputs, decoder_attentions\n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, total loss, duration\n",
      "0 6.701160526275634 0:00:00.404084\n",
      "1 6.677179431915283 0:00:00.389304\n",
      "2 6.653271865844727 0:00:00.407522\n",
      "3 6.629439401626587 0:00:00.384187\n",
      "4 6.605690240859985 0:00:00.401245\n",
      "5 6.581973505020142 0:00:00.400754\n",
      "6 6.558346939086914 0:00:00.405075\n",
      "7 6.534809303283692 0:00:00.394032\n",
      "8 6.511315536499024 0:00:00.391578\n",
      "9 6.487925863265991 0:00:00.388985\n",
      "10 6.464639329910279 0:00:00.415190\n",
      "11 6.441438055038452 0:00:00.400519\n",
      "12 6.418321800231934 0:00:00.377761\n",
      "13 6.39530611038208 0:00:00.383068\n",
      "14 6.372399616241455 0:00:00.401833\n",
      "15 6.349652290344238 0:00:00.403824\n",
      "16 6.327017831802368 0:00:00.394479\n",
      "17 6.304473209381103 0:00:00.408967\n",
      "18 6.282094192504883 0:00:00.391181\n",
      "19 6.259815073013305 0:00:00.399596\n",
      "20 6.237701654434204 0:00:00.378102\n",
      "21 6.215764951705933 0:00:00.388677\n",
      "22 6.193971443176269 0:00:00.383925\n",
      "23 6.1723298072814945 0:00:00.396789\n",
      "24 6.150938034057617 0:00:00.383536\n",
      "25 6.129654264450073 0:00:00.394024\n",
      "26 6.1085930347442625 0:00:00.376719\n",
      "27 6.087764406204224 0:00:00.373788\n",
      "28 6.067163324356079 0:00:00.369427\n",
      "29 6.046714925765992 0:00:00.378553\n",
      "30 6.026614999771118 0:00:00.385428\n",
      "31 6.006624507904053 0:00:00.391708\n",
      "32 5.98696813583374 0:00:00.371487\n",
      "33 5.967644357681275 0:00:00.378201\n",
      "34 5.94843430519104 0:00:00.399202\n",
      "35 5.929586172103882 0:00:00.401427\n",
      "36 5.910977411270141 0:00:00.401276\n",
      "37 5.892685890197754 0:00:00.414804\n",
      "38 5.874675559997558 0:00:00.398748\n",
      "39 5.856971025466919 0:00:00.422605\n",
      "40 5.83967399597168 0:00:00.403351\n",
      "41 5.822535657882691 0:00:00.367908\n",
      "42 5.8057653427124025 0:00:00.379371\n",
      "43 5.7894124507904055 0:00:00.398096\n",
      "44 5.773298549652099 0:00:00.374890\n",
      "45 5.7574975967407225 0:00:00.383615\n",
      "46 5.742059707641602 0:00:00.416124\n",
      "47 5.726917791366577 0:00:00.375539\n",
      "48 5.71201982498169 0:00:00.384424\n",
      "49 5.697565031051636 0:00:00.411350\n",
      "50 5.683337259292602 0:00:00.383507\n",
      "51 5.66947112083435 0:00:00.381652\n",
      "52 5.655960941314698 0:00:00.376449\n",
      "53 5.642547512054444 0:00:00.381826\n",
      "54 5.62952241897583 0:00:00.388375\n",
      "55 5.616814184188843 0:00:00.371155\n",
      "56 5.604188442230225 0:00:00.383555\n",
      "57 5.591924953460693 0:00:00.380908\n",
      "58 5.580023241043091 0:00:00.382111\n",
      "59 5.568410778045655 0:00:00.384452\n",
      "60 5.5568005561828615 0:00:00.380152\n",
      "61 5.545608615875244 0:00:00.413216\n",
      "62 5.534567403793335 0:00:00.392676\n",
      "63 5.523874187469483 0:00:00.376487\n",
      "64 5.513167810440064 0:00:00.380985\n",
      "65 5.5028222560882565 0:00:00.413965\n",
      "66 5.492589378356934 0:00:00.370996\n",
      "67 5.482626819610596 0:00:00.378135\n",
      "68 5.472969245910645 0:00:00.388093\n",
      "69 5.463144683837891 0:00:00.453719\n",
      "70 5.453773498535156 0:00:00.377085\n",
      "71 5.444511604309082 0:00:00.391943\n",
      "72 5.435413837432861 0:00:00.410074\n",
      "73 5.426348876953125 0:00:00.416889\n",
      "74 5.417324352264404 0:00:00.472268\n",
      "75 5.408709621429443 0:00:00.402525\n",
      "76 5.4002806663513185 0:00:00.421202\n",
      "77 5.391830825805664 0:00:00.423099\n",
      "78 5.383511400222778 0:00:00.412860\n",
      "79 5.375293016433716 0:00:00.431893\n",
      "80 5.367311429977417 0:00:00.425032\n",
      "81 5.359268569946289 0:00:00.592455\n",
      "82 5.351522541046142 0:00:00.550875\n",
      "83 5.343831205368042 0:00:00.418444\n",
      "84 5.335756874084472 0:00:00.428788\n",
      "85 5.328893804550171 0:00:00.437043\n",
      "86 5.321095943450928 0:00:00.405562\n",
      "87 5.3138597965240475 0:00:00.447048\n",
      "88 5.306535053253174 0:00:00.427274\n",
      "89 5.299293375015258 0:00:00.450566\n",
      "90 5.292350006103516 0:00:00.421111\n",
      "91 5.285120248794556 0:00:00.423179\n",
      "92 5.278107643127441 0:00:00.433361\n",
      "93 5.271222162246704 0:00:00.461137\n",
      "94 5.264413690567016 0:00:00.419664\n",
      "95 5.257620334625244 0:00:00.444266\n",
      "96 5.250734186172485 0:00:00.428435\n",
      "97 5.244297218322754 0:00:00.430526\n",
      "98 5.237502861022949 0:00:00.433178\n",
      "99 5.231185579299927 0:00:00.393891\n",
      "100 5.224334621429444 0:00:00.427787\n",
      "101 5.218129205703735 0:00:00.429825\n",
      "102 5.21178035736084 0:00:00.442773\n",
      "103 5.20551700592041 0:00:00.438590\n",
      "104 5.1986531734466555 0:00:00.421486\n",
      "105 5.192489147186279 0:00:00.453808\n",
      "106 5.185941505432129 0:00:00.422862\n",
      "107 5.179858589172364 0:00:00.408153\n",
      "108 5.173796319961548 0:00:00.415405\n",
      "109 5.167883348464966 0:00:00.425841\n",
      "110 5.161372804641724 0:00:00.403151\n",
      "111 5.1551836967468265 0:00:00.431527\n",
      "112 5.148974227905273 0:00:00.488961\n",
      "113 5.142957782745361 0:00:00.561508\n",
      "114 5.1368951320648195 0:00:00.542801\n",
      "115 5.131417512893677 0:00:00.480007\n",
      "116 5.125324058532715 0:00:00.415728\n",
      "117 5.119075059890747 0:00:00.634031\n",
      "118 5.113629579544067 0:00:00.450038\n",
      "119 5.107516145706176 0:00:00.440131\n",
      "120 5.101560497283936 0:00:00.544161\n",
      "121 5.095574378967285 0:00:00.442975\n",
      "122 5.089933395385742 0:00:00.569745\n",
      "123 5.0839766502380375 0:00:00.442443\n",
      "124 5.078341865539551 0:00:00.412171\n",
      "125 5.072242164611817 0:00:00.464120\n",
      "126 5.066676235198974 0:00:00.567559\n",
      "127 5.060635280609131 0:00:00.581526\n",
      "128 5.055115699768066 0:00:00.485513\n",
      "129 5.048952960968018 0:00:00.433071\n",
      "130 5.0431715965271 0:00:00.419553\n",
      "131 5.0382507801055905 0:00:00.398533\n",
      "132 5.032093524932861 0:00:00.422993\n",
      "133 5.026762676239014 0:00:00.407698\n",
      "134 5.020881652832031 0:00:00.404985\n",
      "135 5.015640068054199 0:00:00.401697\n",
      "136 5.00996961593628 0:00:00.414966\n",
      "137 5.004531002044677 0:00:00.419890\n",
      "138 4.998686647415161 0:00:00.447744\n",
      "139 4.993208932876587 0:00:00.443143\n",
      "140 4.98782434463501 0:00:00.415108\n",
      "141 4.981740188598633 0:00:00.411111\n",
      "142 4.9765236377716064 0:00:00.420849\n",
      "143 4.971407794952393 0:00:00.412308\n",
      "144 4.965660667419433 0:00:00.403244\n",
      "145 4.960016393661499 0:00:00.430121\n",
      "146 4.954856824874878 0:00:00.459752\n",
      "147 4.9495521068573 0:00:00.433575\n",
      "148 4.944484090805053 0:00:00.431955\n",
      "149 4.938864898681641 0:00:00.418743\n",
      "150 4.9331457138061525 0:00:00.411499\n",
      "151 4.9283568382263185 0:00:00.430163\n",
      "152 4.922736406326294 0:00:00.443664\n",
      "153 4.918395519256592 0:00:00.412093\n",
      "154 4.912212085723877 0:00:00.421486\n",
      "155 4.9071784019470215 0:00:00.422522\n",
      "156 4.902162981033325 0:00:00.439001\n",
      "157 4.897278928756714 0:00:00.439786\n",
      "158 4.891508913040161 0:00:00.434841\n",
      "159 4.885822343826294 0:00:00.584990\n",
      "160 4.880981492996216 0:00:00.569784\n",
      "161 4.87564492225647 0:00:00.456627\n",
      "162 4.870528078079223 0:00:00.440022\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "learning_rate = 0.1\n",
    "w_embedding_dim = 100\n",
    "p_embedding_dim = 100\n",
    "dec_embedding_dim = 100\n",
    "dropout_prob = 0.1\n",
    "\n",
    "# model_encoder = Encoder(vocab_size_fr, w_embedding_dim, p_embedding_dim, dec_embedding_dim, max_sentence_length)\n",
    "# model_decoder = Decoder(dec_embedding_dim, vocab_size_en, max_sentence_length, dropout_prob)\n",
    "model_NMT = NMTModel(vocab_size_fr, w_embedding_dim, p_embedding_dim, dec_embedding_dim, max_sentence_length, vocab_size_en, dropout_prob)\n",
    "\n",
    "optimizer_NMT = optim.SGD(model_NMT.parameters(), lr = learning_rate)\n",
    "# optimizer_encoder = optim.SGD(model_encoder.parameters(), lr = learning_rate)\n",
    "# optimizer_decoder = optim.SGD(model_decoder.parameters(), lr = learning_rate)\n",
    "\n",
    "loss_func = nn.NLLLoss()\n",
    "losses = []\n",
    "avg_losses = []\n",
    "\n",
    "portion = 10\n",
    "\n",
    "train = True\n",
    "print('epoch, total loss, duration')\n",
    "for e in range(epochs):\n",
    "    \n",
    "    then = datetime.now()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    for s in range(portion):\n",
    "     \n",
    "        current_input = corpus2id_fr[s]\n",
    "        gold_output = corpus2id_en[s]\n",
    "        \n",
    "        if len(current_input) > 0 and len(gold_output) > 0:\n",
    "            \n",
    "            optimizer_NMT.zero_grad()\n",
    "            \n",
    "            sent_fr = torch.tensor(np.asarray(current_input), dtype= torch.long)\n",
    "            sent_en = torch.tensor(np.asarray(gold_output), dtype= torch.long)\n",
    "\n",
    "            pos_fr = torch.tensor(np.asarray([p for p in range(len(sent_fr))]))\n",
    "            pos_en = torch.tensor(np.asarray([p for p in range(len(sent_en))]))\n",
    "        \n",
    "            pred, attention_weights = model_NMT(sent_fr, pos_fr, sent_en, train)\n",
    "            \n",
    "            #sent_en = sent_en[1:len(sent_en)] #skip SOS\n",
    "            loss = loss_func(pred[0], sent_en)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer_NMT.step()\n",
    "            \n",
    "            total_loss += loss.item() \n",
    "       \n",
    "    now = datetime.now()\n",
    "        \n",
    "    losses.append(total_loss)\n",
    "    \n",
    "    print(e, total_loss/portion, now-then)\n",
    "\n",
    "with open('model_NMT' + str(portion) + '.pickle','wb') as file:\n",
    "    pickle.dump(model_NMT,file)\n",
    "\n",
    "    \n",
    "iteration= list(range(len(losses)))\n",
    "\n",
    "plt.plot(iteration, losses)\n",
    "plt.xlabel(\"Iterations for MT\")\n",
    "plt.ylabel('Total loss')\n",
    "plt.title('Evolution of the loss as a function of the iteration')\n",
    "plt.savefig(\"mt\" + str(portion)+\".png\")\n",
    "plt.show()\n",
    "\n",
    "test_fr_sentence = corpus2id_fr[0]\n",
    "test_en_sentence = corpus2id_en[0]\n",
    "    \n",
    "decoder_outputs, decoder_attentions = evaluate_sent(model_NMT, test_fr_sentence, test_en_sentence)\n",
    "\n",
    "print(word_ids2string(test_fr_sentence, id2tokens_fr))\n",
    "print(word_ids2string(test_en_sentence, id2tokens_en))\n",
    "print(word_ids2string(decoder_outputs, id2tokens_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = 3\n",
    "\n",
    "test_fr_sentence = corpus2id_fr[pair]\n",
    "test_en_sentence = corpus2id_en[pair]\n",
    "    \n",
    "decoder_outputs, decoder_attentions = evaluate_sent(model_NMT,test_fr_sentence, test_en_sentence)\n",
    "\n",
    "french_gold = word_ids2string(test_fr_sentence, id2tokens_fr)\n",
    "print(french_gold)\n",
    "print(len(word_ids2string(test_fr_sentence, id2tokens_fr)))\n",
    "\n",
    "english_gold = word_ids2string(test_en_sentence, id2tokens_en)\n",
    "print(english_gold)\n",
    "\n",
    "english_output = word_ids2string(decoder_outputs, id2tokens_en)\n",
    "print(english_output)\n",
    "print(len(word_ids2string(decoder_outputs, id2tokens_en)))\n",
    "\n",
    "print(decoder_attentions.size())\n",
    "S = decoder_attentions\n",
    "sent_num = pair\n",
    "\n",
    "# visualize_attention(S,sent_num)\n",
    "\n",
    "french_gold = (\" \").join(french_gold)\n",
    "showAttention(french_gold,english_output,S,pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('model_encoder' + str(portion) + '.pickle','rb') as file:\n",
    "    model_encoder = pickle.load(file)\n",
    "      \n",
    "\n",
    "with open('model_decoder' + str(portion) + '.pickle','rb') as file:\n",
    "    model_decoder = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_sent(model_NMT, sent_fr, sent_en):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        sent_fr = torch.tensor(np.asarray(sent_fr), dtype= torch.long)\n",
    "        sent_en = torch.tensor(np.asarray(sent_en), dtype= torch.long)\n",
    "\n",
    "        pos_fr = torch.tensor(np.asarray([p for p in range(len(sent_fr))]))\n",
    "        pos_en = torch.tensor(np.asarray([p for p in range(len(sent_en))]))\n",
    "\n",
    "#         average_context, stacked_contexts = model_encoder(sent_fr, pos_fr)\n",
    "        \n",
    "#         decoder_outputs, decoder_attentions = model_decoder(sent_en, average_context, stacked_contexts, train=False)\n",
    "        \n",
    "        decoder_outputs, decoder_attentions = model_NMT(sent_fr, pos_fr, sent_en, train=False)\n",
    "        \n",
    "    return decoder_outputs, decoder_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_ids2string(sentence, id2token):\n",
    "    \n",
    "    converted = []\n",
    "\n",
    "    for s in sentence:\n",
    "        converted.append(id2token[s])\n",
    "        \n",
    "    return converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write the results of the predicted sentences to a txt file for evaluation\n",
    "\n",
    "def write_test_eval(model_NMT, test_sentences_fr, test_sentences_en):\n",
    "\n",
    "    filename = \"test_results.txt\" \n",
    "    output = open(filename,\"w\") \n",
    "    \n",
    "    for sent in range(2): #range(len(test_sentences_fr)):\n",
    "\n",
    "        decoder_outputs, decoder_attentions = evaluate_sent(model_NMT, test_sentences_fr[sent], test_sentences_en[sent])\n",
    "        print(decoder_attentions.size())\n",
    "        \n",
    "        output_list = word_ids2string(decoder_outputs, id2tokens_en)\n",
    "        if '<EOS>' in output_list:\n",
    "            output_list.remove('<EOS>')\n",
    "        \n",
    "        output_string = (\" \").join(output_list)\n",
    "        \n",
    "        output.write(output_string + \"\\n\")\n",
    "\n",
    "    output.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_corpus2id_fr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-49cead130d78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwrite_test_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_NMT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_corpus2id_fr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_corpus2id_en\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_corpus2id_fr' is not defined"
     ]
    }
   ],
   "source": [
    "write_test_eval(model_NMT, test_corpus2id_fr, test_corpus2id_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "#BEAM SEARCH\n",
    "#teacher forcing prob\n",
    "#dropout prob\n",
    "#gru lstm rnn check\n",
    "#relu before rnn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_attention(S,sent_num):\n",
    "    \n",
    "    #model_encoder, model_decoder, sent_en, sent_fr\n",
    "    \n",
    "    #************************************************************************\n",
    "    # S is the log softmax version of S, also a torch Tensor! (actually more acurately it's a Variable(Tensor(..))\n",
    "    #************************************************************************\n",
    "\n",
    "    S = S.exp()\n",
    "    \n",
    "    # Plot the attention tensor\n",
    "    plt.clf()\n",
    "    numpy_S = S.data.numpy()\n",
    "    numpy_S = numpy_S[:,:,0]\n",
    "    #print(numpy_S.shape)\n",
    "\n",
    "    plt.imshow(numpy_S)\n",
    "    imname = \"attentions-test-\" + str(sent_num)\n",
    "    plt.savefig(imname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def showAttention(input_sentence, output_words, attentions, sentence_number):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    attentions = attentions.exp()\n",
    "    cax = ax.matshow(attentions[:,:,0].data.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    \n",
    "    imname = \"attentions-test-\" + str(sentence_number)\n",
    "    plt.savefig(imname)\n",
    "    plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.tensor(np.asarray([i for i in range(10)]), dtype= torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "asf = F.log_softmax(a, dim=0)\n",
    "print(asf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = torch.tensor(np.asarray([i+1 for i in range(10)]), dtype= torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st = torch.stack([a,b], dim = 0)\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = torch.tensor(np.asarray([0.1, 0.2]), dtype = torch.float).view(-1,1)\n",
    "print(weights.shape)\n",
    "\n",
    "torch.mul(weights, st)\n",
    "# torch.matmul(weights.view(1,2), st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.stack([a,b], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.mean(st, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.mean(st, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F.softmax(st, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = a*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "long(torch.argmax(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_word = torch.tensor(np.asarray([tokens2id_en['<SOS>']]), dtype = torch.long)\n",
    "print(test_word, test_word.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#     attn_weights = F.softmax(\n",
    "#             self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "#         attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "#                                  encoder_outputs.unsqueeze(0))\n",
    "\n",
    "#         output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "#         output = self.attn_combine(output).unsqueeze(0)\n",
    "           \n",
    "#         atts= torch.matmul(es, hidden_from_decoder)\n",
    "        \n",
    "#         weighted_context = es*attention_weights\n",
    "        \n",
    "        #if EOS for encoder, move on to the decoder\n",
    "        \n",
    "        #attention_matrices = self.attention_projection(e_out)\n",
    "        \n",
    "        #input embedding\n",
    "        #set hidden at the beginning\n",
    "        #get rnn output\n",
    "        #apply softmax\n",
    "\n",
    "        #feed actual word for training\n",
    "        #feed previous word for testing\n",
    "\n",
    "#             #view_shape = embeddings.shape[0]\n",
    "#             output, (hidden, cell) = self.bidirLSTM(embeddings.view(1, 1, -1)) \n",
    "\n",
    "#             hid_f = hidden[0]\n",
    "#             hid_b = hidden[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
