{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial\n",
    "from scipy import stats\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1)\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "from random import randint\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training sets\n",
    "with open('train.en') as f:\n",
    "    train_en = [l.strip() for l in f.readlines()]\n",
    "with open('train.fr') as f:\n",
    "    train_fr = [l.strip() for l in f.readlines()]\n",
    "\n",
    "#validation sets\n",
    "with open('val.en') as f:\n",
    "    val_en = [l.strip() for l in f.readlines()]\n",
    "with open('val.fr') as f:\n",
    "    val_fr = [l.strip() for l in f.readlines()]\n",
    "\n",
    "#test sets\n",
    "with open('test_2017_flickr.en') as f:\n",
    "    test_en = [l.strip() for l in f.readlines()]\n",
    "with open('test_2017_flickr.fr') as f:\n",
    "    test_fr = [l.strip() for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "# 0 PAD - padding 0 for convenience in masking\n",
    "# 1 BOS - beginning of sentence\n",
    "# 2 EOS - end of sentence\n",
    "# 3 UNK - unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_sentence_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokens_sentences(sentences):\n",
    "    tokens_list = []\n",
    "    sentence_list = []\n",
    "    for s in sentences:\n",
    "        split_sent = s.split()\n",
    "        sentence = []\n",
    "        for w in split_sent:\n",
    "\n",
    "            tokens_list.append(w)\n",
    "            sentence.append(w)\n",
    "\n",
    "        sentence_list.append(sentence)\n",
    "    \n",
    "    return tokens_list, sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size EN 15460\n",
      "Vocabulary size FR 17007\n"
     ]
    }
   ],
   "source": [
    "tokens_list_en, sentence_list_en = tokens_sentences(train_en)\n",
    "\n",
    "tokens_train_en = ['<PAD>', '<SOS>', '<EOS>', '<UNK>']\n",
    "tokens_train_en.extend(list(sorted(set(tokens_list_en))))\n",
    "vocab_size_en = len(tokens_train_en)\n",
    "print('Vocabulary size EN', vocab_size_en)\n",
    "\n",
    "count_tokens_train_en = Counter(tokens_list_en)\n",
    "\n",
    "tokens_list_fr, sentence_list_fr = tokens_sentences(train_fr)\n",
    "\n",
    "tokens_train_fr = ['<PAD>', '<SOS>', '<EOS>', '<UNK>']\n",
    "tokens_train_fr.extend(list(sorted(set(tokens_list_fr))))\n",
    "vocab_size_fr = len(tokens_train_fr)\n",
    "print('Vocabulary size FR', len(tokens_train_fr))\n",
    "\n",
    "count_tokens_train_fr = Counter(tokens_list_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_id_dicts(tokens):\n",
    "    #default dictionary key:id value:token\n",
    "    id2tokens = defaultdict(str)\n",
    "\n",
    "    for i in range(len(tokens)):\n",
    "        id2tokens[i] = tokens[i]\n",
    "\n",
    "    #default dictionary key:token value:id\n",
    "    tokens2id = defaultdict(int)\n",
    "\n",
    "    for ind in id2tokens:\n",
    "        tokens2id[id2tokens[ind]] = ind\n",
    "\n",
    "    return tokens2id, id2tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15460\n",
      "17007\n"
     ]
    }
   ],
   "source": [
    "tokens2id_en, id2tokens_en = get_id_dicts(tokens_train_en)\n",
    "\n",
    "vocabulary_size_train_en = len(tokens2id_en)\n",
    "print(vocabulary_size_train_en)\n",
    "\n",
    "tokens2id_fr, id2tokens_fr = get_id_dicts(tokens_train_fr)\n",
    "\n",
    "vocabulary_size_train_fr = len(tokens2id_fr)\n",
    "print(vocabulary_size_train_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_corpus2id(sentence_list, tokens2id):\n",
    "    \n",
    "    #convert dataset to ids\n",
    "    corpus2id = []\n",
    "    \n",
    "    for s in sentence_list:\n",
    "    \n",
    "        sentence2id = []\n",
    "        sentence2id.append(tokens2id['<SOS>'])\n",
    "    \n",
    "        for w in s:\n",
    "            word_id = tokens2id[w]\n",
    "            sentence2id.append(word_id)\n",
    "        \n",
    "        \n",
    "        sentence2id.append(tokens2id['<EOS>'])\n",
    "        corpus2id.append(sentence2id)\n",
    "    \n",
    "    return corpus2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus2id_en = convert_corpus2id(sentence_list_en, tokens2id_en)\n",
    "corpus2id_fr = convert_corpus2id(sentence_list_fr, tokens2id_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2021, 15433, 2129, 8939, 2555, 9954, 9572, 8983, 3797, 2]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus2id_en[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, total loss, average loss, duration\n",
      "0 719.7144274711609 719.714427471 0:00:02.074232\n",
      "1 540.7705373764038 630.242482424 0:00:02.187644\n",
      "2 517.1052298545837 592.530064901 0:00:02.190431\n",
      "3 510.6154594421387 572.051413536 0:00:02.826892\n",
      "4 509.6378049850464 559.568691826 0:00:02.736061\n",
      "5 509.7114906311035 551.259158293 0:00:02.542796\n",
      "6 509.78974533081055 545.334956442 0:00:02.557431\n",
      "7 509.7955799102783 540.892534375 0:00:02.592540\n",
      "8 509.7742762565613 537.43495014 0:00:02.308551\n",
      "9 509.75010204315186 534.66646533 0:00:02.577178\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuSZ5gnDOOdckTxDOOeea5AnCOedck/4/hodBJTBkW4UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f169c7dbc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,vocab_size_fr, w_embedding_dim, p_embedding_dim, dec_embedding_dim, max_sentence_length):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.vocab_size_fr = vocab_size_fr\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        self.w_embedding_dim = w_embedding_dim\n",
    "        self.p_embedding_dim = p_embedding_dim\n",
    "        \n",
    "        self.dec_embedding_dim = dec_embedding_dim\n",
    "        \n",
    "        #encoder\n",
    "        self.w_embeddings = nn.Embedding(self.vocab_size_fr, self.w_embedding_dim)\n",
    "        self.p_embeddings = nn.Embedding(self.max_sentence_length, self.p_embedding_dim)\n",
    "        \n",
    "        self.context_emb_dim = self.w_embedding_dim + self.p_embedding_dim\n",
    "        \n",
    "        self.average_projection = nn.Linear(self.context_emb_dim, self.dec_embedding_dim)\n",
    "        \n",
    "        self.attention_projection = nn.Linear(self.context_emb_dim, self.dec_embedding_dim)\n",
    "        #do we use non-linearity after attention\n",
    "        \n",
    "        #TODO: DROPOUT\n",
    "        \n",
    "        \n",
    "    def forward(self, sent_fr, pos_fr):\n",
    "        \n",
    "        #embedded = self.embedding(input).view(1, 1, -1)\n",
    "        #TODO:BATCH\n",
    "        \n",
    "        ws = []\n",
    "        ps = []\n",
    "        es = []\n",
    "        \n",
    "        for s in range(len(sent_fr)):\n",
    "            word = sent_fr[s]\n",
    "            pos = pos_fr[s]\n",
    "            \n",
    "            w_out = self.w_embeddings(word)\n",
    "\n",
    "            p_out = self.p_embeddings(pos)\n",
    "\n",
    "            e_out = torch.cat((w_out, p_out), 0)\n",
    "    \n",
    "            ws.append(w_out)\n",
    "            ps.append(p_out)\n",
    "            es.append(e_out)\n",
    "        \n",
    "        stacked_contexts = torch.stack(es, dim = 0)\n",
    "        average_context = torch.mean(stacked_contexts, dim = 0)\n",
    "        average_context = self.average_projection(average_context)\n",
    "        \n",
    "        stacked_contexts = self.attention_projection(stacked_contexts)\n",
    "            \n",
    "        return average_context, stacked_contexts\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, dec_embedding_dim, vocab_size_en, max_sentence_length, dropout_prob):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.vocab_size_en = vocab_size_en\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        \n",
    "        self.dec_embedding_dim = dec_embedding_dim\n",
    "        \n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.dropout = nn.Dropout(self.dropout_prob)\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.vocab_size_en, self.dec_embedding_dim)\n",
    "        \n",
    "        self.rnn = nn.RNN(self.dec_embedding_dim, self.dec_embedding_dim)\n",
    "        #self.bidirLSTM = nn.LSTM(self.embedding_dim, self.embedding_dim, bidirectional=True)\n",
    "        #TODO: LSTM, GRU \n",
    "       \n",
    "        #a linear layer after this before softmax\n",
    "        self.out_affine = nn.Linear(self.dec_embedding_dim, self.vocab_size_en)\n",
    "               \n",
    "    \n",
    "    def forward(self, gold_target_sent, encoder_avg_context, encoder_stacked_contexts):\n",
    "        \n",
    "        pred = []\n",
    "        attentions = []\n",
    "        \n",
    "        for s in range(len(gold_target_sent)):\n",
    "            gold_word = gold_target_sent[s]\n",
    "            \n",
    "            output = self.embedding(gold_word)\n",
    "\n",
    "            #g_out = self.dropout(g_out)\n",
    "            \n",
    "            if s == 0:\n",
    "            \n",
    "                #TODO: how to add weighted context\n",
    "                #do we set h0 to avg context OR do we input it?\n",
    "                output, hidden = self.rnn(output.view(1, 1, -1), encoder_avg_context.view(1, 1, -1))\n",
    "                prev_hidden = hidden\n",
    "                \n",
    "                s_output = F.softmax(output[0], dim=0) #TODO: CHECK DIM AND OUTPUT[0]\n",
    "                s_output = self.out_affine(s_output)\n",
    "                pred.append(s_output)\n",
    "                \n",
    "            else:\n",
    "                            \n",
    "                #TODO: how to add weighted context\n",
    "                output, hidden = self.rnn(output.view(1, 1, -1), prev_hidden.view(1, 1, -1))\n",
    "                prev_hidden = hidden\n",
    "                \n",
    "                s_output = F.softmax(output[0], dim=0) #TODO: CHECK DIM AND OUTPUT[0]\n",
    "                s_output = self.out_affine(s_output)\n",
    "                pred.append(s_output)\n",
    "                \n",
    "            attention_weights_word = F.softmax(torch.matmul(encoder_stacked_contexts, prev_hidden.view(-1,1)), dim = 0)\n",
    "            attentions.append(attention_weights_word)\n",
    "            \n",
    "        attention_weights = torch.stack(attentions, dim=0)\n",
    "            \n",
    "        pred = torch.stack(pred, dim=0)\n",
    "        return pred, attention_weights #output, hidden \n",
    "\n",
    "    \n",
    "    #https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "    \n",
    "\n",
    "epochs = 10\n",
    "learning_rate = 0.01\n",
    "w_embedding_dim = 10\n",
    "p_embedding_dim = 10\n",
    "dec_embedding_dim = 10\n",
    "dropout_prob = 0.1\n",
    "\n",
    "model_encoder = Encoder(vocab_size_fr, w_embedding_dim, p_embedding_dim, dec_embedding_dim, max_sentence_length)\n",
    "model_decoder = Decoder(dec_embedding_dim, vocab_size_en, max_sentence_length, dropout_prob)\n",
    "\n",
    "optimizer_encoder = optim.Adam(model_encoder.parameters(), lr = learning_rate)\n",
    "optimizer_decoder = optim.Adam(model_decoder.parameters(), lr = learning_rate)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "losses = []\n",
    "avg_losses = []\n",
    "\n",
    "portion = 100\n",
    "\n",
    "print('epoch, total loss, average loss, duration')\n",
    "for e in range(epochs):\n",
    "    \n",
    "    then = datetime.now()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    for s in range(portion):\n",
    " \n",
    "        current_input = corpus2id_fr[s]\n",
    "        gold_output = corpus2id_en[s]\n",
    "        \n",
    "        if len(current_input) > 0 and len(gold_output) > 0:\n",
    "            \n",
    "            sent_fr = torch.tensor(np.asarray(current_input), dtype= torch.long)\n",
    "            sent_en = torch.tensor(np.asarray(gold_output), dtype= torch.long)\n",
    "\n",
    "            pos_fr = torch.tensor(np.asarray([p for p in range(len(sent_fr))]))\n",
    "            pos_en = torch.tensor(np.asarray([p for p in range(len(sent_en))]))\n",
    "           \n",
    "            sent_fr_pos = torch.tensor(np.asarray(pos_fr), dtype= torch.long)            \n",
    "            sent_en_pos = torch.tensor(np.asarray(pos_en), dtype= torch.long)\n",
    "            \n",
    "            optimizer_encoder.zero_grad()\n",
    "            optimizer_decoder.zero_grad()\n",
    "\n",
    "            average_context, stacked_contexts = model_encoder(sent_fr, sent_fr_pos)\n",
    "       \n",
    "            #prev_hidden = average_context or actual prev_hidden\n",
    "        \n",
    "            pred, attention_weights = model_decoder(sent_en, average_context, stacked_contexts)\n",
    "            \n",
    "            loss = loss_func(pred.squeeze(), sent_en)\n",
    "        \n",
    "            loss.backward()\n",
    "\n",
    "            optimizer_encoder.step()\n",
    "            optimizer_decoder.step()\n",
    "\n",
    "            total_loss += loss.item() \n",
    "        \n",
    "    \n",
    "    now = datetime.now()\n",
    "        \n",
    "    losses.append(total_loss)\n",
    "    \n",
    "    avg_loss = np.mean(losses)\n",
    "    \n",
    "    print(e, total_loss, avg_loss, now-then)\n",
    "    \n",
    "    avg_losses.append(avg_loss)\n",
    "    \n",
    "\n",
    "with open('model_encoder' + str(portion) + '.pickle','wb') as file:\n",
    "    pickle.dump(model_encoder,file)\n",
    "      \n",
    "\n",
    "with open('model_decoder' + str(portion) + '.pickle','wb') as file:\n",
    "    pickle.dump(model_decoder,file)\n",
    "    \n",
    "iteration= list(range(len(avg_losses)))\n",
    "\n",
    "plt.plot(iteration, avg_losses)\n",
    "plt.xlabel(\"Iterations for MT\")\n",
    "plt.ylabel('Average loss')\n",
    "plt.title('Evolution of the loss as a function of the iteration')\n",
    "plt.savefig(\"mt\" + str(portion)+\".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "portion = 100\n",
    "\n",
    "with open('model_encoder' + str(portion) + '.pickle','rb') as file:\n",
    "    model_encoder = pickle.load(file)\n",
    "      \n",
    "\n",
    "with open('model_decoder' + str(portion) + '.pickle','rb') as file:\n",
    "    model_decoder = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_attention(model, sentence):\n",
    "    \n",
    "    out, att = \n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "#TEST - INFERENCE\n",
    "#BEAM SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.tensor(np.asarray([i for i in range(10)]), dtype= torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = torch.tensor(np.asarray([i+1 for i in range(10)]), dtype= torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.],\n",
      "        [  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.]])\n"
     ]
    }
   ],
   "source": [
    "st = torch.stack([a,b], dim = 0)\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   1.],\n",
       "        [  1.,   2.],\n",
       "        [  2.,   3.],\n",
       "        [  3.,   4.],\n",
       "        [  4.,   5.],\n",
       "        [  5.,   6.],\n",
       "        [  6.,   7.],\n",
       "        [  7.,   8.],\n",
       "        [  8.,   9.],\n",
       "        [  9.,  10.]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([a,b], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.5000,  5.5000])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(st, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5000,  1.5000,  2.5000,  3.5000,  4.5000,  5.5000,  6.5000,\n",
       "         7.5000,  8.5000,  9.5000])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(st, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2689,  0.2689,  0.2689,  0.2689,  0.2689,  0.2689,  0.2689,\n",
       "          0.2689,  0.2689,  0.2689],\n",
       "        [ 0.7311,  0.7311,  0.7311,  0.7311,  0.7311,  0.7311,  0.7311,\n",
       "          0.7311,  0.7311,  0.7311]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(st, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.],\n",
       "        [ 1.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [ 6.],\n",
       "        [ 7.],\n",
       "        [ 8.],\n",
       "        [ 9.]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#     attn_weights = F.softmax(\n",
    "#             self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "#         attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "#                                  encoder_outputs.unsqueeze(0))\n",
    "\n",
    "#         output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "#         output = self.attn_combine(output).unsqueeze(0)\n",
    "           \n",
    "#         atts= torch.matmul(es, hidden_from_decoder)\n",
    "        \n",
    "#         weighted_context = es*attention_weights\n",
    "        \n",
    "        #if EOS for encoder, move on to the decoder\n",
    "        \n",
    "        #attention_matrices = self.attention_projection(e_out)\n",
    "        \n",
    "        #input embedding\n",
    "        #set hidden at the beginning\n",
    "        #get rnn output\n",
    "        #apply softmax\n",
    "\n",
    "        #feed actual word for training\n",
    "        #feed previous word for testing\n",
    "\n",
    "#             #view_shape = embeddings.shape[0]\n",
    "#             output, (hidden, cell) = self.bidirLSTM(embeddings.view(1, 1, -1)) \n",
    "\n",
    "#             hid_f = hidden[0]\n",
    "#             hid_b = hidden[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
